{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/home/yecm/public/Multitask-Recommendation-Library/软件测试'),\n",
       " PosixPath('/home/yecm/public/Multitask-Recommendation-Library'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "this_directory = Path(os.curdir).resolve().absolute()\n",
    "project_directory = this_directory.parent\n",
    "if str(project_directory) not in sys.path:\n",
    "    sys.path.append(str(project_directory))\n",
    "this_directory, project_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Shared-Bottom\n",
      "Model: SingleTask\n",
      "Model: OMoE\n",
      "Model: MMoE\n",
      "Model: PLE\n",
      "Model: AITM\n",
      "Model: MetaHeac\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "# categorical_field_dims=[3,2]\n",
    "categorical_field_dims=[]\n",
    "numerical_num=100\n",
    "task_num=2\n",
    "\n",
    "expert_num = 10\n",
    "embed_dim=8\n",
    "# bottom_mlp_dims=[3,4,5]\n",
    "bottom_mlp_dims=[10]*100\n",
    "tower_mlp_dims=[2,3,4] \n",
    "dropout=0.1\n",
    "# layers_num = 10\n",
    "\n",
    "\n",
    "\n",
    "ms = [models.get_model(name, categorical_field_dims, numerical_num, task_num, \n",
    "                       expert_num, embed_dim, \n",
    "                       bottom_mlp_dims, tower_mlp_dims, dropout,\n",
    "                       ) for name in models.model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([403, 6, 4005, 4003, 2203, 9], [28, 828, 28, 32, 4428, 830])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(list(m.shared_parameters())) for m in ms[:-1]], [len(list(m.specific_parameters())) for m in ms[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Embedding-1                 [-1, 0, 8]               0\n",
      "    EmbeddingLayer-2                 [-1, 0, 8]               0\n",
      "            Linear-3                    [-1, 8]             808\n",
      "            Linear-4                   [-1, 10]              90\n",
      "       BatchNorm1d-5                   [-1, 10]              20\n",
      "              ReLU-6                   [-1, 10]               0\n",
      "           Dropout-7                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8                   [-1, 10]               0\n",
      "            Linear-9                   [-1, 10]              90\n",
      "      BatchNorm1d-10                   [-1, 10]              20\n",
      "             ReLU-11                   [-1, 10]               0\n",
      "          Dropout-12                   [-1, 10]               0\n",
      "MultiLayerPerceptron-13                   [-1, 10]               0\n",
      "           Linear-14                   [-1, 10]              90\n",
      "      BatchNorm1d-15                   [-1, 10]              20\n",
      "             ReLU-16                   [-1, 10]               0\n",
      "          Dropout-17                   [-1, 10]               0\n",
      "MultiLayerPerceptron-18                   [-1, 10]               0\n",
      "           Linear-19                   [-1, 10]              90\n",
      "      BatchNorm1d-20                   [-1, 10]              20\n",
      "             ReLU-21                   [-1, 10]               0\n",
      "          Dropout-22                   [-1, 10]               0\n",
      "MultiLayerPerceptron-23                   [-1, 10]               0\n",
      "           Linear-24                   [-1, 10]              90\n",
      "      BatchNorm1d-25                   [-1, 10]              20\n",
      "             ReLU-26                   [-1, 10]               0\n",
      "          Dropout-27                   [-1, 10]               0\n",
      "MultiLayerPerceptron-28                   [-1, 10]               0\n",
      "           Linear-29                   [-1, 10]              90\n",
      "      BatchNorm1d-30                   [-1, 10]              20\n",
      "             ReLU-31                   [-1, 10]               0\n",
      "          Dropout-32                   [-1, 10]               0\n",
      "MultiLayerPerceptron-33                   [-1, 10]               0\n",
      "           Linear-34                   [-1, 10]              90\n",
      "      BatchNorm1d-35                   [-1, 10]              20\n",
      "             ReLU-36                   [-1, 10]               0\n",
      "          Dropout-37                   [-1, 10]               0\n",
      "MultiLayerPerceptron-38                   [-1, 10]               0\n",
      "           Linear-39                   [-1, 10]              90\n",
      "      BatchNorm1d-40                   [-1, 10]              20\n",
      "             ReLU-41                   [-1, 10]               0\n",
      "          Dropout-42                   [-1, 10]               0\n",
      "MultiLayerPerceptron-43                   [-1, 10]               0\n",
      "           Linear-44                   [-1, 10]              90\n",
      "      BatchNorm1d-45                   [-1, 10]              20\n",
      "             ReLU-46                   [-1, 10]               0\n",
      "          Dropout-47                   [-1, 10]               0\n",
      "MultiLayerPerceptron-48                   [-1, 10]               0\n",
      "           Linear-49                   [-1, 10]              90\n",
      "      BatchNorm1d-50                   [-1, 10]              20\n",
      "             ReLU-51                   [-1, 10]               0\n",
      "          Dropout-52                   [-1, 10]               0\n",
      "MultiLayerPerceptron-53                   [-1, 10]               0\n",
      "           Linear-54                   [-1, 10]              90\n",
      "          Softmax-55                   [-1, 10]               0\n",
      "           Linear-56                   [-1, 10]              90\n",
      "      BatchNorm1d-57                   [-1, 10]              20\n",
      "             ReLU-58                   [-1, 10]               0\n",
      "          Dropout-59                   [-1, 10]               0\n",
      "MultiLayerPerceptron-60                   [-1, 10]               0\n",
      "           Linear-61                   [-1, 10]              90\n",
      "      BatchNorm1d-62                   [-1, 10]              20\n",
      "             ReLU-63                   [-1, 10]               0\n",
      "          Dropout-64                   [-1, 10]               0\n",
      "MultiLayerPerceptron-65                   [-1, 10]               0\n",
      "           Linear-66                   [-1, 10]              90\n",
      "      BatchNorm1d-67                   [-1, 10]              20\n",
      "             ReLU-68                   [-1, 10]               0\n",
      "          Dropout-69                   [-1, 10]               0\n",
      "MultiLayerPerceptron-70                   [-1, 10]               0\n",
      "           Linear-71                   [-1, 10]              90\n",
      "      BatchNorm1d-72                   [-1, 10]              20\n",
      "             ReLU-73                   [-1, 10]               0\n",
      "          Dropout-74                   [-1, 10]               0\n",
      "MultiLayerPerceptron-75                   [-1, 10]               0\n",
      "           Linear-76                   [-1, 10]              90\n",
      "      BatchNorm1d-77                   [-1, 10]              20\n",
      "             ReLU-78                   [-1, 10]               0\n",
      "          Dropout-79                   [-1, 10]               0\n",
      "MultiLayerPerceptron-80                   [-1, 10]               0\n",
      "           Linear-81                   [-1, 10]              90\n",
      "          Softmax-82                   [-1, 10]               0\n",
      "           Linear-83                   [-1, 15]             135\n",
      "          Softmax-84                   [-1, 15]               0\n",
      "           Linear-85                   [-1, 10]             110\n",
      "      BatchNorm1d-86                   [-1, 10]              20\n",
      "             ReLU-87                   [-1, 10]               0\n",
      "          Dropout-88                   [-1, 10]               0\n",
      "MultiLayerPerceptron-89                   [-1, 10]               0\n",
      "           Linear-90                   [-1, 10]             110\n",
      "      BatchNorm1d-91                   [-1, 10]              20\n",
      "             ReLU-92                   [-1, 10]               0\n",
      "          Dropout-93                   [-1, 10]               0\n",
      "MultiLayerPerceptron-94                   [-1, 10]               0\n",
      "           Linear-95                   [-1, 10]             110\n",
      "      BatchNorm1d-96                   [-1, 10]              20\n",
      "             ReLU-97                   [-1, 10]               0\n",
      "          Dropout-98                   [-1, 10]               0\n",
      "MultiLayerPerceptron-99                   [-1, 10]               0\n",
      "          Linear-100                   [-1, 10]             110\n",
      "     BatchNorm1d-101                   [-1, 10]              20\n",
      "            ReLU-102                   [-1, 10]               0\n",
      "         Dropout-103                   [-1, 10]               0\n",
      "MultiLayerPerceptron-104                   [-1, 10]               0\n",
      "          Linear-105                   [-1, 10]             110\n",
      "     BatchNorm1d-106                   [-1, 10]              20\n",
      "            ReLU-107                   [-1, 10]               0\n",
      "         Dropout-108                   [-1, 10]               0\n",
      "MultiLayerPerceptron-109                   [-1, 10]               0\n",
      "          Linear-110                   [-1, 10]             110\n",
      "     BatchNorm1d-111                   [-1, 10]              20\n",
      "            ReLU-112                   [-1, 10]               0\n",
      "         Dropout-113                   [-1, 10]               0\n",
      "MultiLayerPerceptron-114                   [-1, 10]               0\n",
      "          Linear-115                   [-1, 10]             110\n",
      "     BatchNorm1d-116                   [-1, 10]              20\n",
      "            ReLU-117                   [-1, 10]               0\n",
      "         Dropout-118                   [-1, 10]               0\n",
      "MultiLayerPerceptron-119                   [-1, 10]               0\n",
      "          Linear-120                   [-1, 10]             110\n",
      "     BatchNorm1d-121                   [-1, 10]              20\n",
      "            ReLU-122                   [-1, 10]               0\n",
      "         Dropout-123                   [-1, 10]               0\n",
      "MultiLayerPerceptron-124                   [-1, 10]               0\n",
      "          Linear-125                   [-1, 10]             110\n",
      "     BatchNorm1d-126                   [-1, 10]              20\n",
      "            ReLU-127                   [-1, 10]               0\n",
      "         Dropout-128                   [-1, 10]               0\n",
      "MultiLayerPerceptron-129                   [-1, 10]               0\n",
      "          Linear-130                   [-1, 10]             110\n",
      "     BatchNorm1d-131                   [-1, 10]              20\n",
      "            ReLU-132                   [-1, 10]               0\n",
      "         Dropout-133                   [-1, 10]               0\n",
      "MultiLayerPerceptron-134                   [-1, 10]               0\n",
      "          Linear-135                   [-1, 10]             110\n",
      "         Softmax-136                   [-1, 10]               0\n",
      "          Linear-137                   [-1, 10]             110\n",
      "     BatchNorm1d-138                   [-1, 10]              20\n",
      "            ReLU-139                   [-1, 10]               0\n",
      "         Dropout-140                   [-1, 10]               0\n",
      "MultiLayerPerceptron-141                   [-1, 10]               0\n",
      "          Linear-142                   [-1, 10]             110\n",
      "     BatchNorm1d-143                   [-1, 10]              20\n",
      "            ReLU-144                   [-1, 10]               0\n",
      "         Dropout-145                   [-1, 10]               0\n",
      "MultiLayerPerceptron-146                   [-1, 10]               0\n",
      "          Linear-147                   [-1, 10]             110\n",
      "     BatchNorm1d-148                   [-1, 10]              20\n",
      "            ReLU-149                   [-1, 10]               0\n",
      "         Dropout-150                   [-1, 10]               0\n",
      "MultiLayerPerceptron-151                   [-1, 10]               0\n",
      "          Linear-152                   [-1, 10]             110\n",
      "     BatchNorm1d-153                   [-1, 10]              20\n",
      "            ReLU-154                   [-1, 10]               0\n",
      "         Dropout-155                   [-1, 10]               0\n",
      "MultiLayerPerceptron-156                   [-1, 10]               0\n",
      "          Linear-157                   [-1, 10]             110\n",
      "     BatchNorm1d-158                   [-1, 10]              20\n",
      "            ReLU-159                   [-1, 10]               0\n",
      "         Dropout-160                   [-1, 10]               0\n",
      "MultiLayerPerceptron-161                   [-1, 10]               0\n",
      "          Linear-162                   [-1, 10]             110\n",
      "         Softmax-163                   [-1, 10]               0\n",
      "          Linear-164                   [-1, 15]             165\n",
      "         Softmax-165                   [-1, 15]               0\n",
      "          Linear-166                   [-1, 10]             110\n",
      "     BatchNorm1d-167                   [-1, 10]              20\n",
      "            ReLU-168                   [-1, 10]               0\n",
      "         Dropout-169                   [-1, 10]               0\n",
      "MultiLayerPerceptron-170                   [-1, 10]               0\n",
      "          Linear-171                   [-1, 10]             110\n",
      "     BatchNorm1d-172                   [-1, 10]              20\n",
      "            ReLU-173                   [-1, 10]               0\n",
      "         Dropout-174                   [-1, 10]               0\n",
      "MultiLayerPerceptron-175                   [-1, 10]               0\n",
      "          Linear-176                   [-1, 10]             110\n",
      "     BatchNorm1d-177                   [-1, 10]              20\n",
      "            ReLU-178                   [-1, 10]               0\n",
      "         Dropout-179                   [-1, 10]               0\n",
      "MultiLayerPerceptron-180                   [-1, 10]               0\n",
      "          Linear-181                   [-1, 10]             110\n",
      "     BatchNorm1d-182                   [-1, 10]              20\n",
      "            ReLU-183                   [-1, 10]               0\n",
      "         Dropout-184                   [-1, 10]               0\n",
      "MultiLayerPerceptron-185                   [-1, 10]               0\n",
      "          Linear-186                   [-1, 10]             110\n",
      "     BatchNorm1d-187                   [-1, 10]              20\n",
      "            ReLU-188                   [-1, 10]               0\n",
      "         Dropout-189                   [-1, 10]               0\n",
      "MultiLayerPerceptron-190                   [-1, 10]               0\n",
      "          Linear-191                   [-1, 10]             110\n",
      "     BatchNorm1d-192                   [-1, 10]              20\n",
      "            ReLU-193                   [-1, 10]               0\n",
      "         Dropout-194                   [-1, 10]               0\n",
      "MultiLayerPerceptron-195                   [-1, 10]               0\n",
      "          Linear-196                   [-1, 10]             110\n",
      "     BatchNorm1d-197                   [-1, 10]              20\n",
      "            ReLU-198                   [-1, 10]               0\n",
      "         Dropout-199                   [-1, 10]               0\n",
      "MultiLayerPerceptron-200                   [-1, 10]               0\n",
      "          Linear-201                   [-1, 10]             110\n",
      "     BatchNorm1d-202                   [-1, 10]              20\n",
      "            ReLU-203                   [-1, 10]               0\n",
      "         Dropout-204                   [-1, 10]               0\n",
      "MultiLayerPerceptron-205                   [-1, 10]               0\n",
      "          Linear-206                   [-1, 10]             110\n",
      "     BatchNorm1d-207                   [-1, 10]              20\n",
      "            ReLU-208                   [-1, 10]               0\n",
      "         Dropout-209                   [-1, 10]               0\n",
      "MultiLayerPerceptron-210                   [-1, 10]               0\n",
      "          Linear-211                   [-1, 10]             110\n",
      "     BatchNorm1d-212                   [-1, 10]              20\n",
      "            ReLU-213                   [-1, 10]               0\n",
      "         Dropout-214                   [-1, 10]               0\n",
      "MultiLayerPerceptron-215                   [-1, 10]               0\n",
      "          Linear-216                   [-1, 10]             110\n",
      "         Softmax-217                   [-1, 10]               0\n",
      "          Linear-218                   [-1, 10]             110\n",
      "     BatchNorm1d-219                   [-1, 10]              20\n",
      "            ReLU-220                   [-1, 10]               0\n",
      "         Dropout-221                   [-1, 10]               0\n",
      "MultiLayerPerceptron-222                   [-1, 10]               0\n",
      "          Linear-223                   [-1, 10]             110\n",
      "     BatchNorm1d-224                   [-1, 10]              20\n",
      "            ReLU-225                   [-1, 10]               0\n",
      "         Dropout-226                   [-1, 10]               0\n",
      "MultiLayerPerceptron-227                   [-1, 10]               0\n",
      "          Linear-228                   [-1, 10]             110\n",
      "     BatchNorm1d-229                   [-1, 10]              20\n",
      "            ReLU-230                   [-1, 10]               0\n",
      "         Dropout-231                   [-1, 10]               0\n",
      "MultiLayerPerceptron-232                   [-1, 10]               0\n",
      "          Linear-233                   [-1, 10]             110\n",
      "     BatchNorm1d-234                   [-1, 10]              20\n",
      "            ReLU-235                   [-1, 10]               0\n",
      "         Dropout-236                   [-1, 10]               0\n",
      "MultiLayerPerceptron-237                   [-1, 10]               0\n",
      "          Linear-238                   [-1, 10]             110\n",
      "     BatchNorm1d-239                   [-1, 10]              20\n",
      "            ReLU-240                   [-1, 10]               0\n",
      "         Dropout-241                   [-1, 10]               0\n",
      "MultiLayerPerceptron-242                   [-1, 10]               0\n",
      "          Linear-243                   [-1, 10]             110\n",
      "         Softmax-244                   [-1, 10]               0\n",
      "          Linear-245                   [-1, 15]             165\n",
      "         Softmax-246                   [-1, 15]               0\n",
      "          Linear-247                   [-1, 10]             110\n",
      "     BatchNorm1d-248                   [-1, 10]              20\n",
      "            ReLU-249                   [-1, 10]               0\n",
      "         Dropout-250                   [-1, 10]               0\n",
      "MultiLayerPerceptron-251                   [-1, 10]               0\n",
      "          Linear-252                   [-1, 10]             110\n",
      "     BatchNorm1d-253                   [-1, 10]              20\n",
      "            ReLU-254                   [-1, 10]               0\n",
      "         Dropout-255                   [-1, 10]               0\n",
      "MultiLayerPerceptron-256                   [-1, 10]               0\n",
      "          Linear-257                   [-1, 10]             110\n",
      "     BatchNorm1d-258                   [-1, 10]              20\n",
      "            ReLU-259                   [-1, 10]               0\n",
      "         Dropout-260                   [-1, 10]               0\n",
      "MultiLayerPerceptron-261                   [-1, 10]               0\n",
      "          Linear-262                   [-1, 10]             110\n",
      "     BatchNorm1d-263                   [-1, 10]              20\n",
      "            ReLU-264                   [-1, 10]               0\n",
      "         Dropout-265                   [-1, 10]               0\n",
      "MultiLayerPerceptron-266                   [-1, 10]               0\n",
      "          Linear-267                   [-1, 10]             110\n",
      "     BatchNorm1d-268                   [-1, 10]              20\n",
      "            ReLU-269                   [-1, 10]               0\n",
      "         Dropout-270                   [-1, 10]               0\n",
      "MultiLayerPerceptron-271                   [-1, 10]               0\n",
      "          Linear-272                   [-1, 10]             110\n",
      "     BatchNorm1d-273                   [-1, 10]              20\n",
      "            ReLU-274                   [-1, 10]               0\n",
      "         Dropout-275                   [-1, 10]               0\n",
      "MultiLayerPerceptron-276                   [-1, 10]               0\n",
      "          Linear-277                   [-1, 10]             110\n",
      "     BatchNorm1d-278                   [-1, 10]              20\n",
      "            ReLU-279                   [-1, 10]               0\n",
      "         Dropout-280                   [-1, 10]               0\n",
      "MultiLayerPerceptron-281                   [-1, 10]               0\n",
      "          Linear-282                   [-1, 10]             110\n",
      "     BatchNorm1d-283                   [-1, 10]              20\n",
      "            ReLU-284                   [-1, 10]               0\n",
      "         Dropout-285                   [-1, 10]               0\n",
      "MultiLayerPerceptron-286                   [-1, 10]               0\n",
      "          Linear-287                   [-1, 10]             110\n",
      "     BatchNorm1d-288                   [-1, 10]              20\n",
      "            ReLU-289                   [-1, 10]               0\n",
      "         Dropout-290                   [-1, 10]               0\n",
      "MultiLayerPerceptron-291                   [-1, 10]               0\n",
      "          Linear-292                   [-1, 10]             110\n",
      "     BatchNorm1d-293                   [-1, 10]              20\n",
      "            ReLU-294                   [-1, 10]               0\n",
      "         Dropout-295                   [-1, 10]               0\n",
      "MultiLayerPerceptron-296                   [-1, 10]               0\n",
      "          Linear-297                   [-1, 10]             110\n",
      "         Softmax-298                   [-1, 10]               0\n",
      "          Linear-299                   [-1, 10]             110\n",
      "     BatchNorm1d-300                   [-1, 10]              20\n",
      "            ReLU-301                   [-1, 10]               0\n",
      "         Dropout-302                   [-1, 10]               0\n",
      "MultiLayerPerceptron-303                   [-1, 10]               0\n",
      "          Linear-304                   [-1, 10]             110\n",
      "     BatchNorm1d-305                   [-1, 10]              20\n",
      "            ReLU-306                   [-1, 10]               0\n",
      "         Dropout-307                   [-1, 10]               0\n",
      "MultiLayerPerceptron-308                   [-1, 10]               0\n",
      "          Linear-309                   [-1, 10]             110\n",
      "     BatchNorm1d-310                   [-1, 10]              20\n",
      "            ReLU-311                   [-1, 10]               0\n",
      "         Dropout-312                   [-1, 10]               0\n",
      "MultiLayerPerceptron-313                   [-1, 10]               0\n",
      "          Linear-314                   [-1, 10]             110\n",
      "     BatchNorm1d-315                   [-1, 10]              20\n",
      "            ReLU-316                   [-1, 10]               0\n",
      "         Dropout-317                   [-1, 10]               0\n",
      "MultiLayerPerceptron-318                   [-1, 10]               0\n",
      "          Linear-319                   [-1, 10]             110\n",
      "     BatchNorm1d-320                   [-1, 10]              20\n",
      "            ReLU-321                   [-1, 10]               0\n",
      "         Dropout-322                   [-1, 10]               0\n",
      "MultiLayerPerceptron-323                   [-1, 10]               0\n",
      "          Linear-324                   [-1, 10]             110\n",
      "         Softmax-325                   [-1, 10]               0\n",
      "          Linear-326                   [-1, 15]             165\n",
      "         Softmax-327                   [-1, 15]               0\n",
      "          Linear-328                   [-1, 10]             110\n",
      "     BatchNorm1d-329                   [-1, 10]              20\n",
      "            ReLU-330                   [-1, 10]               0\n",
      "         Dropout-331                   [-1, 10]               0\n",
      "MultiLayerPerceptron-332                   [-1, 10]               0\n",
      "          Linear-333                   [-1, 10]             110\n",
      "     BatchNorm1d-334                   [-1, 10]              20\n",
      "            ReLU-335                   [-1, 10]               0\n",
      "         Dropout-336                   [-1, 10]               0\n",
      "MultiLayerPerceptron-337                   [-1, 10]               0\n",
      "          Linear-338                   [-1, 10]             110\n",
      "     BatchNorm1d-339                   [-1, 10]              20\n",
      "            ReLU-340                   [-1, 10]               0\n",
      "         Dropout-341                   [-1, 10]               0\n",
      "MultiLayerPerceptron-342                   [-1, 10]               0\n",
      "          Linear-343                   [-1, 10]             110\n",
      "     BatchNorm1d-344                   [-1, 10]              20\n",
      "            ReLU-345                   [-1, 10]               0\n",
      "         Dropout-346                   [-1, 10]               0\n",
      "MultiLayerPerceptron-347                   [-1, 10]               0\n",
      "          Linear-348                   [-1, 10]             110\n",
      "     BatchNorm1d-349                   [-1, 10]              20\n",
      "            ReLU-350                   [-1, 10]               0\n",
      "         Dropout-351                   [-1, 10]               0\n",
      "MultiLayerPerceptron-352                   [-1, 10]               0\n",
      "          Linear-353                   [-1, 10]             110\n",
      "     BatchNorm1d-354                   [-1, 10]              20\n",
      "            ReLU-355                   [-1, 10]               0\n",
      "         Dropout-356                   [-1, 10]               0\n",
      "MultiLayerPerceptron-357                   [-1, 10]               0\n",
      "          Linear-358                   [-1, 10]             110\n",
      "     BatchNorm1d-359                   [-1, 10]              20\n",
      "            ReLU-360                   [-1, 10]               0\n",
      "         Dropout-361                   [-1, 10]               0\n",
      "MultiLayerPerceptron-362                   [-1, 10]               0\n",
      "          Linear-363                   [-1, 10]             110\n",
      "     BatchNorm1d-364                   [-1, 10]              20\n",
      "            ReLU-365                   [-1, 10]               0\n",
      "         Dropout-366                   [-1, 10]               0\n",
      "MultiLayerPerceptron-367                   [-1, 10]               0\n",
      "          Linear-368                   [-1, 10]             110\n",
      "     BatchNorm1d-369                   [-1, 10]              20\n",
      "            ReLU-370                   [-1, 10]               0\n",
      "         Dropout-371                   [-1, 10]               0\n",
      "MultiLayerPerceptron-372                   [-1, 10]               0\n",
      "          Linear-373                   [-1, 10]             110\n",
      "     BatchNorm1d-374                   [-1, 10]              20\n",
      "            ReLU-375                   [-1, 10]               0\n",
      "         Dropout-376                   [-1, 10]               0\n",
      "MultiLayerPerceptron-377                   [-1, 10]               0\n",
      "          Linear-378                   [-1, 10]             110\n",
      "         Softmax-379                   [-1, 10]               0\n",
      "          Linear-380                   [-1, 10]             110\n",
      "     BatchNorm1d-381                   [-1, 10]              20\n",
      "            ReLU-382                   [-1, 10]               0\n",
      "         Dropout-383                   [-1, 10]               0\n",
      "MultiLayerPerceptron-384                   [-1, 10]               0\n",
      "          Linear-385                   [-1, 10]             110\n",
      "     BatchNorm1d-386                   [-1, 10]              20\n",
      "            ReLU-387                   [-1, 10]               0\n",
      "         Dropout-388                   [-1, 10]               0\n",
      "MultiLayerPerceptron-389                   [-1, 10]               0\n",
      "          Linear-390                   [-1, 10]             110\n",
      "     BatchNorm1d-391                   [-1, 10]              20\n",
      "            ReLU-392                   [-1, 10]               0\n",
      "         Dropout-393                   [-1, 10]               0\n",
      "MultiLayerPerceptron-394                   [-1, 10]               0\n",
      "          Linear-395                   [-1, 10]             110\n",
      "     BatchNorm1d-396                   [-1, 10]              20\n",
      "            ReLU-397                   [-1, 10]               0\n",
      "         Dropout-398                   [-1, 10]               0\n",
      "MultiLayerPerceptron-399                   [-1, 10]               0\n",
      "          Linear-400                   [-1, 10]             110\n",
      "     BatchNorm1d-401                   [-1, 10]              20\n",
      "            ReLU-402                   [-1, 10]               0\n",
      "         Dropout-403                   [-1, 10]               0\n",
      "MultiLayerPerceptron-404                   [-1, 10]               0\n",
      "          Linear-405                   [-1, 10]             110\n",
      "         Softmax-406                   [-1, 10]               0\n",
      "          Linear-407                   [-1, 15]             165\n",
      "         Softmax-408                   [-1, 15]               0\n",
      "          Linear-409                   [-1, 10]             110\n",
      "     BatchNorm1d-410                   [-1, 10]              20\n",
      "            ReLU-411                   [-1, 10]               0\n",
      "         Dropout-412                   [-1, 10]               0\n",
      "MultiLayerPerceptron-413                   [-1, 10]               0\n",
      "          Linear-414                   [-1, 10]             110\n",
      "     BatchNorm1d-415                   [-1, 10]              20\n",
      "            ReLU-416                   [-1, 10]               0\n",
      "         Dropout-417                   [-1, 10]               0\n",
      "MultiLayerPerceptron-418                   [-1, 10]               0\n",
      "          Linear-419                   [-1, 10]             110\n",
      "     BatchNorm1d-420                   [-1, 10]              20\n",
      "            ReLU-421                   [-1, 10]               0\n",
      "         Dropout-422                   [-1, 10]               0\n",
      "MultiLayerPerceptron-423                   [-1, 10]               0\n",
      "          Linear-424                   [-1, 10]             110\n",
      "     BatchNorm1d-425                   [-1, 10]              20\n",
      "            ReLU-426                   [-1, 10]               0\n",
      "         Dropout-427                   [-1, 10]               0\n",
      "MultiLayerPerceptron-428                   [-1, 10]               0\n",
      "          Linear-429                   [-1, 10]             110\n",
      "     BatchNorm1d-430                   [-1, 10]              20\n",
      "            ReLU-431                   [-1, 10]               0\n",
      "         Dropout-432                   [-1, 10]               0\n",
      "MultiLayerPerceptron-433                   [-1, 10]               0\n",
      "          Linear-434                   [-1, 10]             110\n",
      "     BatchNorm1d-435                   [-1, 10]              20\n",
      "            ReLU-436                   [-1, 10]               0\n",
      "         Dropout-437                   [-1, 10]               0\n",
      "MultiLayerPerceptron-438                   [-1, 10]               0\n",
      "          Linear-439                   [-1, 10]             110\n",
      "     BatchNorm1d-440                   [-1, 10]              20\n",
      "            ReLU-441                   [-1, 10]               0\n",
      "         Dropout-442                   [-1, 10]               0\n",
      "MultiLayerPerceptron-443                   [-1, 10]               0\n",
      "          Linear-444                   [-1, 10]             110\n",
      "     BatchNorm1d-445                   [-1, 10]              20\n",
      "            ReLU-446                   [-1, 10]               0\n",
      "         Dropout-447                   [-1, 10]               0\n",
      "MultiLayerPerceptron-448                   [-1, 10]               0\n",
      "          Linear-449                   [-1, 10]             110\n",
      "     BatchNorm1d-450                   [-1, 10]              20\n",
      "            ReLU-451                   [-1, 10]               0\n",
      "         Dropout-452                   [-1, 10]               0\n",
      "MultiLayerPerceptron-453                   [-1, 10]               0\n",
      "          Linear-454                   [-1, 10]             110\n",
      "     BatchNorm1d-455                   [-1, 10]              20\n",
      "            ReLU-456                   [-1, 10]               0\n",
      "         Dropout-457                   [-1, 10]               0\n",
      "MultiLayerPerceptron-458                   [-1, 10]               0\n",
      "          Linear-459                   [-1, 10]             110\n",
      "         Softmax-460                   [-1, 10]               0\n",
      "          Linear-461                   [-1, 10]             110\n",
      "     BatchNorm1d-462                   [-1, 10]              20\n",
      "            ReLU-463                   [-1, 10]               0\n",
      "         Dropout-464                   [-1, 10]               0\n",
      "MultiLayerPerceptron-465                   [-1, 10]               0\n",
      "          Linear-466                   [-1, 10]             110\n",
      "     BatchNorm1d-467                   [-1, 10]              20\n",
      "            ReLU-468                   [-1, 10]               0\n",
      "         Dropout-469                   [-1, 10]               0\n",
      "MultiLayerPerceptron-470                   [-1, 10]               0\n",
      "          Linear-471                   [-1, 10]             110\n",
      "     BatchNorm1d-472                   [-1, 10]              20\n",
      "            ReLU-473                   [-1, 10]               0\n",
      "         Dropout-474                   [-1, 10]               0\n",
      "MultiLayerPerceptron-475                   [-1, 10]               0\n",
      "          Linear-476                   [-1, 10]             110\n",
      "     BatchNorm1d-477                   [-1, 10]              20\n",
      "            ReLU-478                   [-1, 10]               0\n",
      "         Dropout-479                   [-1, 10]               0\n",
      "MultiLayerPerceptron-480                   [-1, 10]               0\n",
      "          Linear-481                   [-1, 10]             110\n",
      "     BatchNorm1d-482                   [-1, 10]              20\n",
      "            ReLU-483                   [-1, 10]               0\n",
      "         Dropout-484                   [-1, 10]               0\n",
      "MultiLayerPerceptron-485                   [-1, 10]               0\n",
      "          Linear-486                   [-1, 10]             110\n",
      "         Softmax-487                   [-1, 10]               0\n",
      "          Linear-488                   [-1, 15]             165\n",
      "         Softmax-489                   [-1, 15]               0\n",
      "          Linear-490                   [-1, 10]             110\n",
      "     BatchNorm1d-491                   [-1, 10]              20\n",
      "            ReLU-492                   [-1, 10]               0\n",
      "         Dropout-493                   [-1, 10]               0\n",
      "MultiLayerPerceptron-494                   [-1, 10]               0\n",
      "          Linear-495                   [-1, 10]             110\n",
      "     BatchNorm1d-496                   [-1, 10]              20\n",
      "            ReLU-497                   [-1, 10]               0\n",
      "         Dropout-498                   [-1, 10]               0\n",
      "MultiLayerPerceptron-499                   [-1, 10]               0\n",
      "          Linear-500                   [-1, 10]             110\n",
      "     BatchNorm1d-501                   [-1, 10]              20\n",
      "            ReLU-502                   [-1, 10]               0\n",
      "         Dropout-503                   [-1, 10]               0\n",
      "MultiLayerPerceptron-504                   [-1, 10]               0\n",
      "          Linear-505                   [-1, 10]             110\n",
      "     BatchNorm1d-506                   [-1, 10]              20\n",
      "            ReLU-507                   [-1, 10]               0\n",
      "         Dropout-508                   [-1, 10]               0\n",
      "MultiLayerPerceptron-509                   [-1, 10]               0\n",
      "          Linear-510                   [-1, 10]             110\n",
      "     BatchNorm1d-511                   [-1, 10]              20\n",
      "            ReLU-512                   [-1, 10]               0\n",
      "         Dropout-513                   [-1, 10]               0\n",
      "MultiLayerPerceptron-514                   [-1, 10]               0\n",
      "          Linear-515                   [-1, 10]             110\n",
      "     BatchNorm1d-516                   [-1, 10]              20\n",
      "            ReLU-517                   [-1, 10]               0\n",
      "         Dropout-518                   [-1, 10]               0\n",
      "MultiLayerPerceptron-519                   [-1, 10]               0\n",
      "          Linear-520                   [-1, 10]             110\n",
      "     BatchNorm1d-521                   [-1, 10]              20\n",
      "            ReLU-522                   [-1, 10]               0\n",
      "         Dropout-523                   [-1, 10]               0\n",
      "MultiLayerPerceptron-524                   [-1, 10]               0\n",
      "          Linear-525                   [-1, 10]             110\n",
      "     BatchNorm1d-526                   [-1, 10]              20\n",
      "            ReLU-527                   [-1, 10]               0\n",
      "         Dropout-528                   [-1, 10]               0\n",
      "MultiLayerPerceptron-529                   [-1, 10]               0\n",
      "          Linear-530                   [-1, 10]             110\n",
      "     BatchNorm1d-531                   [-1, 10]              20\n",
      "            ReLU-532                   [-1, 10]               0\n",
      "         Dropout-533                   [-1, 10]               0\n",
      "MultiLayerPerceptron-534                   [-1, 10]               0\n",
      "          Linear-535                   [-1, 10]             110\n",
      "     BatchNorm1d-536                   [-1, 10]              20\n",
      "            ReLU-537                   [-1, 10]               0\n",
      "         Dropout-538                   [-1, 10]               0\n",
      "MultiLayerPerceptron-539                   [-1, 10]               0\n",
      "          Linear-540                   [-1, 10]             110\n",
      "         Softmax-541                   [-1, 10]               0\n",
      "          Linear-542                   [-1, 10]             110\n",
      "     BatchNorm1d-543                   [-1, 10]              20\n",
      "            ReLU-544                   [-1, 10]               0\n",
      "         Dropout-545                   [-1, 10]               0\n",
      "MultiLayerPerceptron-546                   [-1, 10]               0\n",
      "          Linear-547                   [-1, 10]             110\n",
      "     BatchNorm1d-548                   [-1, 10]              20\n",
      "            ReLU-549                   [-1, 10]               0\n",
      "         Dropout-550                   [-1, 10]               0\n",
      "MultiLayerPerceptron-551                   [-1, 10]               0\n",
      "          Linear-552                   [-1, 10]             110\n",
      "     BatchNorm1d-553                   [-1, 10]              20\n",
      "            ReLU-554                   [-1, 10]               0\n",
      "         Dropout-555                   [-1, 10]               0\n",
      "MultiLayerPerceptron-556                   [-1, 10]               0\n",
      "          Linear-557                   [-1, 10]             110\n",
      "     BatchNorm1d-558                   [-1, 10]              20\n",
      "            ReLU-559                   [-1, 10]               0\n",
      "         Dropout-560                   [-1, 10]               0\n",
      "MultiLayerPerceptron-561                   [-1, 10]               0\n",
      "          Linear-562                   [-1, 10]             110\n",
      "     BatchNorm1d-563                   [-1, 10]              20\n",
      "            ReLU-564                   [-1, 10]               0\n",
      "         Dropout-565                   [-1, 10]               0\n",
      "MultiLayerPerceptron-566                   [-1, 10]               0\n",
      "          Linear-567                   [-1, 10]             110\n",
      "         Softmax-568                   [-1, 10]               0\n",
      "          Linear-569                   [-1, 15]             165\n",
      "         Softmax-570                   [-1, 15]               0\n",
      "          Linear-571                   [-1, 10]             110\n",
      "     BatchNorm1d-572                   [-1, 10]              20\n",
      "            ReLU-573                   [-1, 10]               0\n",
      "         Dropout-574                   [-1, 10]               0\n",
      "MultiLayerPerceptron-575                   [-1, 10]               0\n",
      "          Linear-576                   [-1, 10]             110\n",
      "     BatchNorm1d-577                   [-1, 10]              20\n",
      "            ReLU-578                   [-1, 10]               0\n",
      "         Dropout-579                   [-1, 10]               0\n",
      "MultiLayerPerceptron-580                   [-1, 10]               0\n",
      "          Linear-581                   [-1, 10]             110\n",
      "     BatchNorm1d-582                   [-1, 10]              20\n",
      "            ReLU-583                   [-1, 10]               0\n",
      "         Dropout-584                   [-1, 10]               0\n",
      "MultiLayerPerceptron-585                   [-1, 10]               0\n",
      "          Linear-586                   [-1, 10]             110\n",
      "     BatchNorm1d-587                   [-1, 10]              20\n",
      "            ReLU-588                   [-1, 10]               0\n",
      "         Dropout-589                   [-1, 10]               0\n",
      "MultiLayerPerceptron-590                   [-1, 10]               0\n",
      "          Linear-591                   [-1, 10]             110\n",
      "     BatchNorm1d-592                   [-1, 10]              20\n",
      "            ReLU-593                   [-1, 10]               0\n",
      "         Dropout-594                   [-1, 10]               0\n",
      "MultiLayerPerceptron-595                   [-1, 10]               0\n",
      "          Linear-596                   [-1, 10]             110\n",
      "     BatchNorm1d-597                   [-1, 10]              20\n",
      "            ReLU-598                   [-1, 10]               0\n",
      "         Dropout-599                   [-1, 10]               0\n",
      "MultiLayerPerceptron-600                   [-1, 10]               0\n",
      "          Linear-601                   [-1, 10]             110\n",
      "     BatchNorm1d-602                   [-1, 10]              20\n",
      "            ReLU-603                   [-1, 10]               0\n",
      "         Dropout-604                   [-1, 10]               0\n",
      "MultiLayerPerceptron-605                   [-1, 10]               0\n",
      "          Linear-606                   [-1, 10]             110\n",
      "     BatchNorm1d-607                   [-1, 10]              20\n",
      "            ReLU-608                   [-1, 10]               0\n",
      "         Dropout-609                   [-1, 10]               0\n",
      "MultiLayerPerceptron-610                   [-1, 10]               0\n",
      "          Linear-611                   [-1, 10]             110\n",
      "     BatchNorm1d-612                   [-1, 10]              20\n",
      "            ReLU-613                   [-1, 10]               0\n",
      "         Dropout-614                   [-1, 10]               0\n",
      "MultiLayerPerceptron-615                   [-1, 10]               0\n",
      "          Linear-616                   [-1, 10]             110\n",
      "     BatchNorm1d-617                   [-1, 10]              20\n",
      "            ReLU-618                   [-1, 10]               0\n",
      "         Dropout-619                   [-1, 10]               0\n",
      "MultiLayerPerceptron-620                   [-1, 10]               0\n",
      "          Linear-621                   [-1, 10]             110\n",
      "         Softmax-622                   [-1, 10]               0\n",
      "          Linear-623                   [-1, 10]             110\n",
      "     BatchNorm1d-624                   [-1, 10]              20\n",
      "            ReLU-625                   [-1, 10]               0\n",
      "         Dropout-626                   [-1, 10]               0\n",
      "MultiLayerPerceptron-627                   [-1, 10]               0\n",
      "          Linear-628                   [-1, 10]             110\n",
      "     BatchNorm1d-629                   [-1, 10]              20\n",
      "            ReLU-630                   [-1, 10]               0\n",
      "         Dropout-631                   [-1, 10]               0\n",
      "MultiLayerPerceptron-632                   [-1, 10]               0\n",
      "          Linear-633                   [-1, 10]             110\n",
      "     BatchNorm1d-634                   [-1, 10]              20\n",
      "            ReLU-635                   [-1, 10]               0\n",
      "         Dropout-636                   [-1, 10]               0\n",
      "MultiLayerPerceptron-637                   [-1, 10]               0\n",
      "          Linear-638                   [-1, 10]             110\n",
      "     BatchNorm1d-639                   [-1, 10]              20\n",
      "            ReLU-640                   [-1, 10]               0\n",
      "         Dropout-641                   [-1, 10]               0\n",
      "MultiLayerPerceptron-642                   [-1, 10]               0\n",
      "          Linear-643                   [-1, 10]             110\n",
      "     BatchNorm1d-644                   [-1, 10]              20\n",
      "            ReLU-645                   [-1, 10]               0\n",
      "         Dropout-646                   [-1, 10]               0\n",
      "MultiLayerPerceptron-647                   [-1, 10]               0\n",
      "          Linear-648                   [-1, 10]             110\n",
      "         Softmax-649                   [-1, 10]               0\n",
      "          Linear-650                   [-1, 15]             165\n",
      "         Softmax-651                   [-1, 15]               0\n",
      "          Linear-652                   [-1, 10]             110\n",
      "     BatchNorm1d-653                   [-1, 10]              20\n",
      "            ReLU-654                   [-1, 10]               0\n",
      "         Dropout-655                   [-1, 10]               0\n",
      "MultiLayerPerceptron-656                   [-1, 10]               0\n",
      "          Linear-657                   [-1, 10]             110\n",
      "     BatchNorm1d-658                   [-1, 10]              20\n",
      "            ReLU-659                   [-1, 10]               0\n",
      "         Dropout-660                   [-1, 10]               0\n",
      "MultiLayerPerceptron-661                   [-1, 10]               0\n",
      "          Linear-662                   [-1, 10]             110\n",
      "     BatchNorm1d-663                   [-1, 10]              20\n",
      "            ReLU-664                   [-1, 10]               0\n",
      "         Dropout-665                   [-1, 10]               0\n",
      "MultiLayerPerceptron-666                   [-1, 10]               0\n",
      "          Linear-667                   [-1, 10]             110\n",
      "     BatchNorm1d-668                   [-1, 10]              20\n",
      "            ReLU-669                   [-1, 10]               0\n",
      "         Dropout-670                   [-1, 10]               0\n",
      "MultiLayerPerceptron-671                   [-1, 10]               0\n",
      "          Linear-672                   [-1, 10]             110\n",
      "     BatchNorm1d-673                   [-1, 10]              20\n",
      "            ReLU-674                   [-1, 10]               0\n",
      "         Dropout-675                   [-1, 10]               0\n",
      "MultiLayerPerceptron-676                   [-1, 10]               0\n",
      "          Linear-677                   [-1, 10]             110\n",
      "     BatchNorm1d-678                   [-1, 10]              20\n",
      "            ReLU-679                   [-1, 10]               0\n",
      "         Dropout-680                   [-1, 10]               0\n",
      "MultiLayerPerceptron-681                   [-1, 10]               0\n",
      "          Linear-682                   [-1, 10]             110\n",
      "     BatchNorm1d-683                   [-1, 10]              20\n",
      "            ReLU-684                   [-1, 10]               0\n",
      "         Dropout-685                   [-1, 10]               0\n",
      "MultiLayerPerceptron-686                   [-1, 10]               0\n",
      "          Linear-687                   [-1, 10]             110\n",
      "     BatchNorm1d-688                   [-1, 10]              20\n",
      "            ReLU-689                   [-1, 10]               0\n",
      "         Dropout-690                   [-1, 10]               0\n",
      "MultiLayerPerceptron-691                   [-1, 10]               0\n",
      "          Linear-692                   [-1, 10]             110\n",
      "     BatchNorm1d-693                   [-1, 10]              20\n",
      "            ReLU-694                   [-1, 10]               0\n",
      "         Dropout-695                   [-1, 10]               0\n",
      "MultiLayerPerceptron-696                   [-1, 10]               0\n",
      "          Linear-697                   [-1, 10]             110\n",
      "     BatchNorm1d-698                   [-1, 10]              20\n",
      "            ReLU-699                   [-1, 10]               0\n",
      "         Dropout-700                   [-1, 10]               0\n",
      "MultiLayerPerceptron-701                   [-1, 10]               0\n",
      "          Linear-702                   [-1, 10]             110\n",
      "         Softmax-703                   [-1, 10]               0\n",
      "          Linear-704                   [-1, 10]             110\n",
      "     BatchNorm1d-705                   [-1, 10]              20\n",
      "            ReLU-706                   [-1, 10]               0\n",
      "         Dropout-707                   [-1, 10]               0\n",
      "MultiLayerPerceptron-708                   [-1, 10]               0\n",
      "          Linear-709                   [-1, 10]             110\n",
      "     BatchNorm1d-710                   [-1, 10]              20\n",
      "            ReLU-711                   [-1, 10]               0\n",
      "         Dropout-712                   [-1, 10]               0\n",
      "MultiLayerPerceptron-713                   [-1, 10]               0\n",
      "          Linear-714                   [-1, 10]             110\n",
      "     BatchNorm1d-715                   [-1, 10]              20\n",
      "            ReLU-716                   [-1, 10]               0\n",
      "         Dropout-717                   [-1, 10]               0\n",
      "MultiLayerPerceptron-718                   [-1, 10]               0\n",
      "          Linear-719                   [-1, 10]             110\n",
      "     BatchNorm1d-720                   [-1, 10]              20\n",
      "            ReLU-721                   [-1, 10]               0\n",
      "         Dropout-722                   [-1, 10]               0\n",
      "MultiLayerPerceptron-723                   [-1, 10]               0\n",
      "          Linear-724                   [-1, 10]             110\n",
      "     BatchNorm1d-725                   [-1, 10]              20\n",
      "            ReLU-726                   [-1, 10]               0\n",
      "         Dropout-727                   [-1, 10]               0\n",
      "MultiLayerPerceptron-728                   [-1, 10]               0\n",
      "          Linear-729                   [-1, 10]             110\n",
      "         Softmax-730                   [-1, 10]               0\n",
      "          Linear-731                   [-1, 15]             165\n",
      "         Softmax-732                   [-1, 15]               0\n",
      "          Linear-733                   [-1, 10]             110\n",
      "     BatchNorm1d-734                   [-1, 10]              20\n",
      "            ReLU-735                   [-1, 10]               0\n",
      "         Dropout-736                   [-1, 10]               0\n",
      "MultiLayerPerceptron-737                   [-1, 10]               0\n",
      "          Linear-738                   [-1, 10]             110\n",
      "     BatchNorm1d-739                   [-1, 10]              20\n",
      "            ReLU-740                   [-1, 10]               0\n",
      "         Dropout-741                   [-1, 10]               0\n",
      "MultiLayerPerceptron-742                   [-1, 10]               0\n",
      "          Linear-743                   [-1, 10]             110\n",
      "     BatchNorm1d-744                   [-1, 10]              20\n",
      "            ReLU-745                   [-1, 10]               0\n",
      "         Dropout-746                   [-1, 10]               0\n",
      "MultiLayerPerceptron-747                   [-1, 10]               0\n",
      "          Linear-748                   [-1, 10]             110\n",
      "     BatchNorm1d-749                   [-1, 10]              20\n",
      "            ReLU-750                   [-1, 10]               0\n",
      "         Dropout-751                   [-1, 10]               0\n",
      "MultiLayerPerceptron-752                   [-1, 10]               0\n",
      "          Linear-753                   [-1, 10]             110\n",
      "     BatchNorm1d-754                   [-1, 10]              20\n",
      "            ReLU-755                   [-1, 10]               0\n",
      "         Dropout-756                   [-1, 10]               0\n",
      "MultiLayerPerceptron-757                   [-1, 10]               0\n",
      "          Linear-758                   [-1, 10]             110\n",
      "     BatchNorm1d-759                   [-1, 10]              20\n",
      "            ReLU-760                   [-1, 10]               0\n",
      "         Dropout-761                   [-1, 10]               0\n",
      "MultiLayerPerceptron-762                   [-1, 10]               0\n",
      "          Linear-763                   [-1, 10]             110\n",
      "     BatchNorm1d-764                   [-1, 10]              20\n",
      "            ReLU-765                   [-1, 10]               0\n",
      "         Dropout-766                   [-1, 10]               0\n",
      "MultiLayerPerceptron-767                   [-1, 10]               0\n",
      "          Linear-768                   [-1, 10]             110\n",
      "     BatchNorm1d-769                   [-1, 10]              20\n",
      "            ReLU-770                   [-1, 10]               0\n",
      "         Dropout-771                   [-1, 10]               0\n",
      "MultiLayerPerceptron-772                   [-1, 10]               0\n",
      "          Linear-773                   [-1, 10]             110\n",
      "     BatchNorm1d-774                   [-1, 10]              20\n",
      "            ReLU-775                   [-1, 10]               0\n",
      "         Dropout-776                   [-1, 10]               0\n",
      "MultiLayerPerceptron-777                   [-1, 10]               0\n",
      "          Linear-778                   [-1, 10]             110\n",
      "     BatchNorm1d-779                   [-1, 10]              20\n",
      "            ReLU-780                   [-1, 10]               0\n",
      "         Dropout-781                   [-1, 10]               0\n",
      "MultiLayerPerceptron-782                   [-1, 10]               0\n",
      "          Linear-783                   [-1, 10]             110\n",
      "         Softmax-784                   [-1, 10]               0\n",
      "          Linear-785                   [-1, 10]             110\n",
      "     BatchNorm1d-786                   [-1, 10]              20\n",
      "            ReLU-787                   [-1, 10]               0\n",
      "         Dropout-788                   [-1, 10]               0\n",
      "MultiLayerPerceptron-789                   [-1, 10]               0\n",
      "          Linear-790                   [-1, 10]             110\n",
      "     BatchNorm1d-791                   [-1, 10]              20\n",
      "            ReLU-792                   [-1, 10]               0\n",
      "         Dropout-793                   [-1, 10]               0\n",
      "MultiLayerPerceptron-794                   [-1, 10]               0\n",
      "          Linear-795                   [-1, 10]             110\n",
      "     BatchNorm1d-796                   [-1, 10]              20\n",
      "            ReLU-797                   [-1, 10]               0\n",
      "         Dropout-798                   [-1, 10]               0\n",
      "MultiLayerPerceptron-799                   [-1, 10]               0\n",
      "          Linear-800                   [-1, 10]             110\n",
      "     BatchNorm1d-801                   [-1, 10]              20\n",
      "            ReLU-802                   [-1, 10]               0\n",
      "         Dropout-803                   [-1, 10]               0\n",
      "MultiLayerPerceptron-804                   [-1, 10]               0\n",
      "          Linear-805                   [-1, 10]             110\n",
      "     BatchNorm1d-806                   [-1, 10]              20\n",
      "            ReLU-807                   [-1, 10]               0\n",
      "         Dropout-808                   [-1, 10]               0\n",
      "MultiLayerPerceptron-809                   [-1, 10]               0\n",
      "          Linear-810                   [-1, 10]             110\n",
      "         Softmax-811                   [-1, 10]               0\n",
      "          Linear-812                   [-1, 15]             165\n",
      "         Softmax-813                   [-1, 15]               0\n",
      "          Linear-814                   [-1, 10]             110\n",
      "     BatchNorm1d-815                   [-1, 10]              20\n",
      "            ReLU-816                   [-1, 10]               0\n",
      "         Dropout-817                   [-1, 10]               0\n",
      "MultiLayerPerceptron-818                   [-1, 10]               0\n",
      "          Linear-819                   [-1, 10]             110\n",
      "     BatchNorm1d-820                   [-1, 10]              20\n",
      "            ReLU-821                   [-1, 10]               0\n",
      "         Dropout-822                   [-1, 10]               0\n",
      "MultiLayerPerceptron-823                   [-1, 10]               0\n",
      "          Linear-824                   [-1, 10]             110\n",
      "     BatchNorm1d-825                   [-1, 10]              20\n",
      "            ReLU-826                   [-1, 10]               0\n",
      "         Dropout-827                   [-1, 10]               0\n",
      "MultiLayerPerceptron-828                   [-1, 10]               0\n",
      "          Linear-829                   [-1, 10]             110\n",
      "     BatchNorm1d-830                   [-1, 10]              20\n",
      "            ReLU-831                   [-1, 10]               0\n",
      "         Dropout-832                   [-1, 10]               0\n",
      "MultiLayerPerceptron-833                   [-1, 10]               0\n",
      "          Linear-834                   [-1, 10]             110\n",
      "     BatchNorm1d-835                   [-1, 10]              20\n",
      "            ReLU-836                   [-1, 10]               0\n",
      "         Dropout-837                   [-1, 10]               0\n",
      "MultiLayerPerceptron-838                   [-1, 10]               0\n",
      "          Linear-839                   [-1, 10]             110\n",
      "     BatchNorm1d-840                   [-1, 10]              20\n",
      "            ReLU-841                   [-1, 10]               0\n",
      "         Dropout-842                   [-1, 10]               0\n",
      "MultiLayerPerceptron-843                   [-1, 10]               0\n",
      "          Linear-844                   [-1, 10]             110\n",
      "     BatchNorm1d-845                   [-1, 10]              20\n",
      "            ReLU-846                   [-1, 10]               0\n",
      "         Dropout-847                   [-1, 10]               0\n",
      "MultiLayerPerceptron-848                   [-1, 10]               0\n",
      "          Linear-849                   [-1, 10]             110\n",
      "     BatchNorm1d-850                   [-1, 10]              20\n",
      "            ReLU-851                   [-1, 10]               0\n",
      "         Dropout-852                   [-1, 10]               0\n",
      "MultiLayerPerceptron-853                   [-1, 10]               0\n",
      "          Linear-854                   [-1, 10]             110\n",
      "     BatchNorm1d-855                   [-1, 10]              20\n",
      "            ReLU-856                   [-1, 10]               0\n",
      "         Dropout-857                   [-1, 10]               0\n",
      "MultiLayerPerceptron-858                   [-1, 10]               0\n",
      "          Linear-859                   [-1, 10]             110\n",
      "     BatchNorm1d-860                   [-1, 10]              20\n",
      "            ReLU-861                   [-1, 10]               0\n",
      "         Dropout-862                   [-1, 10]               0\n",
      "MultiLayerPerceptron-863                   [-1, 10]               0\n",
      "          Linear-864                   [-1, 10]             110\n",
      "         Softmax-865                   [-1, 10]               0\n",
      "          Linear-866                   [-1, 10]             110\n",
      "     BatchNorm1d-867                   [-1, 10]              20\n",
      "            ReLU-868                   [-1, 10]               0\n",
      "         Dropout-869                   [-1, 10]               0\n",
      "MultiLayerPerceptron-870                   [-1, 10]               0\n",
      "          Linear-871                   [-1, 10]             110\n",
      "     BatchNorm1d-872                   [-1, 10]              20\n",
      "            ReLU-873                   [-1, 10]               0\n",
      "         Dropout-874                   [-1, 10]               0\n",
      "MultiLayerPerceptron-875                   [-1, 10]               0\n",
      "          Linear-876                   [-1, 10]             110\n",
      "     BatchNorm1d-877                   [-1, 10]              20\n",
      "            ReLU-878                   [-1, 10]               0\n",
      "         Dropout-879                   [-1, 10]               0\n",
      "MultiLayerPerceptron-880                   [-1, 10]               0\n",
      "          Linear-881                   [-1, 10]             110\n",
      "     BatchNorm1d-882                   [-1, 10]              20\n",
      "            ReLU-883                   [-1, 10]               0\n",
      "         Dropout-884                   [-1, 10]               0\n",
      "MultiLayerPerceptron-885                   [-1, 10]               0\n",
      "          Linear-886                   [-1, 10]             110\n",
      "     BatchNorm1d-887                   [-1, 10]              20\n",
      "            ReLU-888                   [-1, 10]               0\n",
      "         Dropout-889                   [-1, 10]               0\n",
      "MultiLayerPerceptron-890                   [-1, 10]               0\n",
      "          Linear-891                   [-1, 10]             110\n",
      "         Softmax-892                   [-1, 10]               0\n",
      "          Linear-893                   [-1, 15]             165\n",
      "         Softmax-894                   [-1, 15]               0\n",
      "          Linear-895                   [-1, 10]             110\n",
      "     BatchNorm1d-896                   [-1, 10]              20\n",
      "            ReLU-897                   [-1, 10]               0\n",
      "         Dropout-898                   [-1, 10]               0\n",
      "MultiLayerPerceptron-899                   [-1, 10]               0\n",
      "          Linear-900                   [-1, 10]             110\n",
      "     BatchNorm1d-901                   [-1, 10]              20\n",
      "            ReLU-902                   [-1, 10]               0\n",
      "         Dropout-903                   [-1, 10]               0\n",
      "MultiLayerPerceptron-904                   [-1, 10]               0\n",
      "          Linear-905                   [-1, 10]             110\n",
      "     BatchNorm1d-906                   [-1, 10]              20\n",
      "            ReLU-907                   [-1, 10]               0\n",
      "         Dropout-908                   [-1, 10]               0\n",
      "MultiLayerPerceptron-909                   [-1, 10]               0\n",
      "          Linear-910                   [-1, 10]             110\n",
      "     BatchNorm1d-911                   [-1, 10]              20\n",
      "            ReLU-912                   [-1, 10]               0\n",
      "         Dropout-913                   [-1, 10]               0\n",
      "MultiLayerPerceptron-914                   [-1, 10]               0\n",
      "          Linear-915                   [-1, 10]             110\n",
      "     BatchNorm1d-916                   [-1, 10]              20\n",
      "            ReLU-917                   [-1, 10]               0\n",
      "         Dropout-918                   [-1, 10]               0\n",
      "MultiLayerPerceptron-919                   [-1, 10]               0\n",
      "          Linear-920                   [-1, 10]             110\n",
      "     BatchNorm1d-921                   [-1, 10]              20\n",
      "            ReLU-922                   [-1, 10]               0\n",
      "         Dropout-923                   [-1, 10]               0\n",
      "MultiLayerPerceptron-924                   [-1, 10]               0\n",
      "          Linear-925                   [-1, 10]             110\n",
      "     BatchNorm1d-926                   [-1, 10]              20\n",
      "            ReLU-927                   [-1, 10]               0\n",
      "         Dropout-928                   [-1, 10]               0\n",
      "MultiLayerPerceptron-929                   [-1, 10]               0\n",
      "          Linear-930                   [-1, 10]             110\n",
      "     BatchNorm1d-931                   [-1, 10]              20\n",
      "            ReLU-932                   [-1, 10]               0\n",
      "         Dropout-933                   [-1, 10]               0\n",
      "MultiLayerPerceptron-934                   [-1, 10]               0\n",
      "          Linear-935                   [-1, 10]             110\n",
      "     BatchNorm1d-936                   [-1, 10]              20\n",
      "            ReLU-937                   [-1, 10]               0\n",
      "         Dropout-938                   [-1, 10]               0\n",
      "MultiLayerPerceptron-939                   [-1, 10]               0\n",
      "          Linear-940                   [-1, 10]             110\n",
      "     BatchNorm1d-941                   [-1, 10]              20\n",
      "            ReLU-942                   [-1, 10]               0\n",
      "         Dropout-943                   [-1, 10]               0\n",
      "MultiLayerPerceptron-944                   [-1, 10]               0\n",
      "          Linear-945                   [-1, 10]             110\n",
      "         Softmax-946                   [-1, 10]               0\n",
      "          Linear-947                   [-1, 10]             110\n",
      "     BatchNorm1d-948                   [-1, 10]              20\n",
      "            ReLU-949                   [-1, 10]               0\n",
      "         Dropout-950                   [-1, 10]               0\n",
      "MultiLayerPerceptron-951                   [-1, 10]               0\n",
      "          Linear-952                   [-1, 10]             110\n",
      "     BatchNorm1d-953                   [-1, 10]              20\n",
      "            ReLU-954                   [-1, 10]               0\n",
      "         Dropout-955                   [-1, 10]               0\n",
      "MultiLayerPerceptron-956                   [-1, 10]               0\n",
      "          Linear-957                   [-1, 10]             110\n",
      "     BatchNorm1d-958                   [-1, 10]              20\n",
      "            ReLU-959                   [-1, 10]               0\n",
      "         Dropout-960                   [-1, 10]               0\n",
      "MultiLayerPerceptron-961                   [-1, 10]               0\n",
      "          Linear-962                   [-1, 10]             110\n",
      "     BatchNorm1d-963                   [-1, 10]              20\n",
      "            ReLU-964                   [-1, 10]               0\n",
      "         Dropout-965                   [-1, 10]               0\n",
      "MultiLayerPerceptron-966                   [-1, 10]               0\n",
      "          Linear-967                   [-1, 10]             110\n",
      "     BatchNorm1d-968                   [-1, 10]              20\n",
      "            ReLU-969                   [-1, 10]               0\n",
      "         Dropout-970                   [-1, 10]               0\n",
      "MultiLayerPerceptron-971                   [-1, 10]               0\n",
      "          Linear-972                   [-1, 10]             110\n",
      "         Softmax-973                   [-1, 10]               0\n",
      "          Linear-974                   [-1, 15]             165\n",
      "         Softmax-975                   [-1, 15]               0\n",
      "          Linear-976                   [-1, 10]             110\n",
      "     BatchNorm1d-977                   [-1, 10]              20\n",
      "            ReLU-978                   [-1, 10]               0\n",
      "         Dropout-979                   [-1, 10]               0\n",
      "MultiLayerPerceptron-980                   [-1, 10]               0\n",
      "          Linear-981                   [-1, 10]             110\n",
      "     BatchNorm1d-982                   [-1, 10]              20\n",
      "            ReLU-983                   [-1, 10]               0\n",
      "         Dropout-984                   [-1, 10]               0\n",
      "MultiLayerPerceptron-985                   [-1, 10]               0\n",
      "          Linear-986                   [-1, 10]             110\n",
      "     BatchNorm1d-987                   [-1, 10]              20\n",
      "            ReLU-988                   [-1, 10]               0\n",
      "         Dropout-989                   [-1, 10]               0\n",
      "MultiLayerPerceptron-990                   [-1, 10]               0\n",
      "          Linear-991                   [-1, 10]             110\n",
      "     BatchNorm1d-992                   [-1, 10]              20\n",
      "            ReLU-993                   [-1, 10]               0\n",
      "         Dropout-994                   [-1, 10]               0\n",
      "MultiLayerPerceptron-995                   [-1, 10]               0\n",
      "          Linear-996                   [-1, 10]             110\n",
      "     BatchNorm1d-997                   [-1, 10]              20\n",
      "            ReLU-998                   [-1, 10]               0\n",
      "         Dropout-999                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1000                   [-1, 10]               0\n",
      "         Linear-1001                   [-1, 10]             110\n",
      "    BatchNorm1d-1002                   [-1, 10]              20\n",
      "           ReLU-1003                   [-1, 10]               0\n",
      "        Dropout-1004                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1005                   [-1, 10]               0\n",
      "         Linear-1006                   [-1, 10]             110\n",
      "    BatchNorm1d-1007                   [-1, 10]              20\n",
      "           ReLU-1008                   [-1, 10]               0\n",
      "        Dropout-1009                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1010                   [-1, 10]               0\n",
      "         Linear-1011                   [-1, 10]             110\n",
      "    BatchNorm1d-1012                   [-1, 10]              20\n",
      "           ReLU-1013                   [-1, 10]               0\n",
      "        Dropout-1014                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1015                   [-1, 10]               0\n",
      "         Linear-1016                   [-1, 10]             110\n",
      "    BatchNorm1d-1017                   [-1, 10]              20\n",
      "           ReLU-1018                   [-1, 10]               0\n",
      "        Dropout-1019                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1020                   [-1, 10]               0\n",
      "         Linear-1021                   [-1, 10]             110\n",
      "    BatchNorm1d-1022                   [-1, 10]              20\n",
      "           ReLU-1023                   [-1, 10]               0\n",
      "        Dropout-1024                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1025                   [-1, 10]               0\n",
      "         Linear-1026                   [-1, 10]             110\n",
      "        Softmax-1027                   [-1, 10]               0\n",
      "         Linear-1028                   [-1, 10]             110\n",
      "    BatchNorm1d-1029                   [-1, 10]              20\n",
      "           ReLU-1030                   [-1, 10]               0\n",
      "        Dropout-1031                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1032                   [-1, 10]               0\n",
      "         Linear-1033                   [-1, 10]             110\n",
      "    BatchNorm1d-1034                   [-1, 10]              20\n",
      "           ReLU-1035                   [-1, 10]               0\n",
      "        Dropout-1036                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1037                   [-1, 10]               0\n",
      "         Linear-1038                   [-1, 10]             110\n",
      "    BatchNorm1d-1039                   [-1, 10]              20\n",
      "           ReLU-1040                   [-1, 10]               0\n",
      "        Dropout-1041                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1042                   [-1, 10]               0\n",
      "         Linear-1043                   [-1, 10]             110\n",
      "    BatchNorm1d-1044                   [-1, 10]              20\n",
      "           ReLU-1045                   [-1, 10]               0\n",
      "        Dropout-1046                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1047                   [-1, 10]               0\n",
      "         Linear-1048                   [-1, 10]             110\n",
      "    BatchNorm1d-1049                   [-1, 10]              20\n",
      "           ReLU-1050                   [-1, 10]               0\n",
      "        Dropout-1051                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1052                   [-1, 10]               0\n",
      "         Linear-1053                   [-1, 10]             110\n",
      "        Softmax-1054                   [-1, 10]               0\n",
      "         Linear-1055                   [-1, 15]             165\n",
      "        Softmax-1056                   [-1, 15]               0\n",
      "         Linear-1057                   [-1, 10]             110\n",
      "    BatchNorm1d-1058                   [-1, 10]              20\n",
      "           ReLU-1059                   [-1, 10]               0\n",
      "        Dropout-1060                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1061                   [-1, 10]               0\n",
      "         Linear-1062                   [-1, 10]             110\n",
      "    BatchNorm1d-1063                   [-1, 10]              20\n",
      "           ReLU-1064                   [-1, 10]               0\n",
      "        Dropout-1065                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1066                   [-1, 10]               0\n",
      "         Linear-1067                   [-1, 10]             110\n",
      "    BatchNorm1d-1068                   [-1, 10]              20\n",
      "           ReLU-1069                   [-1, 10]               0\n",
      "        Dropout-1070                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1071                   [-1, 10]               0\n",
      "         Linear-1072                   [-1, 10]             110\n",
      "    BatchNorm1d-1073                   [-1, 10]              20\n",
      "           ReLU-1074                   [-1, 10]               0\n",
      "        Dropout-1075                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1076                   [-1, 10]               0\n",
      "         Linear-1077                   [-1, 10]             110\n",
      "    BatchNorm1d-1078                   [-1, 10]              20\n",
      "           ReLU-1079                   [-1, 10]               0\n",
      "        Dropout-1080                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1081                   [-1, 10]               0\n",
      "         Linear-1082                   [-1, 10]             110\n",
      "    BatchNorm1d-1083                   [-1, 10]              20\n",
      "           ReLU-1084                   [-1, 10]               0\n",
      "        Dropout-1085                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1086                   [-1, 10]               0\n",
      "         Linear-1087                   [-1, 10]             110\n",
      "    BatchNorm1d-1088                   [-1, 10]              20\n",
      "           ReLU-1089                   [-1, 10]               0\n",
      "        Dropout-1090                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1091                   [-1, 10]               0\n",
      "         Linear-1092                   [-1, 10]             110\n",
      "    BatchNorm1d-1093                   [-1, 10]              20\n",
      "           ReLU-1094                   [-1, 10]               0\n",
      "        Dropout-1095                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1096                   [-1, 10]               0\n",
      "         Linear-1097                   [-1, 10]             110\n",
      "    BatchNorm1d-1098                   [-1, 10]              20\n",
      "           ReLU-1099                   [-1, 10]               0\n",
      "        Dropout-1100                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1101                   [-1, 10]               0\n",
      "         Linear-1102                   [-1, 10]             110\n",
      "    BatchNorm1d-1103                   [-1, 10]              20\n",
      "           ReLU-1104                   [-1, 10]               0\n",
      "        Dropout-1105                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1106                   [-1, 10]               0\n",
      "         Linear-1107                   [-1, 10]             110\n",
      "        Softmax-1108                   [-1, 10]               0\n",
      "         Linear-1109                   [-1, 10]             110\n",
      "    BatchNorm1d-1110                   [-1, 10]              20\n",
      "           ReLU-1111                   [-1, 10]               0\n",
      "        Dropout-1112                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1113                   [-1, 10]               0\n",
      "         Linear-1114                   [-1, 10]             110\n",
      "    BatchNorm1d-1115                   [-1, 10]              20\n",
      "           ReLU-1116                   [-1, 10]               0\n",
      "        Dropout-1117                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1118                   [-1, 10]               0\n",
      "         Linear-1119                   [-1, 10]             110\n",
      "    BatchNorm1d-1120                   [-1, 10]              20\n",
      "           ReLU-1121                   [-1, 10]               0\n",
      "        Dropout-1122                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1123                   [-1, 10]               0\n",
      "         Linear-1124                   [-1, 10]             110\n",
      "    BatchNorm1d-1125                   [-1, 10]              20\n",
      "           ReLU-1126                   [-1, 10]               0\n",
      "        Dropout-1127                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1128                   [-1, 10]               0\n",
      "         Linear-1129                   [-1, 10]             110\n",
      "    BatchNorm1d-1130                   [-1, 10]              20\n",
      "           ReLU-1131                   [-1, 10]               0\n",
      "        Dropout-1132                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1133                   [-1, 10]               0\n",
      "         Linear-1134                   [-1, 10]             110\n",
      "        Softmax-1135                   [-1, 10]               0\n",
      "         Linear-1136                   [-1, 15]             165\n",
      "        Softmax-1137                   [-1, 15]               0\n",
      "         Linear-1138                   [-1, 10]             110\n",
      "    BatchNorm1d-1139                   [-1, 10]              20\n",
      "           ReLU-1140                   [-1, 10]               0\n",
      "        Dropout-1141                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1142                   [-1, 10]               0\n",
      "         Linear-1143                   [-1, 10]             110\n",
      "    BatchNorm1d-1144                   [-1, 10]              20\n",
      "           ReLU-1145                   [-1, 10]               0\n",
      "        Dropout-1146                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1147                   [-1, 10]               0\n",
      "         Linear-1148                   [-1, 10]             110\n",
      "    BatchNorm1d-1149                   [-1, 10]              20\n",
      "           ReLU-1150                   [-1, 10]               0\n",
      "        Dropout-1151                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1152                   [-1, 10]               0\n",
      "         Linear-1153                   [-1, 10]             110\n",
      "    BatchNorm1d-1154                   [-1, 10]              20\n",
      "           ReLU-1155                   [-1, 10]               0\n",
      "        Dropout-1156                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1157                   [-1, 10]               0\n",
      "         Linear-1158                   [-1, 10]             110\n",
      "    BatchNorm1d-1159                   [-1, 10]              20\n",
      "           ReLU-1160                   [-1, 10]               0\n",
      "        Dropout-1161                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1162                   [-1, 10]               0\n",
      "         Linear-1163                   [-1, 10]             110\n",
      "    BatchNorm1d-1164                   [-1, 10]              20\n",
      "           ReLU-1165                   [-1, 10]               0\n",
      "        Dropout-1166                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1167                   [-1, 10]               0\n",
      "         Linear-1168                   [-1, 10]             110\n",
      "    BatchNorm1d-1169                   [-1, 10]              20\n",
      "           ReLU-1170                   [-1, 10]               0\n",
      "        Dropout-1171                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1172                   [-1, 10]               0\n",
      "         Linear-1173                   [-1, 10]             110\n",
      "    BatchNorm1d-1174                   [-1, 10]              20\n",
      "           ReLU-1175                   [-1, 10]               0\n",
      "        Dropout-1176                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1177                   [-1, 10]               0\n",
      "         Linear-1178                   [-1, 10]             110\n",
      "    BatchNorm1d-1179                   [-1, 10]              20\n",
      "           ReLU-1180                   [-1, 10]               0\n",
      "        Dropout-1181                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1182                   [-1, 10]               0\n",
      "         Linear-1183                   [-1, 10]             110\n",
      "    BatchNorm1d-1184                   [-1, 10]              20\n",
      "           ReLU-1185                   [-1, 10]               0\n",
      "        Dropout-1186                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1187                   [-1, 10]               0\n",
      "         Linear-1188                   [-1, 10]             110\n",
      "        Softmax-1189                   [-1, 10]               0\n",
      "         Linear-1190                   [-1, 10]             110\n",
      "    BatchNorm1d-1191                   [-1, 10]              20\n",
      "           ReLU-1192                   [-1, 10]               0\n",
      "        Dropout-1193                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1194                   [-1, 10]               0\n",
      "         Linear-1195                   [-1, 10]             110\n",
      "    BatchNorm1d-1196                   [-1, 10]              20\n",
      "           ReLU-1197                   [-1, 10]               0\n",
      "        Dropout-1198                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1199                   [-1, 10]               0\n",
      "         Linear-1200                   [-1, 10]             110\n",
      "    BatchNorm1d-1201                   [-1, 10]              20\n",
      "           ReLU-1202                   [-1, 10]               0\n",
      "        Dropout-1203                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1204                   [-1, 10]               0\n",
      "         Linear-1205                   [-1, 10]             110\n",
      "    BatchNorm1d-1206                   [-1, 10]              20\n",
      "           ReLU-1207                   [-1, 10]               0\n",
      "        Dropout-1208                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1209                   [-1, 10]               0\n",
      "         Linear-1210                   [-1, 10]             110\n",
      "    BatchNorm1d-1211                   [-1, 10]              20\n",
      "           ReLU-1212                   [-1, 10]               0\n",
      "        Dropout-1213                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1214                   [-1, 10]               0\n",
      "         Linear-1215                   [-1, 10]             110\n",
      "        Softmax-1216                   [-1, 10]               0\n",
      "         Linear-1217                   [-1, 15]             165\n",
      "        Softmax-1218                   [-1, 15]               0\n",
      "         Linear-1219                   [-1, 10]             110\n",
      "    BatchNorm1d-1220                   [-1, 10]              20\n",
      "           ReLU-1221                   [-1, 10]               0\n",
      "        Dropout-1222                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1223                   [-1, 10]               0\n",
      "         Linear-1224                   [-1, 10]             110\n",
      "    BatchNorm1d-1225                   [-1, 10]              20\n",
      "           ReLU-1226                   [-1, 10]               0\n",
      "        Dropout-1227                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1228                   [-1, 10]               0\n",
      "         Linear-1229                   [-1, 10]             110\n",
      "    BatchNorm1d-1230                   [-1, 10]              20\n",
      "           ReLU-1231                   [-1, 10]               0\n",
      "        Dropout-1232                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1233                   [-1, 10]               0\n",
      "         Linear-1234                   [-1, 10]             110\n",
      "    BatchNorm1d-1235                   [-1, 10]              20\n",
      "           ReLU-1236                   [-1, 10]               0\n",
      "        Dropout-1237                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1238                   [-1, 10]               0\n",
      "         Linear-1239                   [-1, 10]             110\n",
      "    BatchNorm1d-1240                   [-1, 10]              20\n",
      "           ReLU-1241                   [-1, 10]               0\n",
      "        Dropout-1242                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1243                   [-1, 10]               0\n",
      "         Linear-1244                   [-1, 10]             110\n",
      "    BatchNorm1d-1245                   [-1, 10]              20\n",
      "           ReLU-1246                   [-1, 10]               0\n",
      "        Dropout-1247                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1248                   [-1, 10]               0\n",
      "         Linear-1249                   [-1, 10]             110\n",
      "    BatchNorm1d-1250                   [-1, 10]              20\n",
      "           ReLU-1251                   [-1, 10]               0\n",
      "        Dropout-1252                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1253                   [-1, 10]               0\n",
      "         Linear-1254                   [-1, 10]             110\n",
      "    BatchNorm1d-1255                   [-1, 10]              20\n",
      "           ReLU-1256                   [-1, 10]               0\n",
      "        Dropout-1257                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1258                   [-1, 10]               0\n",
      "         Linear-1259                   [-1, 10]             110\n",
      "    BatchNorm1d-1260                   [-1, 10]              20\n",
      "           ReLU-1261                   [-1, 10]               0\n",
      "        Dropout-1262                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1263                   [-1, 10]               0\n",
      "         Linear-1264                   [-1, 10]             110\n",
      "    BatchNorm1d-1265                   [-1, 10]              20\n",
      "           ReLU-1266                   [-1, 10]               0\n",
      "        Dropout-1267                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1268                   [-1, 10]               0\n",
      "         Linear-1269                   [-1, 10]             110\n",
      "        Softmax-1270                   [-1, 10]               0\n",
      "         Linear-1271                   [-1, 10]             110\n",
      "    BatchNorm1d-1272                   [-1, 10]              20\n",
      "           ReLU-1273                   [-1, 10]               0\n",
      "        Dropout-1274                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1275                   [-1, 10]               0\n",
      "         Linear-1276                   [-1, 10]             110\n",
      "    BatchNorm1d-1277                   [-1, 10]              20\n",
      "           ReLU-1278                   [-1, 10]               0\n",
      "        Dropout-1279                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1280                   [-1, 10]               0\n",
      "         Linear-1281                   [-1, 10]             110\n",
      "    BatchNorm1d-1282                   [-1, 10]              20\n",
      "           ReLU-1283                   [-1, 10]               0\n",
      "        Dropout-1284                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1285                   [-1, 10]               0\n",
      "         Linear-1286                   [-1, 10]             110\n",
      "    BatchNorm1d-1287                   [-1, 10]              20\n",
      "           ReLU-1288                   [-1, 10]               0\n",
      "        Dropout-1289                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1290                   [-1, 10]               0\n",
      "         Linear-1291                   [-1, 10]             110\n",
      "    BatchNorm1d-1292                   [-1, 10]              20\n",
      "           ReLU-1293                   [-1, 10]               0\n",
      "        Dropout-1294                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1295                   [-1, 10]               0\n",
      "         Linear-1296                   [-1, 10]             110\n",
      "        Softmax-1297                   [-1, 10]               0\n",
      "         Linear-1298                   [-1, 15]             165\n",
      "        Softmax-1299                   [-1, 15]               0\n",
      "         Linear-1300                   [-1, 10]             110\n",
      "    BatchNorm1d-1301                   [-1, 10]              20\n",
      "           ReLU-1302                   [-1, 10]               0\n",
      "        Dropout-1303                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1304                   [-1, 10]               0\n",
      "         Linear-1305                   [-1, 10]             110\n",
      "    BatchNorm1d-1306                   [-1, 10]              20\n",
      "           ReLU-1307                   [-1, 10]               0\n",
      "        Dropout-1308                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1309                   [-1, 10]               0\n",
      "         Linear-1310                   [-1, 10]             110\n",
      "    BatchNorm1d-1311                   [-1, 10]              20\n",
      "           ReLU-1312                   [-1, 10]               0\n",
      "        Dropout-1313                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1314                   [-1, 10]               0\n",
      "         Linear-1315                   [-1, 10]             110\n",
      "    BatchNorm1d-1316                   [-1, 10]              20\n",
      "           ReLU-1317                   [-1, 10]               0\n",
      "        Dropout-1318                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1319                   [-1, 10]               0\n",
      "         Linear-1320                   [-1, 10]             110\n",
      "    BatchNorm1d-1321                   [-1, 10]              20\n",
      "           ReLU-1322                   [-1, 10]               0\n",
      "        Dropout-1323                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1324                   [-1, 10]               0\n",
      "         Linear-1325                   [-1, 10]             110\n",
      "    BatchNorm1d-1326                   [-1, 10]              20\n",
      "           ReLU-1327                   [-1, 10]               0\n",
      "        Dropout-1328                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1329                   [-1, 10]               0\n",
      "         Linear-1330                   [-1, 10]             110\n",
      "    BatchNorm1d-1331                   [-1, 10]              20\n",
      "           ReLU-1332                   [-1, 10]               0\n",
      "        Dropout-1333                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1334                   [-1, 10]               0\n",
      "         Linear-1335                   [-1, 10]             110\n",
      "    BatchNorm1d-1336                   [-1, 10]              20\n",
      "           ReLU-1337                   [-1, 10]               0\n",
      "        Dropout-1338                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1339                   [-1, 10]               0\n",
      "         Linear-1340                   [-1, 10]             110\n",
      "    BatchNorm1d-1341                   [-1, 10]              20\n",
      "           ReLU-1342                   [-1, 10]               0\n",
      "        Dropout-1343                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1344                   [-1, 10]               0\n",
      "         Linear-1345                   [-1, 10]             110\n",
      "    BatchNorm1d-1346                   [-1, 10]              20\n",
      "           ReLU-1347                   [-1, 10]               0\n",
      "        Dropout-1348                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1349                   [-1, 10]               0\n",
      "         Linear-1350                   [-1, 10]             110\n",
      "        Softmax-1351                   [-1, 10]               0\n",
      "         Linear-1352                   [-1, 10]             110\n",
      "    BatchNorm1d-1353                   [-1, 10]              20\n",
      "           ReLU-1354                   [-1, 10]               0\n",
      "        Dropout-1355                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1356                   [-1, 10]               0\n",
      "         Linear-1357                   [-1, 10]             110\n",
      "    BatchNorm1d-1358                   [-1, 10]              20\n",
      "           ReLU-1359                   [-1, 10]               0\n",
      "        Dropout-1360                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1361                   [-1, 10]               0\n",
      "         Linear-1362                   [-1, 10]             110\n",
      "    BatchNorm1d-1363                   [-1, 10]              20\n",
      "           ReLU-1364                   [-1, 10]               0\n",
      "        Dropout-1365                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1366                   [-1, 10]               0\n",
      "         Linear-1367                   [-1, 10]             110\n",
      "    BatchNorm1d-1368                   [-1, 10]              20\n",
      "           ReLU-1369                   [-1, 10]               0\n",
      "        Dropout-1370                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1371                   [-1, 10]               0\n",
      "         Linear-1372                   [-1, 10]             110\n",
      "    BatchNorm1d-1373                   [-1, 10]              20\n",
      "           ReLU-1374                   [-1, 10]               0\n",
      "        Dropout-1375                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1376                   [-1, 10]               0\n",
      "         Linear-1377                   [-1, 10]             110\n",
      "        Softmax-1378                   [-1, 10]               0\n",
      "         Linear-1379                   [-1, 15]             165\n",
      "        Softmax-1380                   [-1, 15]               0\n",
      "         Linear-1381                   [-1, 10]             110\n",
      "    BatchNorm1d-1382                   [-1, 10]              20\n",
      "           ReLU-1383                   [-1, 10]               0\n",
      "        Dropout-1384                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1385                   [-1, 10]               0\n",
      "         Linear-1386                   [-1, 10]             110\n",
      "    BatchNorm1d-1387                   [-1, 10]              20\n",
      "           ReLU-1388                   [-1, 10]               0\n",
      "        Dropout-1389                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1390                   [-1, 10]               0\n",
      "         Linear-1391                   [-1, 10]             110\n",
      "    BatchNorm1d-1392                   [-1, 10]              20\n",
      "           ReLU-1393                   [-1, 10]               0\n",
      "        Dropout-1394                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1395                   [-1, 10]               0\n",
      "         Linear-1396                   [-1, 10]             110\n",
      "    BatchNorm1d-1397                   [-1, 10]              20\n",
      "           ReLU-1398                   [-1, 10]               0\n",
      "        Dropout-1399                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1400                   [-1, 10]               0\n",
      "         Linear-1401                   [-1, 10]             110\n",
      "    BatchNorm1d-1402                   [-1, 10]              20\n",
      "           ReLU-1403                   [-1, 10]               0\n",
      "        Dropout-1404                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1405                   [-1, 10]               0\n",
      "         Linear-1406                   [-1, 10]             110\n",
      "    BatchNorm1d-1407                   [-1, 10]              20\n",
      "           ReLU-1408                   [-1, 10]               0\n",
      "        Dropout-1409                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1410                   [-1, 10]               0\n",
      "         Linear-1411                   [-1, 10]             110\n",
      "    BatchNorm1d-1412                   [-1, 10]              20\n",
      "           ReLU-1413                   [-1, 10]               0\n",
      "        Dropout-1414                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1415                   [-1, 10]               0\n",
      "         Linear-1416                   [-1, 10]             110\n",
      "    BatchNorm1d-1417                   [-1, 10]              20\n",
      "           ReLU-1418                   [-1, 10]               0\n",
      "        Dropout-1419                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1420                   [-1, 10]               0\n",
      "         Linear-1421                   [-1, 10]             110\n",
      "    BatchNorm1d-1422                   [-1, 10]              20\n",
      "           ReLU-1423                   [-1, 10]               0\n",
      "        Dropout-1424                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1425                   [-1, 10]               0\n",
      "         Linear-1426                   [-1, 10]             110\n",
      "    BatchNorm1d-1427                   [-1, 10]              20\n",
      "           ReLU-1428                   [-1, 10]               0\n",
      "        Dropout-1429                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1430                   [-1, 10]               0\n",
      "         Linear-1431                   [-1, 10]             110\n",
      "        Softmax-1432                   [-1, 10]               0\n",
      "         Linear-1433                   [-1, 10]             110\n",
      "    BatchNorm1d-1434                   [-1, 10]              20\n",
      "           ReLU-1435                   [-1, 10]               0\n",
      "        Dropout-1436                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1437                   [-1, 10]               0\n",
      "         Linear-1438                   [-1, 10]             110\n",
      "    BatchNorm1d-1439                   [-1, 10]              20\n",
      "           ReLU-1440                   [-1, 10]               0\n",
      "        Dropout-1441                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1442                   [-1, 10]               0\n",
      "         Linear-1443                   [-1, 10]             110\n",
      "    BatchNorm1d-1444                   [-1, 10]              20\n",
      "           ReLU-1445                   [-1, 10]               0\n",
      "        Dropout-1446                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1447                   [-1, 10]               0\n",
      "         Linear-1448                   [-1, 10]             110\n",
      "    BatchNorm1d-1449                   [-1, 10]              20\n",
      "           ReLU-1450                   [-1, 10]               0\n",
      "        Dropout-1451                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1452                   [-1, 10]               0\n",
      "         Linear-1453                   [-1, 10]             110\n",
      "    BatchNorm1d-1454                   [-1, 10]              20\n",
      "           ReLU-1455                   [-1, 10]               0\n",
      "        Dropout-1456                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1457                   [-1, 10]               0\n",
      "         Linear-1458                   [-1, 10]             110\n",
      "        Softmax-1459                   [-1, 10]               0\n",
      "         Linear-1460                   [-1, 15]             165\n",
      "        Softmax-1461                   [-1, 15]               0\n",
      "         Linear-1462                   [-1, 10]             110\n",
      "    BatchNorm1d-1463                   [-1, 10]              20\n",
      "           ReLU-1464                   [-1, 10]               0\n",
      "        Dropout-1465                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1466                   [-1, 10]               0\n",
      "         Linear-1467                   [-1, 10]             110\n",
      "    BatchNorm1d-1468                   [-1, 10]              20\n",
      "           ReLU-1469                   [-1, 10]               0\n",
      "        Dropout-1470                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1471                   [-1, 10]               0\n",
      "         Linear-1472                   [-1, 10]             110\n",
      "    BatchNorm1d-1473                   [-1, 10]              20\n",
      "           ReLU-1474                   [-1, 10]               0\n",
      "        Dropout-1475                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1476                   [-1, 10]               0\n",
      "         Linear-1477                   [-1, 10]             110\n",
      "    BatchNorm1d-1478                   [-1, 10]              20\n",
      "           ReLU-1479                   [-1, 10]               0\n",
      "        Dropout-1480                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1481                   [-1, 10]               0\n",
      "         Linear-1482                   [-1, 10]             110\n",
      "    BatchNorm1d-1483                   [-1, 10]              20\n",
      "           ReLU-1484                   [-1, 10]               0\n",
      "        Dropout-1485                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1486                   [-1, 10]               0\n",
      "         Linear-1487                   [-1, 10]             110\n",
      "    BatchNorm1d-1488                   [-1, 10]              20\n",
      "           ReLU-1489                   [-1, 10]               0\n",
      "        Dropout-1490                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1491                   [-1, 10]               0\n",
      "         Linear-1492                   [-1, 10]             110\n",
      "    BatchNorm1d-1493                   [-1, 10]              20\n",
      "           ReLU-1494                   [-1, 10]               0\n",
      "        Dropout-1495                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1496                   [-1, 10]               0\n",
      "         Linear-1497                   [-1, 10]             110\n",
      "    BatchNorm1d-1498                   [-1, 10]              20\n",
      "           ReLU-1499                   [-1, 10]               0\n",
      "        Dropout-1500                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1501                   [-1, 10]               0\n",
      "         Linear-1502                   [-1, 10]             110\n",
      "    BatchNorm1d-1503                   [-1, 10]              20\n",
      "           ReLU-1504                   [-1, 10]               0\n",
      "        Dropout-1505                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1506                   [-1, 10]               0\n",
      "         Linear-1507                   [-1, 10]             110\n",
      "    BatchNorm1d-1508                   [-1, 10]              20\n",
      "           ReLU-1509                   [-1, 10]               0\n",
      "        Dropout-1510                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1511                   [-1, 10]               0\n",
      "         Linear-1512                   [-1, 10]             110\n",
      "        Softmax-1513                   [-1, 10]               0\n",
      "         Linear-1514                   [-1, 10]             110\n",
      "    BatchNorm1d-1515                   [-1, 10]              20\n",
      "           ReLU-1516                   [-1, 10]               0\n",
      "        Dropout-1517                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1518                   [-1, 10]               0\n",
      "         Linear-1519                   [-1, 10]             110\n",
      "    BatchNorm1d-1520                   [-1, 10]              20\n",
      "           ReLU-1521                   [-1, 10]               0\n",
      "        Dropout-1522                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1523                   [-1, 10]               0\n",
      "         Linear-1524                   [-1, 10]             110\n",
      "    BatchNorm1d-1525                   [-1, 10]              20\n",
      "           ReLU-1526                   [-1, 10]               0\n",
      "        Dropout-1527                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1528                   [-1, 10]               0\n",
      "         Linear-1529                   [-1, 10]             110\n",
      "    BatchNorm1d-1530                   [-1, 10]              20\n",
      "           ReLU-1531                   [-1, 10]               0\n",
      "        Dropout-1532                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1533                   [-1, 10]               0\n",
      "         Linear-1534                   [-1, 10]             110\n",
      "    BatchNorm1d-1535                   [-1, 10]              20\n",
      "           ReLU-1536                   [-1, 10]               0\n",
      "        Dropout-1537                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1538                   [-1, 10]               0\n",
      "         Linear-1539                   [-1, 10]             110\n",
      "        Softmax-1540                   [-1, 10]               0\n",
      "         Linear-1541                   [-1, 15]             165\n",
      "        Softmax-1542                   [-1, 15]               0\n",
      "         Linear-1543                   [-1, 10]             110\n",
      "    BatchNorm1d-1544                   [-1, 10]              20\n",
      "           ReLU-1545                   [-1, 10]               0\n",
      "        Dropout-1546                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1547                   [-1, 10]               0\n",
      "         Linear-1548                   [-1, 10]             110\n",
      "    BatchNorm1d-1549                   [-1, 10]              20\n",
      "           ReLU-1550                   [-1, 10]               0\n",
      "        Dropout-1551                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1552                   [-1, 10]               0\n",
      "         Linear-1553                   [-1, 10]             110\n",
      "    BatchNorm1d-1554                   [-1, 10]              20\n",
      "           ReLU-1555                   [-1, 10]               0\n",
      "        Dropout-1556                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1557                   [-1, 10]               0\n",
      "         Linear-1558                   [-1, 10]             110\n",
      "    BatchNorm1d-1559                   [-1, 10]              20\n",
      "           ReLU-1560                   [-1, 10]               0\n",
      "        Dropout-1561                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1562                   [-1, 10]               0\n",
      "         Linear-1563                   [-1, 10]             110\n",
      "    BatchNorm1d-1564                   [-1, 10]              20\n",
      "           ReLU-1565                   [-1, 10]               0\n",
      "        Dropout-1566                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1567                   [-1, 10]               0\n",
      "         Linear-1568                   [-1, 10]             110\n",
      "    BatchNorm1d-1569                   [-1, 10]              20\n",
      "           ReLU-1570                   [-1, 10]               0\n",
      "        Dropout-1571                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1572                   [-1, 10]               0\n",
      "         Linear-1573                   [-1, 10]             110\n",
      "    BatchNorm1d-1574                   [-1, 10]              20\n",
      "           ReLU-1575                   [-1, 10]               0\n",
      "        Dropout-1576                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1577                   [-1, 10]               0\n",
      "         Linear-1578                   [-1, 10]             110\n",
      "    BatchNorm1d-1579                   [-1, 10]              20\n",
      "           ReLU-1580                   [-1, 10]               0\n",
      "        Dropout-1581                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1582                   [-1, 10]               0\n",
      "         Linear-1583                   [-1, 10]             110\n",
      "    BatchNorm1d-1584                   [-1, 10]              20\n",
      "           ReLU-1585                   [-1, 10]               0\n",
      "        Dropout-1586                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1587                   [-1, 10]               0\n",
      "         Linear-1588                   [-1, 10]             110\n",
      "    BatchNorm1d-1589                   [-1, 10]              20\n",
      "           ReLU-1590                   [-1, 10]               0\n",
      "        Dropout-1591                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1592                   [-1, 10]               0\n",
      "         Linear-1593                   [-1, 10]             110\n",
      "        Softmax-1594                   [-1, 10]               0\n",
      "         Linear-1595                   [-1, 10]             110\n",
      "    BatchNorm1d-1596                   [-1, 10]              20\n",
      "           ReLU-1597                   [-1, 10]               0\n",
      "        Dropout-1598                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1599                   [-1, 10]               0\n",
      "         Linear-1600                   [-1, 10]             110\n",
      "    BatchNorm1d-1601                   [-1, 10]              20\n",
      "           ReLU-1602                   [-1, 10]               0\n",
      "        Dropout-1603                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1604                   [-1, 10]               0\n",
      "         Linear-1605                   [-1, 10]             110\n",
      "    BatchNorm1d-1606                   [-1, 10]              20\n",
      "           ReLU-1607                   [-1, 10]               0\n",
      "        Dropout-1608                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1609                   [-1, 10]               0\n",
      "         Linear-1610                   [-1, 10]             110\n",
      "    BatchNorm1d-1611                   [-1, 10]              20\n",
      "           ReLU-1612                   [-1, 10]               0\n",
      "        Dropout-1613                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1614                   [-1, 10]               0\n",
      "         Linear-1615                   [-1, 10]             110\n",
      "    BatchNorm1d-1616                   [-1, 10]              20\n",
      "           ReLU-1617                   [-1, 10]               0\n",
      "        Dropout-1618                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1619                   [-1, 10]               0\n",
      "         Linear-1620                   [-1, 10]             110\n",
      "        Softmax-1621                   [-1, 10]               0\n",
      "         Linear-1622                   [-1, 15]             165\n",
      "        Softmax-1623                   [-1, 15]               0\n",
      "         Linear-1624                   [-1, 10]             110\n",
      "    BatchNorm1d-1625                   [-1, 10]              20\n",
      "           ReLU-1626                   [-1, 10]               0\n",
      "        Dropout-1627                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1628                   [-1, 10]               0\n",
      "         Linear-1629                   [-1, 10]             110\n",
      "    BatchNorm1d-1630                   [-1, 10]              20\n",
      "           ReLU-1631                   [-1, 10]               0\n",
      "        Dropout-1632                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1633                   [-1, 10]               0\n",
      "         Linear-1634                   [-1, 10]             110\n",
      "    BatchNorm1d-1635                   [-1, 10]              20\n",
      "           ReLU-1636                   [-1, 10]               0\n",
      "        Dropout-1637                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1638                   [-1, 10]               0\n",
      "         Linear-1639                   [-1, 10]             110\n",
      "    BatchNorm1d-1640                   [-1, 10]              20\n",
      "           ReLU-1641                   [-1, 10]               0\n",
      "        Dropout-1642                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1643                   [-1, 10]               0\n",
      "         Linear-1644                   [-1, 10]             110\n",
      "    BatchNorm1d-1645                   [-1, 10]              20\n",
      "           ReLU-1646                   [-1, 10]               0\n",
      "        Dropout-1647                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1648                   [-1, 10]               0\n",
      "         Linear-1649                   [-1, 10]             110\n",
      "    BatchNorm1d-1650                   [-1, 10]              20\n",
      "           ReLU-1651                   [-1, 10]               0\n",
      "        Dropout-1652                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1653                   [-1, 10]               0\n",
      "         Linear-1654                   [-1, 10]             110\n",
      "    BatchNorm1d-1655                   [-1, 10]              20\n",
      "           ReLU-1656                   [-1, 10]               0\n",
      "        Dropout-1657                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1658                   [-1, 10]               0\n",
      "         Linear-1659                   [-1, 10]             110\n",
      "    BatchNorm1d-1660                   [-1, 10]              20\n",
      "           ReLU-1661                   [-1, 10]               0\n",
      "        Dropout-1662                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1663                   [-1, 10]               0\n",
      "         Linear-1664                   [-1, 10]             110\n",
      "    BatchNorm1d-1665                   [-1, 10]              20\n",
      "           ReLU-1666                   [-1, 10]               0\n",
      "        Dropout-1667                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1668                   [-1, 10]               0\n",
      "         Linear-1669                   [-1, 10]             110\n",
      "    BatchNorm1d-1670                   [-1, 10]              20\n",
      "           ReLU-1671                   [-1, 10]               0\n",
      "        Dropout-1672                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1673                   [-1, 10]               0\n",
      "         Linear-1674                   [-1, 10]             110\n",
      "        Softmax-1675                   [-1, 10]               0\n",
      "         Linear-1676                   [-1, 10]             110\n",
      "    BatchNorm1d-1677                   [-1, 10]              20\n",
      "           ReLU-1678                   [-1, 10]               0\n",
      "        Dropout-1679                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1680                   [-1, 10]               0\n",
      "         Linear-1681                   [-1, 10]             110\n",
      "    BatchNorm1d-1682                   [-1, 10]              20\n",
      "           ReLU-1683                   [-1, 10]               0\n",
      "        Dropout-1684                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1685                   [-1, 10]               0\n",
      "         Linear-1686                   [-1, 10]             110\n",
      "    BatchNorm1d-1687                   [-1, 10]              20\n",
      "           ReLU-1688                   [-1, 10]               0\n",
      "        Dropout-1689                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1690                   [-1, 10]               0\n",
      "         Linear-1691                   [-1, 10]             110\n",
      "    BatchNorm1d-1692                   [-1, 10]              20\n",
      "           ReLU-1693                   [-1, 10]               0\n",
      "        Dropout-1694                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1695                   [-1, 10]               0\n",
      "         Linear-1696                   [-1, 10]             110\n",
      "    BatchNorm1d-1697                   [-1, 10]              20\n",
      "           ReLU-1698                   [-1, 10]               0\n",
      "        Dropout-1699                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1700                   [-1, 10]               0\n",
      "         Linear-1701                   [-1, 10]             110\n",
      "        Softmax-1702                   [-1, 10]               0\n",
      "         Linear-1703                   [-1, 15]             165\n",
      "        Softmax-1704                   [-1, 15]               0\n",
      "         Linear-1705                   [-1, 10]             110\n",
      "    BatchNorm1d-1706                   [-1, 10]              20\n",
      "           ReLU-1707                   [-1, 10]               0\n",
      "        Dropout-1708                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1709                   [-1, 10]               0\n",
      "         Linear-1710                   [-1, 10]             110\n",
      "    BatchNorm1d-1711                   [-1, 10]              20\n",
      "           ReLU-1712                   [-1, 10]               0\n",
      "        Dropout-1713                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1714                   [-1, 10]               0\n",
      "         Linear-1715                   [-1, 10]             110\n",
      "    BatchNorm1d-1716                   [-1, 10]              20\n",
      "           ReLU-1717                   [-1, 10]               0\n",
      "        Dropout-1718                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1719                   [-1, 10]               0\n",
      "         Linear-1720                   [-1, 10]             110\n",
      "    BatchNorm1d-1721                   [-1, 10]              20\n",
      "           ReLU-1722                   [-1, 10]               0\n",
      "        Dropout-1723                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1724                   [-1, 10]               0\n",
      "         Linear-1725                   [-1, 10]             110\n",
      "    BatchNorm1d-1726                   [-1, 10]              20\n",
      "           ReLU-1727                   [-1, 10]               0\n",
      "        Dropout-1728                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1729                   [-1, 10]               0\n",
      "         Linear-1730                   [-1, 10]             110\n",
      "    BatchNorm1d-1731                   [-1, 10]              20\n",
      "           ReLU-1732                   [-1, 10]               0\n",
      "        Dropout-1733                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1734                   [-1, 10]               0\n",
      "         Linear-1735                   [-1, 10]             110\n",
      "    BatchNorm1d-1736                   [-1, 10]              20\n",
      "           ReLU-1737                   [-1, 10]               0\n",
      "        Dropout-1738                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1739                   [-1, 10]               0\n",
      "         Linear-1740                   [-1, 10]             110\n",
      "    BatchNorm1d-1741                   [-1, 10]              20\n",
      "           ReLU-1742                   [-1, 10]               0\n",
      "        Dropout-1743                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1744                   [-1, 10]               0\n",
      "         Linear-1745                   [-1, 10]             110\n",
      "    BatchNorm1d-1746                   [-1, 10]              20\n",
      "           ReLU-1747                   [-1, 10]               0\n",
      "        Dropout-1748                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1749                   [-1, 10]               0\n",
      "         Linear-1750                   [-1, 10]             110\n",
      "    BatchNorm1d-1751                   [-1, 10]              20\n",
      "           ReLU-1752                   [-1, 10]               0\n",
      "        Dropout-1753                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1754                   [-1, 10]               0\n",
      "         Linear-1755                   [-1, 10]             110\n",
      "        Softmax-1756                   [-1, 10]               0\n",
      "         Linear-1757                   [-1, 10]             110\n",
      "    BatchNorm1d-1758                   [-1, 10]              20\n",
      "           ReLU-1759                   [-1, 10]               0\n",
      "        Dropout-1760                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1761                   [-1, 10]               0\n",
      "         Linear-1762                   [-1, 10]             110\n",
      "    BatchNorm1d-1763                   [-1, 10]              20\n",
      "           ReLU-1764                   [-1, 10]               0\n",
      "        Dropout-1765                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1766                   [-1, 10]               0\n",
      "         Linear-1767                   [-1, 10]             110\n",
      "    BatchNorm1d-1768                   [-1, 10]              20\n",
      "           ReLU-1769                   [-1, 10]               0\n",
      "        Dropout-1770                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1771                   [-1, 10]               0\n",
      "         Linear-1772                   [-1, 10]             110\n",
      "    BatchNorm1d-1773                   [-1, 10]              20\n",
      "           ReLU-1774                   [-1, 10]               0\n",
      "        Dropout-1775                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1776                   [-1, 10]               0\n",
      "         Linear-1777                   [-1, 10]             110\n",
      "    BatchNorm1d-1778                   [-1, 10]              20\n",
      "           ReLU-1779                   [-1, 10]               0\n",
      "        Dropout-1780                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1781                   [-1, 10]               0\n",
      "         Linear-1782                   [-1, 10]             110\n",
      "        Softmax-1783                   [-1, 10]               0\n",
      "         Linear-1784                   [-1, 15]             165\n",
      "        Softmax-1785                   [-1, 15]               0\n",
      "         Linear-1786                   [-1, 10]             110\n",
      "    BatchNorm1d-1787                   [-1, 10]              20\n",
      "           ReLU-1788                   [-1, 10]               0\n",
      "        Dropout-1789                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1790                   [-1, 10]               0\n",
      "         Linear-1791                   [-1, 10]             110\n",
      "    BatchNorm1d-1792                   [-1, 10]              20\n",
      "           ReLU-1793                   [-1, 10]               0\n",
      "        Dropout-1794                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1795                   [-1, 10]               0\n",
      "         Linear-1796                   [-1, 10]             110\n",
      "    BatchNorm1d-1797                   [-1, 10]              20\n",
      "           ReLU-1798                   [-1, 10]               0\n",
      "        Dropout-1799                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1800                   [-1, 10]               0\n",
      "         Linear-1801                   [-1, 10]             110\n",
      "    BatchNorm1d-1802                   [-1, 10]              20\n",
      "           ReLU-1803                   [-1, 10]               0\n",
      "        Dropout-1804                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1805                   [-1, 10]               0\n",
      "         Linear-1806                   [-1, 10]             110\n",
      "    BatchNorm1d-1807                   [-1, 10]              20\n",
      "           ReLU-1808                   [-1, 10]               0\n",
      "        Dropout-1809                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1810                   [-1, 10]               0\n",
      "         Linear-1811                   [-1, 10]             110\n",
      "    BatchNorm1d-1812                   [-1, 10]              20\n",
      "           ReLU-1813                   [-1, 10]               0\n",
      "        Dropout-1814                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1815                   [-1, 10]               0\n",
      "         Linear-1816                   [-1, 10]             110\n",
      "    BatchNorm1d-1817                   [-1, 10]              20\n",
      "           ReLU-1818                   [-1, 10]               0\n",
      "        Dropout-1819                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1820                   [-1, 10]               0\n",
      "         Linear-1821                   [-1, 10]             110\n",
      "    BatchNorm1d-1822                   [-1, 10]              20\n",
      "           ReLU-1823                   [-1, 10]               0\n",
      "        Dropout-1824                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1825                   [-1, 10]               0\n",
      "         Linear-1826                   [-1, 10]             110\n",
      "    BatchNorm1d-1827                   [-1, 10]              20\n",
      "           ReLU-1828                   [-1, 10]               0\n",
      "        Dropout-1829                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1830                   [-1, 10]               0\n",
      "         Linear-1831                   [-1, 10]             110\n",
      "    BatchNorm1d-1832                   [-1, 10]              20\n",
      "           ReLU-1833                   [-1, 10]               0\n",
      "        Dropout-1834                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1835                   [-1, 10]               0\n",
      "         Linear-1836                   [-1, 10]             110\n",
      "        Softmax-1837                   [-1, 10]               0\n",
      "         Linear-1838                   [-1, 10]             110\n",
      "    BatchNorm1d-1839                   [-1, 10]              20\n",
      "           ReLU-1840                   [-1, 10]               0\n",
      "        Dropout-1841                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1842                   [-1, 10]               0\n",
      "         Linear-1843                   [-1, 10]             110\n",
      "    BatchNorm1d-1844                   [-1, 10]              20\n",
      "           ReLU-1845                   [-1, 10]               0\n",
      "        Dropout-1846                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1847                   [-1, 10]               0\n",
      "         Linear-1848                   [-1, 10]             110\n",
      "    BatchNorm1d-1849                   [-1, 10]              20\n",
      "           ReLU-1850                   [-1, 10]               0\n",
      "        Dropout-1851                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1852                   [-1, 10]               0\n",
      "         Linear-1853                   [-1, 10]             110\n",
      "    BatchNorm1d-1854                   [-1, 10]              20\n",
      "           ReLU-1855                   [-1, 10]               0\n",
      "        Dropout-1856                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1857                   [-1, 10]               0\n",
      "         Linear-1858                   [-1, 10]             110\n",
      "    BatchNorm1d-1859                   [-1, 10]              20\n",
      "           ReLU-1860                   [-1, 10]               0\n",
      "        Dropout-1861                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1862                   [-1, 10]               0\n",
      "         Linear-1863                   [-1, 10]             110\n",
      "        Softmax-1864                   [-1, 10]               0\n",
      "         Linear-1865                   [-1, 15]             165\n",
      "        Softmax-1866                   [-1, 15]               0\n",
      "         Linear-1867                   [-1, 10]             110\n",
      "    BatchNorm1d-1868                   [-1, 10]              20\n",
      "           ReLU-1869                   [-1, 10]               0\n",
      "        Dropout-1870                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1871                   [-1, 10]               0\n",
      "         Linear-1872                   [-1, 10]             110\n",
      "    BatchNorm1d-1873                   [-1, 10]              20\n",
      "           ReLU-1874                   [-1, 10]               0\n",
      "        Dropout-1875                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1876                   [-1, 10]               0\n",
      "         Linear-1877                   [-1, 10]             110\n",
      "    BatchNorm1d-1878                   [-1, 10]              20\n",
      "           ReLU-1879                   [-1, 10]               0\n",
      "        Dropout-1880                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1881                   [-1, 10]               0\n",
      "         Linear-1882                   [-1, 10]             110\n",
      "    BatchNorm1d-1883                   [-1, 10]              20\n",
      "           ReLU-1884                   [-1, 10]               0\n",
      "        Dropout-1885                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1886                   [-1, 10]               0\n",
      "         Linear-1887                   [-1, 10]             110\n",
      "    BatchNorm1d-1888                   [-1, 10]              20\n",
      "           ReLU-1889                   [-1, 10]               0\n",
      "        Dropout-1890                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1891                   [-1, 10]               0\n",
      "         Linear-1892                   [-1, 10]             110\n",
      "    BatchNorm1d-1893                   [-1, 10]              20\n",
      "           ReLU-1894                   [-1, 10]               0\n",
      "        Dropout-1895                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1896                   [-1, 10]               0\n",
      "         Linear-1897                   [-1, 10]             110\n",
      "    BatchNorm1d-1898                   [-1, 10]              20\n",
      "           ReLU-1899                   [-1, 10]               0\n",
      "        Dropout-1900                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1901                   [-1, 10]               0\n",
      "         Linear-1902                   [-1, 10]             110\n",
      "    BatchNorm1d-1903                   [-1, 10]              20\n",
      "           ReLU-1904                   [-1, 10]               0\n",
      "        Dropout-1905                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1906                   [-1, 10]               0\n",
      "         Linear-1907                   [-1, 10]             110\n",
      "    BatchNorm1d-1908                   [-1, 10]              20\n",
      "           ReLU-1909                   [-1, 10]               0\n",
      "        Dropout-1910                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1911                   [-1, 10]               0\n",
      "         Linear-1912                   [-1, 10]             110\n",
      "    BatchNorm1d-1913                   [-1, 10]              20\n",
      "           ReLU-1914                   [-1, 10]               0\n",
      "        Dropout-1915                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1916                   [-1, 10]               0\n",
      "         Linear-1917                   [-1, 10]             110\n",
      "        Softmax-1918                   [-1, 10]               0\n",
      "         Linear-1919                   [-1, 10]             110\n",
      "    BatchNorm1d-1920                   [-1, 10]              20\n",
      "           ReLU-1921                   [-1, 10]               0\n",
      "        Dropout-1922                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1923                   [-1, 10]               0\n",
      "         Linear-1924                   [-1, 10]             110\n",
      "    BatchNorm1d-1925                   [-1, 10]              20\n",
      "           ReLU-1926                   [-1, 10]               0\n",
      "        Dropout-1927                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1928                   [-1, 10]               0\n",
      "         Linear-1929                   [-1, 10]             110\n",
      "    BatchNorm1d-1930                   [-1, 10]              20\n",
      "           ReLU-1931                   [-1, 10]               0\n",
      "        Dropout-1932                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1933                   [-1, 10]               0\n",
      "         Linear-1934                   [-1, 10]             110\n",
      "    BatchNorm1d-1935                   [-1, 10]              20\n",
      "           ReLU-1936                   [-1, 10]               0\n",
      "        Dropout-1937                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1938                   [-1, 10]               0\n",
      "         Linear-1939                   [-1, 10]             110\n",
      "    BatchNorm1d-1940                   [-1, 10]              20\n",
      "           ReLU-1941                   [-1, 10]               0\n",
      "        Dropout-1942                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1943                   [-1, 10]               0\n",
      "         Linear-1944                   [-1, 10]             110\n",
      "        Softmax-1945                   [-1, 10]               0\n",
      "         Linear-1946                   [-1, 15]             165\n",
      "        Softmax-1947                   [-1, 15]               0\n",
      "         Linear-1948                   [-1, 10]             110\n",
      "    BatchNorm1d-1949                   [-1, 10]              20\n",
      "           ReLU-1950                   [-1, 10]               0\n",
      "        Dropout-1951                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1952                   [-1, 10]               0\n",
      "         Linear-1953                   [-1, 10]             110\n",
      "    BatchNorm1d-1954                   [-1, 10]              20\n",
      "           ReLU-1955                   [-1, 10]               0\n",
      "        Dropout-1956                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1957                   [-1, 10]               0\n",
      "         Linear-1958                   [-1, 10]             110\n",
      "    BatchNorm1d-1959                   [-1, 10]              20\n",
      "           ReLU-1960                   [-1, 10]               0\n",
      "        Dropout-1961                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1962                   [-1, 10]               0\n",
      "         Linear-1963                   [-1, 10]             110\n",
      "    BatchNorm1d-1964                   [-1, 10]              20\n",
      "           ReLU-1965                   [-1, 10]               0\n",
      "        Dropout-1966                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1967                   [-1, 10]               0\n",
      "         Linear-1968                   [-1, 10]             110\n",
      "    BatchNorm1d-1969                   [-1, 10]              20\n",
      "           ReLU-1970                   [-1, 10]               0\n",
      "        Dropout-1971                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1972                   [-1, 10]               0\n",
      "         Linear-1973                   [-1, 10]             110\n",
      "    BatchNorm1d-1974                   [-1, 10]              20\n",
      "           ReLU-1975                   [-1, 10]               0\n",
      "        Dropout-1976                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1977                   [-1, 10]               0\n",
      "         Linear-1978                   [-1, 10]             110\n",
      "    BatchNorm1d-1979                   [-1, 10]              20\n",
      "           ReLU-1980                   [-1, 10]               0\n",
      "        Dropout-1981                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1982                   [-1, 10]               0\n",
      "         Linear-1983                   [-1, 10]             110\n",
      "    BatchNorm1d-1984                   [-1, 10]              20\n",
      "           ReLU-1985                   [-1, 10]               0\n",
      "        Dropout-1986                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1987                   [-1, 10]               0\n",
      "         Linear-1988                   [-1, 10]             110\n",
      "    BatchNorm1d-1989                   [-1, 10]              20\n",
      "           ReLU-1990                   [-1, 10]               0\n",
      "        Dropout-1991                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1992                   [-1, 10]               0\n",
      "         Linear-1993                   [-1, 10]             110\n",
      "    BatchNorm1d-1994                   [-1, 10]              20\n",
      "           ReLU-1995                   [-1, 10]               0\n",
      "        Dropout-1996                   [-1, 10]               0\n",
      "MultiLayerPerceptron-1997                   [-1, 10]               0\n",
      "         Linear-1998                   [-1, 10]             110\n",
      "        Softmax-1999                   [-1, 10]               0\n",
      "         Linear-2000                   [-1, 10]             110\n",
      "    BatchNorm1d-2001                   [-1, 10]              20\n",
      "           ReLU-2002                   [-1, 10]               0\n",
      "        Dropout-2003                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2004                   [-1, 10]               0\n",
      "         Linear-2005                   [-1, 10]             110\n",
      "    BatchNorm1d-2006                   [-1, 10]              20\n",
      "           ReLU-2007                   [-1, 10]               0\n",
      "        Dropout-2008                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2009                   [-1, 10]               0\n",
      "         Linear-2010                   [-1, 10]             110\n",
      "    BatchNorm1d-2011                   [-1, 10]              20\n",
      "           ReLU-2012                   [-1, 10]               0\n",
      "        Dropout-2013                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2014                   [-1, 10]               0\n",
      "         Linear-2015                   [-1, 10]             110\n",
      "    BatchNorm1d-2016                   [-1, 10]              20\n",
      "           ReLU-2017                   [-1, 10]               0\n",
      "        Dropout-2018                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2019                   [-1, 10]               0\n",
      "         Linear-2020                   [-1, 10]             110\n",
      "    BatchNorm1d-2021                   [-1, 10]              20\n",
      "           ReLU-2022                   [-1, 10]               0\n",
      "        Dropout-2023                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2024                   [-1, 10]               0\n",
      "         Linear-2025                   [-1, 10]             110\n",
      "        Softmax-2026                   [-1, 10]               0\n",
      "         Linear-2027                   [-1, 15]             165\n",
      "        Softmax-2028                   [-1, 15]               0\n",
      "         Linear-2029                   [-1, 10]             110\n",
      "    BatchNorm1d-2030                   [-1, 10]              20\n",
      "           ReLU-2031                   [-1, 10]               0\n",
      "        Dropout-2032                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2033                   [-1, 10]               0\n",
      "         Linear-2034                   [-1, 10]             110\n",
      "    BatchNorm1d-2035                   [-1, 10]              20\n",
      "           ReLU-2036                   [-1, 10]               0\n",
      "        Dropout-2037                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2038                   [-1, 10]               0\n",
      "         Linear-2039                   [-1, 10]             110\n",
      "    BatchNorm1d-2040                   [-1, 10]              20\n",
      "           ReLU-2041                   [-1, 10]               0\n",
      "        Dropout-2042                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2043                   [-1, 10]               0\n",
      "         Linear-2044                   [-1, 10]             110\n",
      "    BatchNorm1d-2045                   [-1, 10]              20\n",
      "           ReLU-2046                   [-1, 10]               0\n",
      "        Dropout-2047                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2048                   [-1, 10]               0\n",
      "         Linear-2049                   [-1, 10]             110\n",
      "    BatchNorm1d-2050                   [-1, 10]              20\n",
      "           ReLU-2051                   [-1, 10]               0\n",
      "        Dropout-2052                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2053                   [-1, 10]               0\n",
      "         Linear-2054                   [-1, 10]             110\n",
      "    BatchNorm1d-2055                   [-1, 10]              20\n",
      "           ReLU-2056                   [-1, 10]               0\n",
      "        Dropout-2057                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2058                   [-1, 10]               0\n",
      "         Linear-2059                   [-1, 10]             110\n",
      "    BatchNorm1d-2060                   [-1, 10]              20\n",
      "           ReLU-2061                   [-1, 10]               0\n",
      "        Dropout-2062                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2063                   [-1, 10]               0\n",
      "         Linear-2064                   [-1, 10]             110\n",
      "    BatchNorm1d-2065                   [-1, 10]              20\n",
      "           ReLU-2066                   [-1, 10]               0\n",
      "        Dropout-2067                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2068                   [-1, 10]               0\n",
      "         Linear-2069                   [-1, 10]             110\n",
      "    BatchNorm1d-2070                   [-1, 10]              20\n",
      "           ReLU-2071                   [-1, 10]               0\n",
      "        Dropout-2072                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2073                   [-1, 10]               0\n",
      "         Linear-2074                   [-1, 10]             110\n",
      "    BatchNorm1d-2075                   [-1, 10]              20\n",
      "           ReLU-2076                   [-1, 10]               0\n",
      "        Dropout-2077                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2078                   [-1, 10]               0\n",
      "         Linear-2079                   [-1, 10]             110\n",
      "        Softmax-2080                   [-1, 10]               0\n",
      "         Linear-2081                   [-1, 10]             110\n",
      "    BatchNorm1d-2082                   [-1, 10]              20\n",
      "           ReLU-2083                   [-1, 10]               0\n",
      "        Dropout-2084                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2085                   [-1, 10]               0\n",
      "         Linear-2086                   [-1, 10]             110\n",
      "    BatchNorm1d-2087                   [-1, 10]              20\n",
      "           ReLU-2088                   [-1, 10]               0\n",
      "        Dropout-2089                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2090                   [-1, 10]               0\n",
      "         Linear-2091                   [-1, 10]             110\n",
      "    BatchNorm1d-2092                   [-1, 10]              20\n",
      "           ReLU-2093                   [-1, 10]               0\n",
      "        Dropout-2094                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2095                   [-1, 10]               0\n",
      "         Linear-2096                   [-1, 10]             110\n",
      "    BatchNorm1d-2097                   [-1, 10]              20\n",
      "           ReLU-2098                   [-1, 10]               0\n",
      "        Dropout-2099                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2100                   [-1, 10]               0\n",
      "         Linear-2101                   [-1, 10]             110\n",
      "    BatchNorm1d-2102                   [-1, 10]              20\n",
      "           ReLU-2103                   [-1, 10]               0\n",
      "        Dropout-2104                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2105                   [-1, 10]               0\n",
      "         Linear-2106                   [-1, 10]             110\n",
      "        Softmax-2107                   [-1, 10]               0\n",
      "         Linear-2108                   [-1, 15]             165\n",
      "        Softmax-2109                   [-1, 15]               0\n",
      "         Linear-2110                   [-1, 10]             110\n",
      "    BatchNorm1d-2111                   [-1, 10]              20\n",
      "           ReLU-2112                   [-1, 10]               0\n",
      "        Dropout-2113                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2114                   [-1, 10]               0\n",
      "         Linear-2115                   [-1, 10]             110\n",
      "    BatchNorm1d-2116                   [-1, 10]              20\n",
      "           ReLU-2117                   [-1, 10]               0\n",
      "        Dropout-2118                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2119                   [-1, 10]               0\n",
      "         Linear-2120                   [-1, 10]             110\n",
      "    BatchNorm1d-2121                   [-1, 10]              20\n",
      "           ReLU-2122                   [-1, 10]               0\n",
      "        Dropout-2123                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2124                   [-1, 10]               0\n",
      "         Linear-2125                   [-1, 10]             110\n",
      "    BatchNorm1d-2126                   [-1, 10]              20\n",
      "           ReLU-2127                   [-1, 10]               0\n",
      "        Dropout-2128                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2129                   [-1, 10]               0\n",
      "         Linear-2130                   [-1, 10]             110\n",
      "    BatchNorm1d-2131                   [-1, 10]              20\n",
      "           ReLU-2132                   [-1, 10]               0\n",
      "        Dropout-2133                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2134                   [-1, 10]               0\n",
      "         Linear-2135                   [-1, 10]             110\n",
      "    BatchNorm1d-2136                   [-1, 10]              20\n",
      "           ReLU-2137                   [-1, 10]               0\n",
      "        Dropout-2138                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2139                   [-1, 10]               0\n",
      "         Linear-2140                   [-1, 10]             110\n",
      "    BatchNorm1d-2141                   [-1, 10]              20\n",
      "           ReLU-2142                   [-1, 10]               0\n",
      "        Dropout-2143                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2144                   [-1, 10]               0\n",
      "         Linear-2145                   [-1, 10]             110\n",
      "    BatchNorm1d-2146                   [-1, 10]              20\n",
      "           ReLU-2147                   [-1, 10]               0\n",
      "        Dropout-2148                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2149                   [-1, 10]               0\n",
      "         Linear-2150                   [-1, 10]             110\n",
      "    BatchNorm1d-2151                   [-1, 10]              20\n",
      "           ReLU-2152                   [-1, 10]               0\n",
      "        Dropout-2153                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2154                   [-1, 10]               0\n",
      "         Linear-2155                   [-1, 10]             110\n",
      "    BatchNorm1d-2156                   [-1, 10]              20\n",
      "           ReLU-2157                   [-1, 10]               0\n",
      "        Dropout-2158                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2159                   [-1, 10]               0\n",
      "         Linear-2160                   [-1, 10]             110\n",
      "        Softmax-2161                   [-1, 10]               0\n",
      "         Linear-2162                   [-1, 10]             110\n",
      "    BatchNorm1d-2163                   [-1, 10]              20\n",
      "           ReLU-2164                   [-1, 10]               0\n",
      "        Dropout-2165                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2166                   [-1, 10]               0\n",
      "         Linear-2167                   [-1, 10]             110\n",
      "    BatchNorm1d-2168                   [-1, 10]              20\n",
      "           ReLU-2169                   [-1, 10]               0\n",
      "        Dropout-2170                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2171                   [-1, 10]               0\n",
      "         Linear-2172                   [-1, 10]             110\n",
      "    BatchNorm1d-2173                   [-1, 10]              20\n",
      "           ReLU-2174                   [-1, 10]               0\n",
      "        Dropout-2175                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2176                   [-1, 10]               0\n",
      "         Linear-2177                   [-1, 10]             110\n",
      "    BatchNorm1d-2178                   [-1, 10]              20\n",
      "           ReLU-2179                   [-1, 10]               0\n",
      "        Dropout-2180                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2181                   [-1, 10]               0\n",
      "         Linear-2182                   [-1, 10]             110\n",
      "    BatchNorm1d-2183                   [-1, 10]              20\n",
      "           ReLU-2184                   [-1, 10]               0\n",
      "        Dropout-2185                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2186                   [-1, 10]               0\n",
      "         Linear-2187                   [-1, 10]             110\n",
      "        Softmax-2188                   [-1, 10]               0\n",
      "         Linear-2189                   [-1, 15]             165\n",
      "        Softmax-2190                   [-1, 15]               0\n",
      "         Linear-2191                   [-1, 10]             110\n",
      "    BatchNorm1d-2192                   [-1, 10]              20\n",
      "           ReLU-2193                   [-1, 10]               0\n",
      "        Dropout-2194                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2195                   [-1, 10]               0\n",
      "         Linear-2196                   [-1, 10]             110\n",
      "    BatchNorm1d-2197                   [-1, 10]              20\n",
      "           ReLU-2198                   [-1, 10]               0\n",
      "        Dropout-2199                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2200                   [-1, 10]               0\n",
      "         Linear-2201                   [-1, 10]             110\n",
      "    BatchNorm1d-2202                   [-1, 10]              20\n",
      "           ReLU-2203                   [-1, 10]               0\n",
      "        Dropout-2204                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2205                   [-1, 10]               0\n",
      "         Linear-2206                   [-1, 10]             110\n",
      "    BatchNorm1d-2207                   [-1, 10]              20\n",
      "           ReLU-2208                   [-1, 10]               0\n",
      "        Dropout-2209                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2210                   [-1, 10]               0\n",
      "         Linear-2211                   [-1, 10]             110\n",
      "    BatchNorm1d-2212                   [-1, 10]              20\n",
      "           ReLU-2213                   [-1, 10]               0\n",
      "        Dropout-2214                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2215                   [-1, 10]               0\n",
      "         Linear-2216                   [-1, 10]             110\n",
      "    BatchNorm1d-2217                   [-1, 10]              20\n",
      "           ReLU-2218                   [-1, 10]               0\n",
      "        Dropout-2219                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2220                   [-1, 10]               0\n",
      "         Linear-2221                   [-1, 10]             110\n",
      "    BatchNorm1d-2222                   [-1, 10]              20\n",
      "           ReLU-2223                   [-1, 10]               0\n",
      "        Dropout-2224                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2225                   [-1, 10]               0\n",
      "         Linear-2226                   [-1, 10]             110\n",
      "    BatchNorm1d-2227                   [-1, 10]              20\n",
      "           ReLU-2228                   [-1, 10]               0\n",
      "        Dropout-2229                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2230                   [-1, 10]               0\n",
      "         Linear-2231                   [-1, 10]             110\n",
      "    BatchNorm1d-2232                   [-1, 10]              20\n",
      "           ReLU-2233                   [-1, 10]               0\n",
      "        Dropout-2234                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2235                   [-1, 10]               0\n",
      "         Linear-2236                   [-1, 10]             110\n",
      "    BatchNorm1d-2237                   [-1, 10]              20\n",
      "           ReLU-2238                   [-1, 10]               0\n",
      "        Dropout-2239                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2240                   [-1, 10]               0\n",
      "         Linear-2241                   [-1, 10]             110\n",
      "        Softmax-2242                   [-1, 10]               0\n",
      "         Linear-2243                   [-1, 10]             110\n",
      "    BatchNorm1d-2244                   [-1, 10]              20\n",
      "           ReLU-2245                   [-1, 10]               0\n",
      "        Dropout-2246                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2247                   [-1, 10]               0\n",
      "         Linear-2248                   [-1, 10]             110\n",
      "    BatchNorm1d-2249                   [-1, 10]              20\n",
      "           ReLU-2250                   [-1, 10]               0\n",
      "        Dropout-2251                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2252                   [-1, 10]               0\n",
      "         Linear-2253                   [-1, 10]             110\n",
      "    BatchNorm1d-2254                   [-1, 10]              20\n",
      "           ReLU-2255                   [-1, 10]               0\n",
      "        Dropout-2256                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2257                   [-1, 10]               0\n",
      "         Linear-2258                   [-1, 10]             110\n",
      "    BatchNorm1d-2259                   [-1, 10]              20\n",
      "           ReLU-2260                   [-1, 10]               0\n",
      "        Dropout-2261                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2262                   [-1, 10]               0\n",
      "         Linear-2263                   [-1, 10]             110\n",
      "    BatchNorm1d-2264                   [-1, 10]              20\n",
      "           ReLU-2265                   [-1, 10]               0\n",
      "        Dropout-2266                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2267                   [-1, 10]               0\n",
      "         Linear-2268                   [-1, 10]             110\n",
      "        Softmax-2269                   [-1, 10]               0\n",
      "         Linear-2270                   [-1, 15]             165\n",
      "        Softmax-2271                   [-1, 15]               0\n",
      "         Linear-2272                   [-1, 10]             110\n",
      "    BatchNorm1d-2273                   [-1, 10]              20\n",
      "           ReLU-2274                   [-1, 10]               0\n",
      "        Dropout-2275                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2276                   [-1, 10]               0\n",
      "         Linear-2277                   [-1, 10]             110\n",
      "    BatchNorm1d-2278                   [-1, 10]              20\n",
      "           ReLU-2279                   [-1, 10]               0\n",
      "        Dropout-2280                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2281                   [-1, 10]               0\n",
      "         Linear-2282                   [-1, 10]             110\n",
      "    BatchNorm1d-2283                   [-1, 10]              20\n",
      "           ReLU-2284                   [-1, 10]               0\n",
      "        Dropout-2285                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2286                   [-1, 10]               0\n",
      "         Linear-2287                   [-1, 10]             110\n",
      "    BatchNorm1d-2288                   [-1, 10]              20\n",
      "           ReLU-2289                   [-1, 10]               0\n",
      "        Dropout-2290                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2291                   [-1, 10]               0\n",
      "         Linear-2292                   [-1, 10]             110\n",
      "    BatchNorm1d-2293                   [-1, 10]              20\n",
      "           ReLU-2294                   [-1, 10]               0\n",
      "        Dropout-2295                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2296                   [-1, 10]               0\n",
      "         Linear-2297                   [-1, 10]             110\n",
      "    BatchNorm1d-2298                   [-1, 10]              20\n",
      "           ReLU-2299                   [-1, 10]               0\n",
      "        Dropout-2300                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2301                   [-1, 10]               0\n",
      "         Linear-2302                   [-1, 10]             110\n",
      "    BatchNorm1d-2303                   [-1, 10]              20\n",
      "           ReLU-2304                   [-1, 10]               0\n",
      "        Dropout-2305                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2306                   [-1, 10]               0\n",
      "         Linear-2307                   [-1, 10]             110\n",
      "    BatchNorm1d-2308                   [-1, 10]              20\n",
      "           ReLU-2309                   [-1, 10]               0\n",
      "        Dropout-2310                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2311                   [-1, 10]               0\n",
      "         Linear-2312                   [-1, 10]             110\n",
      "    BatchNorm1d-2313                   [-1, 10]              20\n",
      "           ReLU-2314                   [-1, 10]               0\n",
      "        Dropout-2315                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2316                   [-1, 10]               0\n",
      "         Linear-2317                   [-1, 10]             110\n",
      "    BatchNorm1d-2318                   [-1, 10]              20\n",
      "           ReLU-2319                   [-1, 10]               0\n",
      "        Dropout-2320                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2321                   [-1, 10]               0\n",
      "         Linear-2322                   [-1, 10]             110\n",
      "        Softmax-2323                   [-1, 10]               0\n",
      "         Linear-2324                   [-1, 10]             110\n",
      "    BatchNorm1d-2325                   [-1, 10]              20\n",
      "           ReLU-2326                   [-1, 10]               0\n",
      "        Dropout-2327                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2328                   [-1, 10]               0\n",
      "         Linear-2329                   [-1, 10]             110\n",
      "    BatchNorm1d-2330                   [-1, 10]              20\n",
      "           ReLU-2331                   [-1, 10]               0\n",
      "        Dropout-2332                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2333                   [-1, 10]               0\n",
      "         Linear-2334                   [-1, 10]             110\n",
      "    BatchNorm1d-2335                   [-1, 10]              20\n",
      "           ReLU-2336                   [-1, 10]               0\n",
      "        Dropout-2337                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2338                   [-1, 10]               0\n",
      "         Linear-2339                   [-1, 10]             110\n",
      "    BatchNorm1d-2340                   [-1, 10]              20\n",
      "           ReLU-2341                   [-1, 10]               0\n",
      "        Dropout-2342                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2343                   [-1, 10]               0\n",
      "         Linear-2344                   [-1, 10]             110\n",
      "    BatchNorm1d-2345                   [-1, 10]              20\n",
      "           ReLU-2346                   [-1, 10]               0\n",
      "        Dropout-2347                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2348                   [-1, 10]               0\n",
      "         Linear-2349                   [-1, 10]             110\n",
      "        Softmax-2350                   [-1, 10]               0\n",
      "         Linear-2351                   [-1, 15]             165\n",
      "        Softmax-2352                   [-1, 15]               0\n",
      "         Linear-2353                   [-1, 10]             110\n",
      "    BatchNorm1d-2354                   [-1, 10]              20\n",
      "           ReLU-2355                   [-1, 10]               0\n",
      "        Dropout-2356                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2357                   [-1, 10]               0\n",
      "         Linear-2358                   [-1, 10]             110\n",
      "    BatchNorm1d-2359                   [-1, 10]              20\n",
      "           ReLU-2360                   [-1, 10]               0\n",
      "        Dropout-2361                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2362                   [-1, 10]               0\n",
      "         Linear-2363                   [-1, 10]             110\n",
      "    BatchNorm1d-2364                   [-1, 10]              20\n",
      "           ReLU-2365                   [-1, 10]               0\n",
      "        Dropout-2366                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2367                   [-1, 10]               0\n",
      "         Linear-2368                   [-1, 10]             110\n",
      "    BatchNorm1d-2369                   [-1, 10]              20\n",
      "           ReLU-2370                   [-1, 10]               0\n",
      "        Dropout-2371                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2372                   [-1, 10]               0\n",
      "         Linear-2373                   [-1, 10]             110\n",
      "    BatchNorm1d-2374                   [-1, 10]              20\n",
      "           ReLU-2375                   [-1, 10]               0\n",
      "        Dropout-2376                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2377                   [-1, 10]               0\n",
      "         Linear-2378                   [-1, 10]             110\n",
      "    BatchNorm1d-2379                   [-1, 10]              20\n",
      "           ReLU-2380                   [-1, 10]               0\n",
      "        Dropout-2381                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2382                   [-1, 10]               0\n",
      "         Linear-2383                   [-1, 10]             110\n",
      "    BatchNorm1d-2384                   [-1, 10]              20\n",
      "           ReLU-2385                   [-1, 10]               0\n",
      "        Dropout-2386                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2387                   [-1, 10]               0\n",
      "         Linear-2388                   [-1, 10]             110\n",
      "    BatchNorm1d-2389                   [-1, 10]              20\n",
      "           ReLU-2390                   [-1, 10]               0\n",
      "        Dropout-2391                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2392                   [-1, 10]               0\n",
      "         Linear-2393                   [-1, 10]             110\n",
      "    BatchNorm1d-2394                   [-1, 10]              20\n",
      "           ReLU-2395                   [-1, 10]               0\n",
      "        Dropout-2396                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2397                   [-1, 10]               0\n",
      "         Linear-2398                   [-1, 10]             110\n",
      "    BatchNorm1d-2399                   [-1, 10]              20\n",
      "           ReLU-2400                   [-1, 10]               0\n",
      "        Dropout-2401                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2402                   [-1, 10]               0\n",
      "         Linear-2403                   [-1, 10]             110\n",
      "        Softmax-2404                   [-1, 10]               0\n",
      "         Linear-2405                   [-1, 10]             110\n",
      "    BatchNorm1d-2406                   [-1, 10]              20\n",
      "           ReLU-2407                   [-1, 10]               0\n",
      "        Dropout-2408                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2409                   [-1, 10]               0\n",
      "         Linear-2410                   [-1, 10]             110\n",
      "    BatchNorm1d-2411                   [-1, 10]              20\n",
      "           ReLU-2412                   [-1, 10]               0\n",
      "        Dropout-2413                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2414                   [-1, 10]               0\n",
      "         Linear-2415                   [-1, 10]             110\n",
      "    BatchNorm1d-2416                   [-1, 10]              20\n",
      "           ReLU-2417                   [-1, 10]               0\n",
      "        Dropout-2418                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2419                   [-1, 10]               0\n",
      "         Linear-2420                   [-1, 10]             110\n",
      "    BatchNorm1d-2421                   [-1, 10]              20\n",
      "           ReLU-2422                   [-1, 10]               0\n",
      "        Dropout-2423                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2424                   [-1, 10]               0\n",
      "         Linear-2425                   [-1, 10]             110\n",
      "    BatchNorm1d-2426                   [-1, 10]              20\n",
      "           ReLU-2427                   [-1, 10]               0\n",
      "        Dropout-2428                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2429                   [-1, 10]               0\n",
      "         Linear-2430                   [-1, 10]             110\n",
      "        Softmax-2431                   [-1, 10]               0\n",
      "         Linear-2432                   [-1, 15]             165\n",
      "        Softmax-2433                   [-1, 15]               0\n",
      "         Linear-2434                   [-1, 10]             110\n",
      "    BatchNorm1d-2435                   [-1, 10]              20\n",
      "           ReLU-2436                   [-1, 10]               0\n",
      "        Dropout-2437                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2438                   [-1, 10]               0\n",
      "         Linear-2439                   [-1, 10]             110\n",
      "    BatchNorm1d-2440                   [-1, 10]              20\n",
      "           ReLU-2441                   [-1, 10]               0\n",
      "        Dropout-2442                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2443                   [-1, 10]               0\n",
      "         Linear-2444                   [-1, 10]             110\n",
      "    BatchNorm1d-2445                   [-1, 10]              20\n",
      "           ReLU-2446                   [-1, 10]               0\n",
      "        Dropout-2447                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2448                   [-1, 10]               0\n",
      "         Linear-2449                   [-1, 10]             110\n",
      "    BatchNorm1d-2450                   [-1, 10]              20\n",
      "           ReLU-2451                   [-1, 10]               0\n",
      "        Dropout-2452                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2453                   [-1, 10]               0\n",
      "         Linear-2454                   [-1, 10]             110\n",
      "    BatchNorm1d-2455                   [-1, 10]              20\n",
      "           ReLU-2456                   [-1, 10]               0\n",
      "        Dropout-2457                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2458                   [-1, 10]               0\n",
      "         Linear-2459                   [-1, 10]             110\n",
      "    BatchNorm1d-2460                   [-1, 10]              20\n",
      "           ReLU-2461                   [-1, 10]               0\n",
      "        Dropout-2462                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2463                   [-1, 10]               0\n",
      "         Linear-2464                   [-1, 10]             110\n",
      "    BatchNorm1d-2465                   [-1, 10]              20\n",
      "           ReLU-2466                   [-1, 10]               0\n",
      "        Dropout-2467                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2468                   [-1, 10]               0\n",
      "         Linear-2469                   [-1, 10]             110\n",
      "    BatchNorm1d-2470                   [-1, 10]              20\n",
      "           ReLU-2471                   [-1, 10]               0\n",
      "        Dropout-2472                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2473                   [-1, 10]               0\n",
      "         Linear-2474                   [-1, 10]             110\n",
      "    BatchNorm1d-2475                   [-1, 10]              20\n",
      "           ReLU-2476                   [-1, 10]               0\n",
      "        Dropout-2477                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2478                   [-1, 10]               0\n",
      "         Linear-2479                   [-1, 10]             110\n",
      "    BatchNorm1d-2480                   [-1, 10]              20\n",
      "           ReLU-2481                   [-1, 10]               0\n",
      "        Dropout-2482                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2483                   [-1, 10]               0\n",
      "         Linear-2484                   [-1, 10]             110\n",
      "        Softmax-2485                   [-1, 10]               0\n",
      "         Linear-2486                   [-1, 10]             110\n",
      "    BatchNorm1d-2487                   [-1, 10]              20\n",
      "           ReLU-2488                   [-1, 10]               0\n",
      "        Dropout-2489                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2490                   [-1, 10]               0\n",
      "         Linear-2491                   [-1, 10]             110\n",
      "    BatchNorm1d-2492                   [-1, 10]              20\n",
      "           ReLU-2493                   [-1, 10]               0\n",
      "        Dropout-2494                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2495                   [-1, 10]               0\n",
      "         Linear-2496                   [-1, 10]             110\n",
      "    BatchNorm1d-2497                   [-1, 10]              20\n",
      "           ReLU-2498                   [-1, 10]               0\n",
      "        Dropout-2499                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2500                   [-1, 10]               0\n",
      "         Linear-2501                   [-1, 10]             110\n",
      "    BatchNorm1d-2502                   [-1, 10]              20\n",
      "           ReLU-2503                   [-1, 10]               0\n",
      "        Dropout-2504                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2505                   [-1, 10]               0\n",
      "         Linear-2506                   [-1, 10]             110\n",
      "    BatchNorm1d-2507                   [-1, 10]              20\n",
      "           ReLU-2508                   [-1, 10]               0\n",
      "        Dropout-2509                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2510                   [-1, 10]               0\n",
      "         Linear-2511                   [-1, 10]             110\n",
      "        Softmax-2512                   [-1, 10]               0\n",
      "         Linear-2513                   [-1, 15]             165\n",
      "        Softmax-2514                   [-1, 15]               0\n",
      "         Linear-2515                   [-1, 10]             110\n",
      "    BatchNorm1d-2516                   [-1, 10]              20\n",
      "           ReLU-2517                   [-1, 10]               0\n",
      "        Dropout-2518                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2519                   [-1, 10]               0\n",
      "         Linear-2520                   [-1, 10]             110\n",
      "    BatchNorm1d-2521                   [-1, 10]              20\n",
      "           ReLU-2522                   [-1, 10]               0\n",
      "        Dropout-2523                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2524                   [-1, 10]               0\n",
      "         Linear-2525                   [-1, 10]             110\n",
      "    BatchNorm1d-2526                   [-1, 10]              20\n",
      "           ReLU-2527                   [-1, 10]               0\n",
      "        Dropout-2528                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2529                   [-1, 10]               0\n",
      "         Linear-2530                   [-1, 10]             110\n",
      "    BatchNorm1d-2531                   [-1, 10]              20\n",
      "           ReLU-2532                   [-1, 10]               0\n",
      "        Dropout-2533                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2534                   [-1, 10]               0\n",
      "         Linear-2535                   [-1, 10]             110\n",
      "    BatchNorm1d-2536                   [-1, 10]              20\n",
      "           ReLU-2537                   [-1, 10]               0\n",
      "        Dropout-2538                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2539                   [-1, 10]               0\n",
      "         Linear-2540                   [-1, 10]             110\n",
      "    BatchNorm1d-2541                   [-1, 10]              20\n",
      "           ReLU-2542                   [-1, 10]               0\n",
      "        Dropout-2543                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2544                   [-1, 10]               0\n",
      "         Linear-2545                   [-1, 10]             110\n",
      "    BatchNorm1d-2546                   [-1, 10]              20\n",
      "           ReLU-2547                   [-1, 10]               0\n",
      "        Dropout-2548                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2549                   [-1, 10]               0\n",
      "         Linear-2550                   [-1, 10]             110\n",
      "    BatchNorm1d-2551                   [-1, 10]              20\n",
      "           ReLU-2552                   [-1, 10]               0\n",
      "        Dropout-2553                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2554                   [-1, 10]               0\n",
      "         Linear-2555                   [-1, 10]             110\n",
      "    BatchNorm1d-2556                   [-1, 10]              20\n",
      "           ReLU-2557                   [-1, 10]               0\n",
      "        Dropout-2558                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2559                   [-1, 10]               0\n",
      "         Linear-2560                   [-1, 10]             110\n",
      "    BatchNorm1d-2561                   [-1, 10]              20\n",
      "           ReLU-2562                   [-1, 10]               0\n",
      "        Dropout-2563                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2564                   [-1, 10]               0\n",
      "         Linear-2565                   [-1, 10]             110\n",
      "        Softmax-2566                   [-1, 10]               0\n",
      "         Linear-2567                   [-1, 10]             110\n",
      "    BatchNorm1d-2568                   [-1, 10]              20\n",
      "           ReLU-2569                   [-1, 10]               0\n",
      "        Dropout-2570                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2571                   [-1, 10]               0\n",
      "         Linear-2572                   [-1, 10]             110\n",
      "    BatchNorm1d-2573                   [-1, 10]              20\n",
      "           ReLU-2574                   [-1, 10]               0\n",
      "        Dropout-2575                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2576                   [-1, 10]               0\n",
      "         Linear-2577                   [-1, 10]             110\n",
      "    BatchNorm1d-2578                   [-1, 10]              20\n",
      "           ReLU-2579                   [-1, 10]               0\n",
      "        Dropout-2580                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2581                   [-1, 10]               0\n",
      "         Linear-2582                   [-1, 10]             110\n",
      "    BatchNorm1d-2583                   [-1, 10]              20\n",
      "           ReLU-2584                   [-1, 10]               0\n",
      "        Dropout-2585                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2586                   [-1, 10]               0\n",
      "         Linear-2587                   [-1, 10]             110\n",
      "    BatchNorm1d-2588                   [-1, 10]              20\n",
      "           ReLU-2589                   [-1, 10]               0\n",
      "        Dropout-2590                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2591                   [-1, 10]               0\n",
      "         Linear-2592                   [-1, 10]             110\n",
      "        Softmax-2593                   [-1, 10]               0\n",
      "         Linear-2594                   [-1, 15]             165\n",
      "        Softmax-2595                   [-1, 15]               0\n",
      "         Linear-2596                   [-1, 10]             110\n",
      "    BatchNorm1d-2597                   [-1, 10]              20\n",
      "           ReLU-2598                   [-1, 10]               0\n",
      "        Dropout-2599                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2600                   [-1, 10]               0\n",
      "         Linear-2601                   [-1, 10]             110\n",
      "    BatchNorm1d-2602                   [-1, 10]              20\n",
      "           ReLU-2603                   [-1, 10]               0\n",
      "        Dropout-2604                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2605                   [-1, 10]               0\n",
      "         Linear-2606                   [-1, 10]             110\n",
      "    BatchNorm1d-2607                   [-1, 10]              20\n",
      "           ReLU-2608                   [-1, 10]               0\n",
      "        Dropout-2609                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2610                   [-1, 10]               0\n",
      "         Linear-2611                   [-1, 10]             110\n",
      "    BatchNorm1d-2612                   [-1, 10]              20\n",
      "           ReLU-2613                   [-1, 10]               0\n",
      "        Dropout-2614                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2615                   [-1, 10]               0\n",
      "         Linear-2616                   [-1, 10]             110\n",
      "    BatchNorm1d-2617                   [-1, 10]              20\n",
      "           ReLU-2618                   [-1, 10]               0\n",
      "        Dropout-2619                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2620                   [-1, 10]               0\n",
      "         Linear-2621                   [-1, 10]             110\n",
      "    BatchNorm1d-2622                   [-1, 10]              20\n",
      "           ReLU-2623                   [-1, 10]               0\n",
      "        Dropout-2624                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2625                   [-1, 10]               0\n",
      "         Linear-2626                   [-1, 10]             110\n",
      "    BatchNorm1d-2627                   [-1, 10]              20\n",
      "           ReLU-2628                   [-1, 10]               0\n",
      "        Dropout-2629                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2630                   [-1, 10]               0\n",
      "         Linear-2631                   [-1, 10]             110\n",
      "    BatchNorm1d-2632                   [-1, 10]              20\n",
      "           ReLU-2633                   [-1, 10]               0\n",
      "        Dropout-2634                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2635                   [-1, 10]               0\n",
      "         Linear-2636                   [-1, 10]             110\n",
      "    BatchNorm1d-2637                   [-1, 10]              20\n",
      "           ReLU-2638                   [-1, 10]               0\n",
      "        Dropout-2639                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2640                   [-1, 10]               0\n",
      "         Linear-2641                   [-1, 10]             110\n",
      "    BatchNorm1d-2642                   [-1, 10]              20\n",
      "           ReLU-2643                   [-1, 10]               0\n",
      "        Dropout-2644                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2645                   [-1, 10]               0\n",
      "         Linear-2646                   [-1, 10]             110\n",
      "        Softmax-2647                   [-1, 10]               0\n",
      "         Linear-2648                   [-1, 10]             110\n",
      "    BatchNorm1d-2649                   [-1, 10]              20\n",
      "           ReLU-2650                   [-1, 10]               0\n",
      "        Dropout-2651                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2652                   [-1, 10]               0\n",
      "         Linear-2653                   [-1, 10]             110\n",
      "    BatchNorm1d-2654                   [-1, 10]              20\n",
      "           ReLU-2655                   [-1, 10]               0\n",
      "        Dropout-2656                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2657                   [-1, 10]               0\n",
      "         Linear-2658                   [-1, 10]             110\n",
      "    BatchNorm1d-2659                   [-1, 10]              20\n",
      "           ReLU-2660                   [-1, 10]               0\n",
      "        Dropout-2661                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2662                   [-1, 10]               0\n",
      "         Linear-2663                   [-1, 10]             110\n",
      "    BatchNorm1d-2664                   [-1, 10]              20\n",
      "           ReLU-2665                   [-1, 10]               0\n",
      "        Dropout-2666                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2667                   [-1, 10]               0\n",
      "         Linear-2668                   [-1, 10]             110\n",
      "    BatchNorm1d-2669                   [-1, 10]              20\n",
      "           ReLU-2670                   [-1, 10]               0\n",
      "        Dropout-2671                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2672                   [-1, 10]               0\n",
      "         Linear-2673                   [-1, 10]             110\n",
      "        Softmax-2674                   [-1, 10]               0\n",
      "         Linear-2675                   [-1, 15]             165\n",
      "        Softmax-2676                   [-1, 15]               0\n",
      "         Linear-2677                   [-1, 10]             110\n",
      "    BatchNorm1d-2678                   [-1, 10]              20\n",
      "           ReLU-2679                   [-1, 10]               0\n",
      "        Dropout-2680                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2681                   [-1, 10]               0\n",
      "         Linear-2682                   [-1, 10]             110\n",
      "    BatchNorm1d-2683                   [-1, 10]              20\n",
      "           ReLU-2684                   [-1, 10]               0\n",
      "        Dropout-2685                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2686                   [-1, 10]               0\n",
      "         Linear-2687                   [-1, 10]             110\n",
      "    BatchNorm1d-2688                   [-1, 10]              20\n",
      "           ReLU-2689                   [-1, 10]               0\n",
      "        Dropout-2690                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2691                   [-1, 10]               0\n",
      "         Linear-2692                   [-1, 10]             110\n",
      "    BatchNorm1d-2693                   [-1, 10]              20\n",
      "           ReLU-2694                   [-1, 10]               0\n",
      "        Dropout-2695                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2696                   [-1, 10]               0\n",
      "         Linear-2697                   [-1, 10]             110\n",
      "    BatchNorm1d-2698                   [-1, 10]              20\n",
      "           ReLU-2699                   [-1, 10]               0\n",
      "        Dropout-2700                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2701                   [-1, 10]               0\n",
      "         Linear-2702                   [-1, 10]             110\n",
      "    BatchNorm1d-2703                   [-1, 10]              20\n",
      "           ReLU-2704                   [-1, 10]               0\n",
      "        Dropout-2705                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2706                   [-1, 10]               0\n",
      "         Linear-2707                   [-1, 10]             110\n",
      "    BatchNorm1d-2708                   [-1, 10]              20\n",
      "           ReLU-2709                   [-1, 10]               0\n",
      "        Dropout-2710                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2711                   [-1, 10]               0\n",
      "         Linear-2712                   [-1, 10]             110\n",
      "    BatchNorm1d-2713                   [-1, 10]              20\n",
      "           ReLU-2714                   [-1, 10]               0\n",
      "        Dropout-2715                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2716                   [-1, 10]               0\n",
      "         Linear-2717                   [-1, 10]             110\n",
      "    BatchNorm1d-2718                   [-1, 10]              20\n",
      "           ReLU-2719                   [-1, 10]               0\n",
      "        Dropout-2720                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2721                   [-1, 10]               0\n",
      "         Linear-2722                   [-1, 10]             110\n",
      "    BatchNorm1d-2723                   [-1, 10]              20\n",
      "           ReLU-2724                   [-1, 10]               0\n",
      "        Dropout-2725                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2726                   [-1, 10]               0\n",
      "         Linear-2727                   [-1, 10]             110\n",
      "        Softmax-2728                   [-1, 10]               0\n",
      "         Linear-2729                   [-1, 10]             110\n",
      "    BatchNorm1d-2730                   [-1, 10]              20\n",
      "           ReLU-2731                   [-1, 10]               0\n",
      "        Dropout-2732                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2733                   [-1, 10]               0\n",
      "         Linear-2734                   [-1, 10]             110\n",
      "    BatchNorm1d-2735                   [-1, 10]              20\n",
      "           ReLU-2736                   [-1, 10]               0\n",
      "        Dropout-2737                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2738                   [-1, 10]               0\n",
      "         Linear-2739                   [-1, 10]             110\n",
      "    BatchNorm1d-2740                   [-1, 10]              20\n",
      "           ReLU-2741                   [-1, 10]               0\n",
      "        Dropout-2742                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2743                   [-1, 10]               0\n",
      "         Linear-2744                   [-1, 10]             110\n",
      "    BatchNorm1d-2745                   [-1, 10]              20\n",
      "           ReLU-2746                   [-1, 10]               0\n",
      "        Dropout-2747                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2748                   [-1, 10]               0\n",
      "         Linear-2749                   [-1, 10]             110\n",
      "    BatchNorm1d-2750                   [-1, 10]              20\n",
      "           ReLU-2751                   [-1, 10]               0\n",
      "        Dropout-2752                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2753                   [-1, 10]               0\n",
      "         Linear-2754                   [-1, 10]             110\n",
      "        Softmax-2755                   [-1, 10]               0\n",
      "         Linear-2756                   [-1, 15]             165\n",
      "        Softmax-2757                   [-1, 15]               0\n",
      "         Linear-2758                   [-1, 10]             110\n",
      "    BatchNorm1d-2759                   [-1, 10]              20\n",
      "           ReLU-2760                   [-1, 10]               0\n",
      "        Dropout-2761                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2762                   [-1, 10]               0\n",
      "         Linear-2763                   [-1, 10]             110\n",
      "    BatchNorm1d-2764                   [-1, 10]              20\n",
      "           ReLU-2765                   [-1, 10]               0\n",
      "        Dropout-2766                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2767                   [-1, 10]               0\n",
      "         Linear-2768                   [-1, 10]             110\n",
      "    BatchNorm1d-2769                   [-1, 10]              20\n",
      "           ReLU-2770                   [-1, 10]               0\n",
      "        Dropout-2771                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2772                   [-1, 10]               0\n",
      "         Linear-2773                   [-1, 10]             110\n",
      "    BatchNorm1d-2774                   [-1, 10]              20\n",
      "           ReLU-2775                   [-1, 10]               0\n",
      "        Dropout-2776                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2777                   [-1, 10]               0\n",
      "         Linear-2778                   [-1, 10]             110\n",
      "    BatchNorm1d-2779                   [-1, 10]              20\n",
      "           ReLU-2780                   [-1, 10]               0\n",
      "        Dropout-2781                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2782                   [-1, 10]               0\n",
      "         Linear-2783                   [-1, 10]             110\n",
      "    BatchNorm1d-2784                   [-1, 10]              20\n",
      "           ReLU-2785                   [-1, 10]               0\n",
      "        Dropout-2786                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2787                   [-1, 10]               0\n",
      "         Linear-2788                   [-1, 10]             110\n",
      "    BatchNorm1d-2789                   [-1, 10]              20\n",
      "           ReLU-2790                   [-1, 10]               0\n",
      "        Dropout-2791                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2792                   [-1, 10]               0\n",
      "         Linear-2793                   [-1, 10]             110\n",
      "    BatchNorm1d-2794                   [-1, 10]              20\n",
      "           ReLU-2795                   [-1, 10]               0\n",
      "        Dropout-2796                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2797                   [-1, 10]               0\n",
      "         Linear-2798                   [-1, 10]             110\n",
      "    BatchNorm1d-2799                   [-1, 10]              20\n",
      "           ReLU-2800                   [-1, 10]               0\n",
      "        Dropout-2801                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2802                   [-1, 10]               0\n",
      "         Linear-2803                   [-1, 10]             110\n",
      "    BatchNorm1d-2804                   [-1, 10]              20\n",
      "           ReLU-2805                   [-1, 10]               0\n",
      "        Dropout-2806                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2807                   [-1, 10]               0\n",
      "         Linear-2808                   [-1, 10]             110\n",
      "        Softmax-2809                   [-1, 10]               0\n",
      "         Linear-2810                   [-1, 10]             110\n",
      "    BatchNorm1d-2811                   [-1, 10]              20\n",
      "           ReLU-2812                   [-1, 10]               0\n",
      "        Dropout-2813                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2814                   [-1, 10]               0\n",
      "         Linear-2815                   [-1, 10]             110\n",
      "    BatchNorm1d-2816                   [-1, 10]              20\n",
      "           ReLU-2817                   [-1, 10]               0\n",
      "        Dropout-2818                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2819                   [-1, 10]               0\n",
      "         Linear-2820                   [-1, 10]             110\n",
      "    BatchNorm1d-2821                   [-1, 10]              20\n",
      "           ReLU-2822                   [-1, 10]               0\n",
      "        Dropout-2823                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2824                   [-1, 10]               0\n",
      "         Linear-2825                   [-1, 10]             110\n",
      "    BatchNorm1d-2826                   [-1, 10]              20\n",
      "           ReLU-2827                   [-1, 10]               0\n",
      "        Dropout-2828                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2829                   [-1, 10]               0\n",
      "         Linear-2830                   [-1, 10]             110\n",
      "    BatchNorm1d-2831                   [-1, 10]              20\n",
      "           ReLU-2832                   [-1, 10]               0\n",
      "        Dropout-2833                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2834                   [-1, 10]               0\n",
      "         Linear-2835                   [-1, 10]             110\n",
      "        Softmax-2836                   [-1, 10]               0\n",
      "         Linear-2837                   [-1, 15]             165\n",
      "        Softmax-2838                   [-1, 15]               0\n",
      "         Linear-2839                   [-1, 10]             110\n",
      "    BatchNorm1d-2840                   [-1, 10]              20\n",
      "           ReLU-2841                   [-1, 10]               0\n",
      "        Dropout-2842                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2843                   [-1, 10]               0\n",
      "         Linear-2844                   [-1, 10]             110\n",
      "    BatchNorm1d-2845                   [-1, 10]              20\n",
      "           ReLU-2846                   [-1, 10]               0\n",
      "        Dropout-2847                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2848                   [-1, 10]               0\n",
      "         Linear-2849                   [-1, 10]             110\n",
      "    BatchNorm1d-2850                   [-1, 10]              20\n",
      "           ReLU-2851                   [-1, 10]               0\n",
      "        Dropout-2852                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2853                   [-1, 10]               0\n",
      "         Linear-2854                   [-1, 10]             110\n",
      "    BatchNorm1d-2855                   [-1, 10]              20\n",
      "           ReLU-2856                   [-1, 10]               0\n",
      "        Dropout-2857                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2858                   [-1, 10]               0\n",
      "         Linear-2859                   [-1, 10]             110\n",
      "    BatchNorm1d-2860                   [-1, 10]              20\n",
      "           ReLU-2861                   [-1, 10]               0\n",
      "        Dropout-2862                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2863                   [-1, 10]               0\n",
      "         Linear-2864                   [-1, 10]             110\n",
      "    BatchNorm1d-2865                   [-1, 10]              20\n",
      "           ReLU-2866                   [-1, 10]               0\n",
      "        Dropout-2867                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2868                   [-1, 10]               0\n",
      "         Linear-2869                   [-1, 10]             110\n",
      "    BatchNorm1d-2870                   [-1, 10]              20\n",
      "           ReLU-2871                   [-1, 10]               0\n",
      "        Dropout-2872                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2873                   [-1, 10]               0\n",
      "         Linear-2874                   [-1, 10]             110\n",
      "    BatchNorm1d-2875                   [-1, 10]              20\n",
      "           ReLU-2876                   [-1, 10]               0\n",
      "        Dropout-2877                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2878                   [-1, 10]               0\n",
      "         Linear-2879                   [-1, 10]             110\n",
      "    BatchNorm1d-2880                   [-1, 10]              20\n",
      "           ReLU-2881                   [-1, 10]               0\n",
      "        Dropout-2882                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2883                   [-1, 10]               0\n",
      "         Linear-2884                   [-1, 10]             110\n",
      "    BatchNorm1d-2885                   [-1, 10]              20\n",
      "           ReLU-2886                   [-1, 10]               0\n",
      "        Dropout-2887                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2888                   [-1, 10]               0\n",
      "         Linear-2889                   [-1, 10]             110\n",
      "        Softmax-2890                   [-1, 10]               0\n",
      "         Linear-2891                   [-1, 10]             110\n",
      "    BatchNorm1d-2892                   [-1, 10]              20\n",
      "           ReLU-2893                   [-1, 10]               0\n",
      "        Dropout-2894                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2895                   [-1, 10]               0\n",
      "         Linear-2896                   [-1, 10]             110\n",
      "    BatchNorm1d-2897                   [-1, 10]              20\n",
      "           ReLU-2898                   [-1, 10]               0\n",
      "        Dropout-2899                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2900                   [-1, 10]               0\n",
      "         Linear-2901                   [-1, 10]             110\n",
      "    BatchNorm1d-2902                   [-1, 10]              20\n",
      "           ReLU-2903                   [-1, 10]               0\n",
      "        Dropout-2904                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2905                   [-1, 10]               0\n",
      "         Linear-2906                   [-1, 10]             110\n",
      "    BatchNorm1d-2907                   [-1, 10]              20\n",
      "           ReLU-2908                   [-1, 10]               0\n",
      "        Dropout-2909                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2910                   [-1, 10]               0\n",
      "         Linear-2911                   [-1, 10]             110\n",
      "    BatchNorm1d-2912                   [-1, 10]              20\n",
      "           ReLU-2913                   [-1, 10]               0\n",
      "        Dropout-2914                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2915                   [-1, 10]               0\n",
      "         Linear-2916                   [-1, 10]             110\n",
      "        Softmax-2917                   [-1, 10]               0\n",
      "         Linear-2918                   [-1, 15]             165\n",
      "        Softmax-2919                   [-1, 15]               0\n",
      "         Linear-2920                   [-1, 10]             110\n",
      "    BatchNorm1d-2921                   [-1, 10]              20\n",
      "           ReLU-2922                   [-1, 10]               0\n",
      "        Dropout-2923                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2924                   [-1, 10]               0\n",
      "         Linear-2925                   [-1, 10]             110\n",
      "    BatchNorm1d-2926                   [-1, 10]              20\n",
      "           ReLU-2927                   [-1, 10]               0\n",
      "        Dropout-2928                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2929                   [-1, 10]               0\n",
      "         Linear-2930                   [-1, 10]             110\n",
      "    BatchNorm1d-2931                   [-1, 10]              20\n",
      "           ReLU-2932                   [-1, 10]               0\n",
      "        Dropout-2933                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2934                   [-1, 10]               0\n",
      "         Linear-2935                   [-1, 10]             110\n",
      "    BatchNorm1d-2936                   [-1, 10]              20\n",
      "           ReLU-2937                   [-1, 10]               0\n",
      "        Dropout-2938                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2939                   [-1, 10]               0\n",
      "         Linear-2940                   [-1, 10]             110\n",
      "    BatchNorm1d-2941                   [-1, 10]              20\n",
      "           ReLU-2942                   [-1, 10]               0\n",
      "        Dropout-2943                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2944                   [-1, 10]               0\n",
      "         Linear-2945                   [-1, 10]             110\n",
      "    BatchNorm1d-2946                   [-1, 10]              20\n",
      "           ReLU-2947                   [-1, 10]               0\n",
      "        Dropout-2948                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2949                   [-1, 10]               0\n",
      "         Linear-2950                   [-1, 10]             110\n",
      "    BatchNorm1d-2951                   [-1, 10]              20\n",
      "           ReLU-2952                   [-1, 10]               0\n",
      "        Dropout-2953                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2954                   [-1, 10]               0\n",
      "         Linear-2955                   [-1, 10]             110\n",
      "    BatchNorm1d-2956                   [-1, 10]              20\n",
      "           ReLU-2957                   [-1, 10]               0\n",
      "        Dropout-2958                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2959                   [-1, 10]               0\n",
      "         Linear-2960                   [-1, 10]             110\n",
      "    BatchNorm1d-2961                   [-1, 10]              20\n",
      "           ReLU-2962                   [-1, 10]               0\n",
      "        Dropout-2963                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2964                   [-1, 10]               0\n",
      "         Linear-2965                   [-1, 10]             110\n",
      "    BatchNorm1d-2966                   [-1, 10]              20\n",
      "           ReLU-2967                   [-1, 10]               0\n",
      "        Dropout-2968                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2969                   [-1, 10]               0\n",
      "         Linear-2970                   [-1, 10]             110\n",
      "        Softmax-2971                   [-1, 10]               0\n",
      "         Linear-2972                   [-1, 10]             110\n",
      "    BatchNorm1d-2973                   [-1, 10]              20\n",
      "           ReLU-2974                   [-1, 10]               0\n",
      "        Dropout-2975                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2976                   [-1, 10]               0\n",
      "         Linear-2977                   [-1, 10]             110\n",
      "    BatchNorm1d-2978                   [-1, 10]              20\n",
      "           ReLU-2979                   [-1, 10]               0\n",
      "        Dropout-2980                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2981                   [-1, 10]               0\n",
      "         Linear-2982                   [-1, 10]             110\n",
      "    BatchNorm1d-2983                   [-1, 10]              20\n",
      "           ReLU-2984                   [-1, 10]               0\n",
      "        Dropout-2985                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2986                   [-1, 10]               0\n",
      "         Linear-2987                   [-1, 10]             110\n",
      "    BatchNorm1d-2988                   [-1, 10]              20\n",
      "           ReLU-2989                   [-1, 10]               0\n",
      "        Dropout-2990                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2991                   [-1, 10]               0\n",
      "         Linear-2992                   [-1, 10]             110\n",
      "    BatchNorm1d-2993                   [-1, 10]              20\n",
      "           ReLU-2994                   [-1, 10]               0\n",
      "        Dropout-2995                   [-1, 10]               0\n",
      "MultiLayerPerceptron-2996                   [-1, 10]               0\n",
      "         Linear-2997                   [-1, 10]             110\n",
      "        Softmax-2998                   [-1, 10]               0\n",
      "         Linear-2999                   [-1, 15]             165\n",
      "        Softmax-3000                   [-1, 15]               0\n",
      "         Linear-3001                   [-1, 10]             110\n",
      "    BatchNorm1d-3002                   [-1, 10]              20\n",
      "           ReLU-3003                   [-1, 10]               0\n",
      "        Dropout-3004                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3005                   [-1, 10]               0\n",
      "         Linear-3006                   [-1, 10]             110\n",
      "    BatchNorm1d-3007                   [-1, 10]              20\n",
      "           ReLU-3008                   [-1, 10]               0\n",
      "        Dropout-3009                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3010                   [-1, 10]               0\n",
      "         Linear-3011                   [-1, 10]             110\n",
      "    BatchNorm1d-3012                   [-1, 10]              20\n",
      "           ReLU-3013                   [-1, 10]               0\n",
      "        Dropout-3014                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3015                   [-1, 10]               0\n",
      "         Linear-3016                   [-1, 10]             110\n",
      "    BatchNorm1d-3017                   [-1, 10]              20\n",
      "           ReLU-3018                   [-1, 10]               0\n",
      "        Dropout-3019                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3020                   [-1, 10]               0\n",
      "         Linear-3021                   [-1, 10]             110\n",
      "    BatchNorm1d-3022                   [-1, 10]              20\n",
      "           ReLU-3023                   [-1, 10]               0\n",
      "        Dropout-3024                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3025                   [-1, 10]               0\n",
      "         Linear-3026                   [-1, 10]             110\n",
      "    BatchNorm1d-3027                   [-1, 10]              20\n",
      "           ReLU-3028                   [-1, 10]               0\n",
      "        Dropout-3029                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3030                   [-1, 10]               0\n",
      "         Linear-3031                   [-1, 10]             110\n",
      "    BatchNorm1d-3032                   [-1, 10]              20\n",
      "           ReLU-3033                   [-1, 10]               0\n",
      "        Dropout-3034                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3035                   [-1, 10]               0\n",
      "         Linear-3036                   [-1, 10]             110\n",
      "    BatchNorm1d-3037                   [-1, 10]              20\n",
      "           ReLU-3038                   [-1, 10]               0\n",
      "        Dropout-3039                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3040                   [-1, 10]               0\n",
      "         Linear-3041                   [-1, 10]             110\n",
      "    BatchNorm1d-3042                   [-1, 10]              20\n",
      "           ReLU-3043                   [-1, 10]               0\n",
      "        Dropout-3044                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3045                   [-1, 10]               0\n",
      "         Linear-3046                   [-1, 10]             110\n",
      "    BatchNorm1d-3047                   [-1, 10]              20\n",
      "           ReLU-3048                   [-1, 10]               0\n",
      "        Dropout-3049                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3050                   [-1, 10]               0\n",
      "         Linear-3051                   [-1, 10]             110\n",
      "        Softmax-3052                   [-1, 10]               0\n",
      "         Linear-3053                   [-1, 10]             110\n",
      "    BatchNorm1d-3054                   [-1, 10]              20\n",
      "           ReLU-3055                   [-1, 10]               0\n",
      "        Dropout-3056                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3057                   [-1, 10]               0\n",
      "         Linear-3058                   [-1, 10]             110\n",
      "    BatchNorm1d-3059                   [-1, 10]              20\n",
      "           ReLU-3060                   [-1, 10]               0\n",
      "        Dropout-3061                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3062                   [-1, 10]               0\n",
      "         Linear-3063                   [-1, 10]             110\n",
      "    BatchNorm1d-3064                   [-1, 10]              20\n",
      "           ReLU-3065                   [-1, 10]               0\n",
      "        Dropout-3066                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3067                   [-1, 10]               0\n",
      "         Linear-3068                   [-1, 10]             110\n",
      "    BatchNorm1d-3069                   [-1, 10]              20\n",
      "           ReLU-3070                   [-1, 10]               0\n",
      "        Dropout-3071                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3072                   [-1, 10]               0\n",
      "         Linear-3073                   [-1, 10]             110\n",
      "    BatchNorm1d-3074                   [-1, 10]              20\n",
      "           ReLU-3075                   [-1, 10]               0\n",
      "        Dropout-3076                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3077                   [-1, 10]               0\n",
      "         Linear-3078                   [-1, 10]             110\n",
      "        Softmax-3079                   [-1, 10]               0\n",
      "         Linear-3080                   [-1, 15]             165\n",
      "        Softmax-3081                   [-1, 15]               0\n",
      "         Linear-3082                   [-1, 10]             110\n",
      "    BatchNorm1d-3083                   [-1, 10]              20\n",
      "           ReLU-3084                   [-1, 10]               0\n",
      "        Dropout-3085                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3086                   [-1, 10]               0\n",
      "         Linear-3087                   [-1, 10]             110\n",
      "    BatchNorm1d-3088                   [-1, 10]              20\n",
      "           ReLU-3089                   [-1, 10]               0\n",
      "        Dropout-3090                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3091                   [-1, 10]               0\n",
      "         Linear-3092                   [-1, 10]             110\n",
      "    BatchNorm1d-3093                   [-1, 10]              20\n",
      "           ReLU-3094                   [-1, 10]               0\n",
      "        Dropout-3095                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3096                   [-1, 10]               0\n",
      "         Linear-3097                   [-1, 10]             110\n",
      "    BatchNorm1d-3098                   [-1, 10]              20\n",
      "           ReLU-3099                   [-1, 10]               0\n",
      "        Dropout-3100                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3101                   [-1, 10]               0\n",
      "         Linear-3102                   [-1, 10]             110\n",
      "    BatchNorm1d-3103                   [-1, 10]              20\n",
      "           ReLU-3104                   [-1, 10]               0\n",
      "        Dropout-3105                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3106                   [-1, 10]               0\n",
      "         Linear-3107                   [-1, 10]             110\n",
      "    BatchNorm1d-3108                   [-1, 10]              20\n",
      "           ReLU-3109                   [-1, 10]               0\n",
      "        Dropout-3110                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3111                   [-1, 10]               0\n",
      "         Linear-3112                   [-1, 10]             110\n",
      "    BatchNorm1d-3113                   [-1, 10]              20\n",
      "           ReLU-3114                   [-1, 10]               0\n",
      "        Dropout-3115                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3116                   [-1, 10]               0\n",
      "         Linear-3117                   [-1, 10]             110\n",
      "    BatchNorm1d-3118                   [-1, 10]              20\n",
      "           ReLU-3119                   [-1, 10]               0\n",
      "        Dropout-3120                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3121                   [-1, 10]               0\n",
      "         Linear-3122                   [-1, 10]             110\n",
      "    BatchNorm1d-3123                   [-1, 10]              20\n",
      "           ReLU-3124                   [-1, 10]               0\n",
      "        Dropout-3125                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3126                   [-1, 10]               0\n",
      "         Linear-3127                   [-1, 10]             110\n",
      "    BatchNorm1d-3128                   [-1, 10]              20\n",
      "           ReLU-3129                   [-1, 10]               0\n",
      "        Dropout-3130                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3131                   [-1, 10]               0\n",
      "         Linear-3132                   [-1, 10]             110\n",
      "        Softmax-3133                   [-1, 10]               0\n",
      "         Linear-3134                   [-1, 10]             110\n",
      "    BatchNorm1d-3135                   [-1, 10]              20\n",
      "           ReLU-3136                   [-1, 10]               0\n",
      "        Dropout-3137                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3138                   [-1, 10]               0\n",
      "         Linear-3139                   [-1, 10]             110\n",
      "    BatchNorm1d-3140                   [-1, 10]              20\n",
      "           ReLU-3141                   [-1, 10]               0\n",
      "        Dropout-3142                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3143                   [-1, 10]               0\n",
      "         Linear-3144                   [-1, 10]             110\n",
      "    BatchNorm1d-3145                   [-1, 10]              20\n",
      "           ReLU-3146                   [-1, 10]               0\n",
      "        Dropout-3147                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3148                   [-1, 10]               0\n",
      "         Linear-3149                   [-1, 10]             110\n",
      "    BatchNorm1d-3150                   [-1, 10]              20\n",
      "           ReLU-3151                   [-1, 10]               0\n",
      "        Dropout-3152                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3153                   [-1, 10]               0\n",
      "         Linear-3154                   [-1, 10]             110\n",
      "    BatchNorm1d-3155                   [-1, 10]              20\n",
      "           ReLU-3156                   [-1, 10]               0\n",
      "        Dropout-3157                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3158                   [-1, 10]               0\n",
      "         Linear-3159                   [-1, 10]             110\n",
      "        Softmax-3160                   [-1, 10]               0\n",
      "         Linear-3161                   [-1, 15]             165\n",
      "        Softmax-3162                   [-1, 15]               0\n",
      "         Linear-3163                   [-1, 10]             110\n",
      "    BatchNorm1d-3164                   [-1, 10]              20\n",
      "           ReLU-3165                   [-1, 10]               0\n",
      "        Dropout-3166                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3167                   [-1, 10]               0\n",
      "         Linear-3168                   [-1, 10]             110\n",
      "    BatchNorm1d-3169                   [-1, 10]              20\n",
      "           ReLU-3170                   [-1, 10]               0\n",
      "        Dropout-3171                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3172                   [-1, 10]               0\n",
      "         Linear-3173                   [-1, 10]             110\n",
      "    BatchNorm1d-3174                   [-1, 10]              20\n",
      "           ReLU-3175                   [-1, 10]               0\n",
      "        Dropout-3176                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3177                   [-1, 10]               0\n",
      "         Linear-3178                   [-1, 10]             110\n",
      "    BatchNorm1d-3179                   [-1, 10]              20\n",
      "           ReLU-3180                   [-1, 10]               0\n",
      "        Dropout-3181                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3182                   [-1, 10]               0\n",
      "         Linear-3183                   [-1, 10]             110\n",
      "    BatchNorm1d-3184                   [-1, 10]              20\n",
      "           ReLU-3185                   [-1, 10]               0\n",
      "        Dropout-3186                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3187                   [-1, 10]               0\n",
      "         Linear-3188                   [-1, 10]             110\n",
      "    BatchNorm1d-3189                   [-1, 10]              20\n",
      "           ReLU-3190                   [-1, 10]               0\n",
      "        Dropout-3191                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3192                   [-1, 10]               0\n",
      "         Linear-3193                   [-1, 10]             110\n",
      "    BatchNorm1d-3194                   [-1, 10]              20\n",
      "           ReLU-3195                   [-1, 10]               0\n",
      "        Dropout-3196                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3197                   [-1, 10]               0\n",
      "         Linear-3198                   [-1, 10]             110\n",
      "    BatchNorm1d-3199                   [-1, 10]              20\n",
      "           ReLU-3200                   [-1, 10]               0\n",
      "        Dropout-3201                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3202                   [-1, 10]               0\n",
      "         Linear-3203                   [-1, 10]             110\n",
      "    BatchNorm1d-3204                   [-1, 10]              20\n",
      "           ReLU-3205                   [-1, 10]               0\n",
      "        Dropout-3206                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3207                   [-1, 10]               0\n",
      "         Linear-3208                   [-1, 10]             110\n",
      "    BatchNorm1d-3209                   [-1, 10]              20\n",
      "           ReLU-3210                   [-1, 10]               0\n",
      "        Dropout-3211                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3212                   [-1, 10]               0\n",
      "         Linear-3213                   [-1, 10]             110\n",
      "        Softmax-3214                   [-1, 10]               0\n",
      "         Linear-3215                   [-1, 10]             110\n",
      "    BatchNorm1d-3216                   [-1, 10]              20\n",
      "           ReLU-3217                   [-1, 10]               0\n",
      "        Dropout-3218                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3219                   [-1, 10]               0\n",
      "         Linear-3220                   [-1, 10]             110\n",
      "    BatchNorm1d-3221                   [-1, 10]              20\n",
      "           ReLU-3222                   [-1, 10]               0\n",
      "        Dropout-3223                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3224                   [-1, 10]               0\n",
      "         Linear-3225                   [-1, 10]             110\n",
      "    BatchNorm1d-3226                   [-1, 10]              20\n",
      "           ReLU-3227                   [-1, 10]               0\n",
      "        Dropout-3228                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3229                   [-1, 10]               0\n",
      "         Linear-3230                   [-1, 10]             110\n",
      "    BatchNorm1d-3231                   [-1, 10]              20\n",
      "           ReLU-3232                   [-1, 10]               0\n",
      "        Dropout-3233                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3234                   [-1, 10]               0\n",
      "         Linear-3235                   [-1, 10]             110\n",
      "    BatchNorm1d-3236                   [-1, 10]              20\n",
      "           ReLU-3237                   [-1, 10]               0\n",
      "        Dropout-3238                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3239                   [-1, 10]               0\n",
      "         Linear-3240                   [-1, 10]             110\n",
      "        Softmax-3241                   [-1, 10]               0\n",
      "         Linear-3242                   [-1, 15]             165\n",
      "        Softmax-3243                   [-1, 15]               0\n",
      "         Linear-3244                   [-1, 10]             110\n",
      "    BatchNorm1d-3245                   [-1, 10]              20\n",
      "           ReLU-3246                   [-1, 10]               0\n",
      "        Dropout-3247                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3248                   [-1, 10]               0\n",
      "         Linear-3249                   [-1, 10]             110\n",
      "    BatchNorm1d-3250                   [-1, 10]              20\n",
      "           ReLU-3251                   [-1, 10]               0\n",
      "        Dropout-3252                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3253                   [-1, 10]               0\n",
      "         Linear-3254                   [-1, 10]             110\n",
      "    BatchNorm1d-3255                   [-1, 10]              20\n",
      "           ReLU-3256                   [-1, 10]               0\n",
      "        Dropout-3257                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3258                   [-1, 10]               0\n",
      "         Linear-3259                   [-1, 10]             110\n",
      "    BatchNorm1d-3260                   [-1, 10]              20\n",
      "           ReLU-3261                   [-1, 10]               0\n",
      "        Dropout-3262                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3263                   [-1, 10]               0\n",
      "         Linear-3264                   [-1, 10]             110\n",
      "    BatchNorm1d-3265                   [-1, 10]              20\n",
      "           ReLU-3266                   [-1, 10]               0\n",
      "        Dropout-3267                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3268                   [-1, 10]               0\n",
      "         Linear-3269                   [-1, 10]             110\n",
      "    BatchNorm1d-3270                   [-1, 10]              20\n",
      "           ReLU-3271                   [-1, 10]               0\n",
      "        Dropout-3272                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3273                   [-1, 10]               0\n",
      "         Linear-3274                   [-1, 10]             110\n",
      "    BatchNorm1d-3275                   [-1, 10]              20\n",
      "           ReLU-3276                   [-1, 10]               0\n",
      "        Dropout-3277                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3278                   [-1, 10]               0\n",
      "         Linear-3279                   [-1, 10]             110\n",
      "    BatchNorm1d-3280                   [-1, 10]              20\n",
      "           ReLU-3281                   [-1, 10]               0\n",
      "        Dropout-3282                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3283                   [-1, 10]               0\n",
      "         Linear-3284                   [-1, 10]             110\n",
      "    BatchNorm1d-3285                   [-1, 10]              20\n",
      "           ReLU-3286                   [-1, 10]               0\n",
      "        Dropout-3287                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3288                   [-1, 10]               0\n",
      "         Linear-3289                   [-1, 10]             110\n",
      "    BatchNorm1d-3290                   [-1, 10]              20\n",
      "           ReLU-3291                   [-1, 10]               0\n",
      "        Dropout-3292                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3293                   [-1, 10]               0\n",
      "         Linear-3294                   [-1, 10]             110\n",
      "        Softmax-3295                   [-1, 10]               0\n",
      "         Linear-3296                   [-1, 10]             110\n",
      "    BatchNorm1d-3297                   [-1, 10]              20\n",
      "           ReLU-3298                   [-1, 10]               0\n",
      "        Dropout-3299                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3300                   [-1, 10]               0\n",
      "         Linear-3301                   [-1, 10]             110\n",
      "    BatchNorm1d-3302                   [-1, 10]              20\n",
      "           ReLU-3303                   [-1, 10]               0\n",
      "        Dropout-3304                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3305                   [-1, 10]               0\n",
      "         Linear-3306                   [-1, 10]             110\n",
      "    BatchNorm1d-3307                   [-1, 10]              20\n",
      "           ReLU-3308                   [-1, 10]               0\n",
      "        Dropout-3309                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3310                   [-1, 10]               0\n",
      "         Linear-3311                   [-1, 10]             110\n",
      "    BatchNorm1d-3312                   [-1, 10]              20\n",
      "           ReLU-3313                   [-1, 10]               0\n",
      "        Dropout-3314                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3315                   [-1, 10]               0\n",
      "         Linear-3316                   [-1, 10]             110\n",
      "    BatchNorm1d-3317                   [-1, 10]              20\n",
      "           ReLU-3318                   [-1, 10]               0\n",
      "        Dropout-3319                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3320                   [-1, 10]               0\n",
      "         Linear-3321                   [-1, 10]             110\n",
      "        Softmax-3322                   [-1, 10]               0\n",
      "         Linear-3323                   [-1, 15]             165\n",
      "        Softmax-3324                   [-1, 15]               0\n",
      "         Linear-3325                   [-1, 10]             110\n",
      "    BatchNorm1d-3326                   [-1, 10]              20\n",
      "           ReLU-3327                   [-1, 10]               0\n",
      "        Dropout-3328                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3329                   [-1, 10]               0\n",
      "         Linear-3330                   [-1, 10]             110\n",
      "    BatchNorm1d-3331                   [-1, 10]              20\n",
      "           ReLU-3332                   [-1, 10]               0\n",
      "        Dropout-3333                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3334                   [-1, 10]               0\n",
      "         Linear-3335                   [-1, 10]             110\n",
      "    BatchNorm1d-3336                   [-1, 10]              20\n",
      "           ReLU-3337                   [-1, 10]               0\n",
      "        Dropout-3338                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3339                   [-1, 10]               0\n",
      "         Linear-3340                   [-1, 10]             110\n",
      "    BatchNorm1d-3341                   [-1, 10]              20\n",
      "           ReLU-3342                   [-1, 10]               0\n",
      "        Dropout-3343                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3344                   [-1, 10]               0\n",
      "         Linear-3345                   [-1, 10]             110\n",
      "    BatchNorm1d-3346                   [-1, 10]              20\n",
      "           ReLU-3347                   [-1, 10]               0\n",
      "        Dropout-3348                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3349                   [-1, 10]               0\n",
      "         Linear-3350                   [-1, 10]             110\n",
      "    BatchNorm1d-3351                   [-1, 10]              20\n",
      "           ReLU-3352                   [-1, 10]               0\n",
      "        Dropout-3353                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3354                   [-1, 10]               0\n",
      "         Linear-3355                   [-1, 10]             110\n",
      "    BatchNorm1d-3356                   [-1, 10]              20\n",
      "           ReLU-3357                   [-1, 10]               0\n",
      "        Dropout-3358                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3359                   [-1, 10]               0\n",
      "         Linear-3360                   [-1, 10]             110\n",
      "    BatchNorm1d-3361                   [-1, 10]              20\n",
      "           ReLU-3362                   [-1, 10]               0\n",
      "        Dropout-3363                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3364                   [-1, 10]               0\n",
      "         Linear-3365                   [-1, 10]             110\n",
      "    BatchNorm1d-3366                   [-1, 10]              20\n",
      "           ReLU-3367                   [-1, 10]               0\n",
      "        Dropout-3368                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3369                   [-1, 10]               0\n",
      "         Linear-3370                   [-1, 10]             110\n",
      "    BatchNorm1d-3371                   [-1, 10]              20\n",
      "           ReLU-3372                   [-1, 10]               0\n",
      "        Dropout-3373                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3374                   [-1, 10]               0\n",
      "         Linear-3375                   [-1, 10]             110\n",
      "        Softmax-3376                   [-1, 10]               0\n",
      "         Linear-3377                   [-1, 10]             110\n",
      "    BatchNorm1d-3378                   [-1, 10]              20\n",
      "           ReLU-3379                   [-1, 10]               0\n",
      "        Dropout-3380                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3381                   [-1, 10]               0\n",
      "         Linear-3382                   [-1, 10]             110\n",
      "    BatchNorm1d-3383                   [-1, 10]              20\n",
      "           ReLU-3384                   [-1, 10]               0\n",
      "        Dropout-3385                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3386                   [-1, 10]               0\n",
      "         Linear-3387                   [-1, 10]             110\n",
      "    BatchNorm1d-3388                   [-1, 10]              20\n",
      "           ReLU-3389                   [-1, 10]               0\n",
      "        Dropout-3390                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3391                   [-1, 10]               0\n",
      "         Linear-3392                   [-1, 10]             110\n",
      "    BatchNorm1d-3393                   [-1, 10]              20\n",
      "           ReLU-3394                   [-1, 10]               0\n",
      "        Dropout-3395                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3396                   [-1, 10]               0\n",
      "         Linear-3397                   [-1, 10]             110\n",
      "    BatchNorm1d-3398                   [-1, 10]              20\n",
      "           ReLU-3399                   [-1, 10]               0\n",
      "        Dropout-3400                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3401                   [-1, 10]               0\n",
      "         Linear-3402                   [-1, 10]             110\n",
      "        Softmax-3403                   [-1, 10]               0\n",
      "         Linear-3404                   [-1, 15]             165\n",
      "        Softmax-3405                   [-1, 15]               0\n",
      "         Linear-3406                   [-1, 10]             110\n",
      "    BatchNorm1d-3407                   [-1, 10]              20\n",
      "           ReLU-3408                   [-1, 10]               0\n",
      "        Dropout-3409                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3410                   [-1, 10]               0\n",
      "         Linear-3411                   [-1, 10]             110\n",
      "    BatchNorm1d-3412                   [-1, 10]              20\n",
      "           ReLU-3413                   [-1, 10]               0\n",
      "        Dropout-3414                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3415                   [-1, 10]               0\n",
      "         Linear-3416                   [-1, 10]             110\n",
      "    BatchNorm1d-3417                   [-1, 10]              20\n",
      "           ReLU-3418                   [-1, 10]               0\n",
      "        Dropout-3419                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3420                   [-1, 10]               0\n",
      "         Linear-3421                   [-1, 10]             110\n",
      "    BatchNorm1d-3422                   [-1, 10]              20\n",
      "           ReLU-3423                   [-1, 10]               0\n",
      "        Dropout-3424                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3425                   [-1, 10]               0\n",
      "         Linear-3426                   [-1, 10]             110\n",
      "    BatchNorm1d-3427                   [-1, 10]              20\n",
      "           ReLU-3428                   [-1, 10]               0\n",
      "        Dropout-3429                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3430                   [-1, 10]               0\n",
      "         Linear-3431                   [-1, 10]             110\n",
      "    BatchNorm1d-3432                   [-1, 10]              20\n",
      "           ReLU-3433                   [-1, 10]               0\n",
      "        Dropout-3434                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3435                   [-1, 10]               0\n",
      "         Linear-3436                   [-1, 10]             110\n",
      "    BatchNorm1d-3437                   [-1, 10]              20\n",
      "           ReLU-3438                   [-1, 10]               0\n",
      "        Dropout-3439                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3440                   [-1, 10]               0\n",
      "         Linear-3441                   [-1, 10]             110\n",
      "    BatchNorm1d-3442                   [-1, 10]              20\n",
      "           ReLU-3443                   [-1, 10]               0\n",
      "        Dropout-3444                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3445                   [-1, 10]               0\n",
      "         Linear-3446                   [-1, 10]             110\n",
      "    BatchNorm1d-3447                   [-1, 10]              20\n",
      "           ReLU-3448                   [-1, 10]               0\n",
      "        Dropout-3449                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3450                   [-1, 10]               0\n",
      "         Linear-3451                   [-1, 10]             110\n",
      "    BatchNorm1d-3452                   [-1, 10]              20\n",
      "           ReLU-3453                   [-1, 10]               0\n",
      "        Dropout-3454                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3455                   [-1, 10]               0\n",
      "         Linear-3456                   [-1, 10]             110\n",
      "        Softmax-3457                   [-1, 10]               0\n",
      "         Linear-3458                   [-1, 10]             110\n",
      "    BatchNorm1d-3459                   [-1, 10]              20\n",
      "           ReLU-3460                   [-1, 10]               0\n",
      "        Dropout-3461                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3462                   [-1, 10]               0\n",
      "         Linear-3463                   [-1, 10]             110\n",
      "    BatchNorm1d-3464                   [-1, 10]              20\n",
      "           ReLU-3465                   [-1, 10]               0\n",
      "        Dropout-3466                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3467                   [-1, 10]               0\n",
      "         Linear-3468                   [-1, 10]             110\n",
      "    BatchNorm1d-3469                   [-1, 10]              20\n",
      "           ReLU-3470                   [-1, 10]               0\n",
      "        Dropout-3471                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3472                   [-1, 10]               0\n",
      "         Linear-3473                   [-1, 10]             110\n",
      "    BatchNorm1d-3474                   [-1, 10]              20\n",
      "           ReLU-3475                   [-1, 10]               0\n",
      "        Dropout-3476                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3477                   [-1, 10]               0\n",
      "         Linear-3478                   [-1, 10]             110\n",
      "    BatchNorm1d-3479                   [-1, 10]              20\n",
      "           ReLU-3480                   [-1, 10]               0\n",
      "        Dropout-3481                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3482                   [-1, 10]               0\n",
      "         Linear-3483                   [-1, 10]             110\n",
      "        Softmax-3484                   [-1, 10]               0\n",
      "         Linear-3485                   [-1, 15]             165\n",
      "        Softmax-3486                   [-1, 15]               0\n",
      "         Linear-3487                   [-1, 10]             110\n",
      "    BatchNorm1d-3488                   [-1, 10]              20\n",
      "           ReLU-3489                   [-1, 10]               0\n",
      "        Dropout-3490                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3491                   [-1, 10]               0\n",
      "         Linear-3492                   [-1, 10]             110\n",
      "    BatchNorm1d-3493                   [-1, 10]              20\n",
      "           ReLU-3494                   [-1, 10]               0\n",
      "        Dropout-3495                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3496                   [-1, 10]               0\n",
      "         Linear-3497                   [-1, 10]             110\n",
      "    BatchNorm1d-3498                   [-1, 10]              20\n",
      "           ReLU-3499                   [-1, 10]               0\n",
      "        Dropout-3500                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3501                   [-1, 10]               0\n",
      "         Linear-3502                   [-1, 10]             110\n",
      "    BatchNorm1d-3503                   [-1, 10]              20\n",
      "           ReLU-3504                   [-1, 10]               0\n",
      "        Dropout-3505                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3506                   [-1, 10]               0\n",
      "         Linear-3507                   [-1, 10]             110\n",
      "    BatchNorm1d-3508                   [-1, 10]              20\n",
      "           ReLU-3509                   [-1, 10]               0\n",
      "        Dropout-3510                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3511                   [-1, 10]               0\n",
      "         Linear-3512                   [-1, 10]             110\n",
      "    BatchNorm1d-3513                   [-1, 10]              20\n",
      "           ReLU-3514                   [-1, 10]               0\n",
      "        Dropout-3515                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3516                   [-1, 10]               0\n",
      "         Linear-3517                   [-1, 10]             110\n",
      "    BatchNorm1d-3518                   [-1, 10]              20\n",
      "           ReLU-3519                   [-1, 10]               0\n",
      "        Dropout-3520                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3521                   [-1, 10]               0\n",
      "         Linear-3522                   [-1, 10]             110\n",
      "    BatchNorm1d-3523                   [-1, 10]              20\n",
      "           ReLU-3524                   [-1, 10]               0\n",
      "        Dropout-3525                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3526                   [-1, 10]               0\n",
      "         Linear-3527                   [-1, 10]             110\n",
      "    BatchNorm1d-3528                   [-1, 10]              20\n",
      "           ReLU-3529                   [-1, 10]               0\n",
      "        Dropout-3530                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3531                   [-1, 10]               0\n",
      "         Linear-3532                   [-1, 10]             110\n",
      "    BatchNorm1d-3533                   [-1, 10]              20\n",
      "           ReLU-3534                   [-1, 10]               0\n",
      "        Dropout-3535                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3536                   [-1, 10]               0\n",
      "         Linear-3537                   [-1, 10]             110\n",
      "        Softmax-3538                   [-1, 10]               0\n",
      "         Linear-3539                   [-1, 10]             110\n",
      "    BatchNorm1d-3540                   [-1, 10]              20\n",
      "           ReLU-3541                   [-1, 10]               0\n",
      "        Dropout-3542                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3543                   [-1, 10]               0\n",
      "         Linear-3544                   [-1, 10]             110\n",
      "    BatchNorm1d-3545                   [-1, 10]              20\n",
      "           ReLU-3546                   [-1, 10]               0\n",
      "        Dropout-3547                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3548                   [-1, 10]               0\n",
      "         Linear-3549                   [-1, 10]             110\n",
      "    BatchNorm1d-3550                   [-1, 10]              20\n",
      "           ReLU-3551                   [-1, 10]               0\n",
      "        Dropout-3552                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3553                   [-1, 10]               0\n",
      "         Linear-3554                   [-1, 10]             110\n",
      "    BatchNorm1d-3555                   [-1, 10]              20\n",
      "           ReLU-3556                   [-1, 10]               0\n",
      "        Dropout-3557                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3558                   [-1, 10]               0\n",
      "         Linear-3559                   [-1, 10]             110\n",
      "    BatchNorm1d-3560                   [-1, 10]              20\n",
      "           ReLU-3561                   [-1, 10]               0\n",
      "        Dropout-3562                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3563                   [-1, 10]               0\n",
      "         Linear-3564                   [-1, 10]             110\n",
      "        Softmax-3565                   [-1, 10]               0\n",
      "         Linear-3566                   [-1, 15]             165\n",
      "        Softmax-3567                   [-1, 15]               0\n",
      "         Linear-3568                   [-1, 10]             110\n",
      "    BatchNorm1d-3569                   [-1, 10]              20\n",
      "           ReLU-3570                   [-1, 10]               0\n",
      "        Dropout-3571                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3572                   [-1, 10]               0\n",
      "         Linear-3573                   [-1, 10]             110\n",
      "    BatchNorm1d-3574                   [-1, 10]              20\n",
      "           ReLU-3575                   [-1, 10]               0\n",
      "        Dropout-3576                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3577                   [-1, 10]               0\n",
      "         Linear-3578                   [-1, 10]             110\n",
      "    BatchNorm1d-3579                   [-1, 10]              20\n",
      "           ReLU-3580                   [-1, 10]               0\n",
      "        Dropout-3581                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3582                   [-1, 10]               0\n",
      "         Linear-3583                   [-1, 10]             110\n",
      "    BatchNorm1d-3584                   [-1, 10]              20\n",
      "           ReLU-3585                   [-1, 10]               0\n",
      "        Dropout-3586                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3587                   [-1, 10]               0\n",
      "         Linear-3588                   [-1, 10]             110\n",
      "    BatchNorm1d-3589                   [-1, 10]              20\n",
      "           ReLU-3590                   [-1, 10]               0\n",
      "        Dropout-3591                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3592                   [-1, 10]               0\n",
      "         Linear-3593                   [-1, 10]             110\n",
      "    BatchNorm1d-3594                   [-1, 10]              20\n",
      "           ReLU-3595                   [-1, 10]               0\n",
      "        Dropout-3596                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3597                   [-1, 10]               0\n",
      "         Linear-3598                   [-1, 10]             110\n",
      "    BatchNorm1d-3599                   [-1, 10]              20\n",
      "           ReLU-3600                   [-1, 10]               0\n",
      "        Dropout-3601                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3602                   [-1, 10]               0\n",
      "         Linear-3603                   [-1, 10]             110\n",
      "    BatchNorm1d-3604                   [-1, 10]              20\n",
      "           ReLU-3605                   [-1, 10]               0\n",
      "        Dropout-3606                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3607                   [-1, 10]               0\n",
      "         Linear-3608                   [-1, 10]             110\n",
      "    BatchNorm1d-3609                   [-1, 10]              20\n",
      "           ReLU-3610                   [-1, 10]               0\n",
      "        Dropout-3611                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3612                   [-1, 10]               0\n",
      "         Linear-3613                   [-1, 10]             110\n",
      "    BatchNorm1d-3614                   [-1, 10]              20\n",
      "           ReLU-3615                   [-1, 10]               0\n",
      "        Dropout-3616                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3617                   [-1, 10]               0\n",
      "         Linear-3618                   [-1, 10]             110\n",
      "        Softmax-3619                   [-1, 10]               0\n",
      "         Linear-3620                   [-1, 10]             110\n",
      "    BatchNorm1d-3621                   [-1, 10]              20\n",
      "           ReLU-3622                   [-1, 10]               0\n",
      "        Dropout-3623                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3624                   [-1, 10]               0\n",
      "         Linear-3625                   [-1, 10]             110\n",
      "    BatchNorm1d-3626                   [-1, 10]              20\n",
      "           ReLU-3627                   [-1, 10]               0\n",
      "        Dropout-3628                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3629                   [-1, 10]               0\n",
      "         Linear-3630                   [-1, 10]             110\n",
      "    BatchNorm1d-3631                   [-1, 10]              20\n",
      "           ReLU-3632                   [-1, 10]               0\n",
      "        Dropout-3633                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3634                   [-1, 10]               0\n",
      "         Linear-3635                   [-1, 10]             110\n",
      "    BatchNorm1d-3636                   [-1, 10]              20\n",
      "           ReLU-3637                   [-1, 10]               0\n",
      "        Dropout-3638                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3639                   [-1, 10]               0\n",
      "         Linear-3640                   [-1, 10]             110\n",
      "    BatchNorm1d-3641                   [-1, 10]              20\n",
      "           ReLU-3642                   [-1, 10]               0\n",
      "        Dropout-3643                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3644                   [-1, 10]               0\n",
      "         Linear-3645                   [-1, 10]             110\n",
      "        Softmax-3646                   [-1, 10]               0\n",
      "         Linear-3647                   [-1, 15]             165\n",
      "        Softmax-3648                   [-1, 15]               0\n",
      "         Linear-3649                   [-1, 10]             110\n",
      "    BatchNorm1d-3650                   [-1, 10]              20\n",
      "           ReLU-3651                   [-1, 10]               0\n",
      "        Dropout-3652                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3653                   [-1, 10]               0\n",
      "         Linear-3654                   [-1, 10]             110\n",
      "    BatchNorm1d-3655                   [-1, 10]              20\n",
      "           ReLU-3656                   [-1, 10]               0\n",
      "        Dropout-3657                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3658                   [-1, 10]               0\n",
      "         Linear-3659                   [-1, 10]             110\n",
      "    BatchNorm1d-3660                   [-1, 10]              20\n",
      "           ReLU-3661                   [-1, 10]               0\n",
      "        Dropout-3662                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3663                   [-1, 10]               0\n",
      "         Linear-3664                   [-1, 10]             110\n",
      "    BatchNorm1d-3665                   [-1, 10]              20\n",
      "           ReLU-3666                   [-1, 10]               0\n",
      "        Dropout-3667                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3668                   [-1, 10]               0\n",
      "         Linear-3669                   [-1, 10]             110\n",
      "    BatchNorm1d-3670                   [-1, 10]              20\n",
      "           ReLU-3671                   [-1, 10]               0\n",
      "        Dropout-3672                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3673                   [-1, 10]               0\n",
      "         Linear-3674                   [-1, 10]             110\n",
      "    BatchNorm1d-3675                   [-1, 10]              20\n",
      "           ReLU-3676                   [-1, 10]               0\n",
      "        Dropout-3677                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3678                   [-1, 10]               0\n",
      "         Linear-3679                   [-1, 10]             110\n",
      "    BatchNorm1d-3680                   [-1, 10]              20\n",
      "           ReLU-3681                   [-1, 10]               0\n",
      "        Dropout-3682                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3683                   [-1, 10]               0\n",
      "         Linear-3684                   [-1, 10]             110\n",
      "    BatchNorm1d-3685                   [-1, 10]              20\n",
      "           ReLU-3686                   [-1, 10]               0\n",
      "        Dropout-3687                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3688                   [-1, 10]               0\n",
      "         Linear-3689                   [-1, 10]             110\n",
      "    BatchNorm1d-3690                   [-1, 10]              20\n",
      "           ReLU-3691                   [-1, 10]               0\n",
      "        Dropout-3692                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3693                   [-1, 10]               0\n",
      "         Linear-3694                   [-1, 10]             110\n",
      "    BatchNorm1d-3695                   [-1, 10]              20\n",
      "           ReLU-3696                   [-1, 10]               0\n",
      "        Dropout-3697                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3698                   [-1, 10]               0\n",
      "         Linear-3699                   [-1, 10]             110\n",
      "        Softmax-3700                   [-1, 10]               0\n",
      "         Linear-3701                   [-1, 10]             110\n",
      "    BatchNorm1d-3702                   [-1, 10]              20\n",
      "           ReLU-3703                   [-1, 10]               0\n",
      "        Dropout-3704                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3705                   [-1, 10]               0\n",
      "         Linear-3706                   [-1, 10]             110\n",
      "    BatchNorm1d-3707                   [-1, 10]              20\n",
      "           ReLU-3708                   [-1, 10]               0\n",
      "        Dropout-3709                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3710                   [-1, 10]               0\n",
      "         Linear-3711                   [-1, 10]             110\n",
      "    BatchNorm1d-3712                   [-1, 10]              20\n",
      "           ReLU-3713                   [-1, 10]               0\n",
      "        Dropout-3714                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3715                   [-1, 10]               0\n",
      "         Linear-3716                   [-1, 10]             110\n",
      "    BatchNorm1d-3717                   [-1, 10]              20\n",
      "           ReLU-3718                   [-1, 10]               0\n",
      "        Dropout-3719                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3720                   [-1, 10]               0\n",
      "         Linear-3721                   [-1, 10]             110\n",
      "    BatchNorm1d-3722                   [-1, 10]              20\n",
      "           ReLU-3723                   [-1, 10]               0\n",
      "        Dropout-3724                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3725                   [-1, 10]               0\n",
      "         Linear-3726                   [-1, 10]             110\n",
      "        Softmax-3727                   [-1, 10]               0\n",
      "         Linear-3728                   [-1, 15]             165\n",
      "        Softmax-3729                   [-1, 15]               0\n",
      "         Linear-3730                   [-1, 10]             110\n",
      "    BatchNorm1d-3731                   [-1, 10]              20\n",
      "           ReLU-3732                   [-1, 10]               0\n",
      "        Dropout-3733                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3734                   [-1, 10]               0\n",
      "         Linear-3735                   [-1, 10]             110\n",
      "    BatchNorm1d-3736                   [-1, 10]              20\n",
      "           ReLU-3737                   [-1, 10]               0\n",
      "        Dropout-3738                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3739                   [-1, 10]               0\n",
      "         Linear-3740                   [-1, 10]             110\n",
      "    BatchNorm1d-3741                   [-1, 10]              20\n",
      "           ReLU-3742                   [-1, 10]               0\n",
      "        Dropout-3743                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3744                   [-1, 10]               0\n",
      "         Linear-3745                   [-1, 10]             110\n",
      "    BatchNorm1d-3746                   [-1, 10]              20\n",
      "           ReLU-3747                   [-1, 10]               0\n",
      "        Dropout-3748                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3749                   [-1, 10]               0\n",
      "         Linear-3750                   [-1, 10]             110\n",
      "    BatchNorm1d-3751                   [-1, 10]              20\n",
      "           ReLU-3752                   [-1, 10]               0\n",
      "        Dropout-3753                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3754                   [-1, 10]               0\n",
      "         Linear-3755                   [-1, 10]             110\n",
      "    BatchNorm1d-3756                   [-1, 10]              20\n",
      "           ReLU-3757                   [-1, 10]               0\n",
      "        Dropout-3758                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3759                   [-1, 10]               0\n",
      "         Linear-3760                   [-1, 10]             110\n",
      "    BatchNorm1d-3761                   [-1, 10]              20\n",
      "           ReLU-3762                   [-1, 10]               0\n",
      "        Dropout-3763                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3764                   [-1, 10]               0\n",
      "         Linear-3765                   [-1, 10]             110\n",
      "    BatchNorm1d-3766                   [-1, 10]              20\n",
      "           ReLU-3767                   [-1, 10]               0\n",
      "        Dropout-3768                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3769                   [-1, 10]               0\n",
      "         Linear-3770                   [-1, 10]             110\n",
      "    BatchNorm1d-3771                   [-1, 10]              20\n",
      "           ReLU-3772                   [-1, 10]               0\n",
      "        Dropout-3773                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3774                   [-1, 10]               0\n",
      "         Linear-3775                   [-1, 10]             110\n",
      "    BatchNorm1d-3776                   [-1, 10]              20\n",
      "           ReLU-3777                   [-1, 10]               0\n",
      "        Dropout-3778                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3779                   [-1, 10]               0\n",
      "         Linear-3780                   [-1, 10]             110\n",
      "        Softmax-3781                   [-1, 10]               0\n",
      "         Linear-3782                   [-1, 10]             110\n",
      "    BatchNorm1d-3783                   [-1, 10]              20\n",
      "           ReLU-3784                   [-1, 10]               0\n",
      "        Dropout-3785                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3786                   [-1, 10]               0\n",
      "         Linear-3787                   [-1, 10]             110\n",
      "    BatchNorm1d-3788                   [-1, 10]              20\n",
      "           ReLU-3789                   [-1, 10]               0\n",
      "        Dropout-3790                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3791                   [-1, 10]               0\n",
      "         Linear-3792                   [-1, 10]             110\n",
      "    BatchNorm1d-3793                   [-1, 10]              20\n",
      "           ReLU-3794                   [-1, 10]               0\n",
      "        Dropout-3795                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3796                   [-1, 10]               0\n",
      "         Linear-3797                   [-1, 10]             110\n",
      "    BatchNorm1d-3798                   [-1, 10]              20\n",
      "           ReLU-3799                   [-1, 10]               0\n",
      "        Dropout-3800                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3801                   [-1, 10]               0\n",
      "         Linear-3802                   [-1, 10]             110\n",
      "    BatchNorm1d-3803                   [-1, 10]              20\n",
      "           ReLU-3804                   [-1, 10]               0\n",
      "        Dropout-3805                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3806                   [-1, 10]               0\n",
      "         Linear-3807                   [-1, 10]             110\n",
      "        Softmax-3808                   [-1, 10]               0\n",
      "         Linear-3809                   [-1, 15]             165\n",
      "        Softmax-3810                   [-1, 15]               0\n",
      "         Linear-3811                   [-1, 10]             110\n",
      "    BatchNorm1d-3812                   [-1, 10]              20\n",
      "           ReLU-3813                   [-1, 10]               0\n",
      "        Dropout-3814                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3815                   [-1, 10]               0\n",
      "         Linear-3816                   [-1, 10]             110\n",
      "    BatchNorm1d-3817                   [-1, 10]              20\n",
      "           ReLU-3818                   [-1, 10]               0\n",
      "        Dropout-3819                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3820                   [-1, 10]               0\n",
      "         Linear-3821                   [-1, 10]             110\n",
      "    BatchNorm1d-3822                   [-1, 10]              20\n",
      "           ReLU-3823                   [-1, 10]               0\n",
      "        Dropout-3824                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3825                   [-1, 10]               0\n",
      "         Linear-3826                   [-1, 10]             110\n",
      "    BatchNorm1d-3827                   [-1, 10]              20\n",
      "           ReLU-3828                   [-1, 10]               0\n",
      "        Dropout-3829                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3830                   [-1, 10]               0\n",
      "         Linear-3831                   [-1, 10]             110\n",
      "    BatchNorm1d-3832                   [-1, 10]              20\n",
      "           ReLU-3833                   [-1, 10]               0\n",
      "        Dropout-3834                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3835                   [-1, 10]               0\n",
      "         Linear-3836                   [-1, 10]             110\n",
      "    BatchNorm1d-3837                   [-1, 10]              20\n",
      "           ReLU-3838                   [-1, 10]               0\n",
      "        Dropout-3839                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3840                   [-1, 10]               0\n",
      "         Linear-3841                   [-1, 10]             110\n",
      "    BatchNorm1d-3842                   [-1, 10]              20\n",
      "           ReLU-3843                   [-1, 10]               0\n",
      "        Dropout-3844                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3845                   [-1, 10]               0\n",
      "         Linear-3846                   [-1, 10]             110\n",
      "    BatchNorm1d-3847                   [-1, 10]              20\n",
      "           ReLU-3848                   [-1, 10]               0\n",
      "        Dropout-3849                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3850                   [-1, 10]               0\n",
      "         Linear-3851                   [-1, 10]             110\n",
      "    BatchNorm1d-3852                   [-1, 10]              20\n",
      "           ReLU-3853                   [-1, 10]               0\n",
      "        Dropout-3854                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3855                   [-1, 10]               0\n",
      "         Linear-3856                   [-1, 10]             110\n",
      "    BatchNorm1d-3857                   [-1, 10]              20\n",
      "           ReLU-3858                   [-1, 10]               0\n",
      "        Dropout-3859                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3860                   [-1, 10]               0\n",
      "         Linear-3861                   [-1, 10]             110\n",
      "        Softmax-3862                   [-1, 10]               0\n",
      "         Linear-3863                   [-1, 10]             110\n",
      "    BatchNorm1d-3864                   [-1, 10]              20\n",
      "           ReLU-3865                   [-1, 10]               0\n",
      "        Dropout-3866                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3867                   [-1, 10]               0\n",
      "         Linear-3868                   [-1, 10]             110\n",
      "    BatchNorm1d-3869                   [-1, 10]              20\n",
      "           ReLU-3870                   [-1, 10]               0\n",
      "        Dropout-3871                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3872                   [-1, 10]               0\n",
      "         Linear-3873                   [-1, 10]             110\n",
      "    BatchNorm1d-3874                   [-1, 10]              20\n",
      "           ReLU-3875                   [-1, 10]               0\n",
      "        Dropout-3876                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3877                   [-1, 10]               0\n",
      "         Linear-3878                   [-1, 10]             110\n",
      "    BatchNorm1d-3879                   [-1, 10]              20\n",
      "           ReLU-3880                   [-1, 10]               0\n",
      "        Dropout-3881                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3882                   [-1, 10]               0\n",
      "         Linear-3883                   [-1, 10]             110\n",
      "    BatchNorm1d-3884                   [-1, 10]              20\n",
      "           ReLU-3885                   [-1, 10]               0\n",
      "        Dropout-3886                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3887                   [-1, 10]               0\n",
      "         Linear-3888                   [-1, 10]             110\n",
      "        Softmax-3889                   [-1, 10]               0\n",
      "         Linear-3890                   [-1, 15]             165\n",
      "        Softmax-3891                   [-1, 15]               0\n",
      "         Linear-3892                   [-1, 10]             110\n",
      "    BatchNorm1d-3893                   [-1, 10]              20\n",
      "           ReLU-3894                   [-1, 10]               0\n",
      "        Dropout-3895                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3896                   [-1, 10]               0\n",
      "         Linear-3897                   [-1, 10]             110\n",
      "    BatchNorm1d-3898                   [-1, 10]              20\n",
      "           ReLU-3899                   [-1, 10]               0\n",
      "        Dropout-3900                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3901                   [-1, 10]               0\n",
      "         Linear-3902                   [-1, 10]             110\n",
      "    BatchNorm1d-3903                   [-1, 10]              20\n",
      "           ReLU-3904                   [-1, 10]               0\n",
      "        Dropout-3905                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3906                   [-1, 10]               0\n",
      "         Linear-3907                   [-1, 10]             110\n",
      "    BatchNorm1d-3908                   [-1, 10]              20\n",
      "           ReLU-3909                   [-1, 10]               0\n",
      "        Dropout-3910                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3911                   [-1, 10]               0\n",
      "         Linear-3912                   [-1, 10]             110\n",
      "    BatchNorm1d-3913                   [-1, 10]              20\n",
      "           ReLU-3914                   [-1, 10]               0\n",
      "        Dropout-3915                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3916                   [-1, 10]               0\n",
      "         Linear-3917                   [-1, 10]             110\n",
      "    BatchNorm1d-3918                   [-1, 10]              20\n",
      "           ReLU-3919                   [-1, 10]               0\n",
      "        Dropout-3920                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3921                   [-1, 10]               0\n",
      "         Linear-3922                   [-1, 10]             110\n",
      "    BatchNorm1d-3923                   [-1, 10]              20\n",
      "           ReLU-3924                   [-1, 10]               0\n",
      "        Dropout-3925                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3926                   [-1, 10]               0\n",
      "         Linear-3927                   [-1, 10]             110\n",
      "    BatchNorm1d-3928                   [-1, 10]              20\n",
      "           ReLU-3929                   [-1, 10]               0\n",
      "        Dropout-3930                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3931                   [-1, 10]               0\n",
      "         Linear-3932                   [-1, 10]             110\n",
      "    BatchNorm1d-3933                   [-1, 10]              20\n",
      "           ReLU-3934                   [-1, 10]               0\n",
      "        Dropout-3935                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3936                   [-1, 10]               0\n",
      "         Linear-3937                   [-1, 10]             110\n",
      "    BatchNorm1d-3938                   [-1, 10]              20\n",
      "           ReLU-3939                   [-1, 10]               0\n",
      "        Dropout-3940                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3941                   [-1, 10]               0\n",
      "         Linear-3942                   [-1, 10]             110\n",
      "        Softmax-3943                   [-1, 10]               0\n",
      "         Linear-3944                   [-1, 10]             110\n",
      "    BatchNorm1d-3945                   [-1, 10]              20\n",
      "           ReLU-3946                   [-1, 10]               0\n",
      "        Dropout-3947                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3948                   [-1, 10]               0\n",
      "         Linear-3949                   [-1, 10]             110\n",
      "    BatchNorm1d-3950                   [-1, 10]              20\n",
      "           ReLU-3951                   [-1, 10]               0\n",
      "        Dropout-3952                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3953                   [-1, 10]               0\n",
      "         Linear-3954                   [-1, 10]             110\n",
      "    BatchNorm1d-3955                   [-1, 10]              20\n",
      "           ReLU-3956                   [-1, 10]               0\n",
      "        Dropout-3957                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3958                   [-1, 10]               0\n",
      "         Linear-3959                   [-1, 10]             110\n",
      "    BatchNorm1d-3960                   [-1, 10]              20\n",
      "           ReLU-3961                   [-1, 10]               0\n",
      "        Dropout-3962                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3963                   [-1, 10]               0\n",
      "         Linear-3964                   [-1, 10]             110\n",
      "    BatchNorm1d-3965                   [-1, 10]              20\n",
      "           ReLU-3966                   [-1, 10]               0\n",
      "        Dropout-3967                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3968                   [-1, 10]               0\n",
      "         Linear-3969                   [-1, 10]             110\n",
      "        Softmax-3970                   [-1, 10]               0\n",
      "         Linear-3971                   [-1, 15]             165\n",
      "        Softmax-3972                   [-1, 15]               0\n",
      "         Linear-3973                   [-1, 10]             110\n",
      "    BatchNorm1d-3974                   [-1, 10]              20\n",
      "           ReLU-3975                   [-1, 10]               0\n",
      "        Dropout-3976                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3977                   [-1, 10]               0\n",
      "         Linear-3978                   [-1, 10]             110\n",
      "    BatchNorm1d-3979                   [-1, 10]              20\n",
      "           ReLU-3980                   [-1, 10]               0\n",
      "        Dropout-3981                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3982                   [-1, 10]               0\n",
      "         Linear-3983                   [-1, 10]             110\n",
      "    BatchNorm1d-3984                   [-1, 10]              20\n",
      "           ReLU-3985                   [-1, 10]               0\n",
      "        Dropout-3986                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3987                   [-1, 10]               0\n",
      "         Linear-3988                   [-1, 10]             110\n",
      "    BatchNorm1d-3989                   [-1, 10]              20\n",
      "           ReLU-3990                   [-1, 10]               0\n",
      "        Dropout-3991                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3992                   [-1, 10]               0\n",
      "         Linear-3993                   [-1, 10]             110\n",
      "    BatchNorm1d-3994                   [-1, 10]              20\n",
      "           ReLU-3995                   [-1, 10]               0\n",
      "        Dropout-3996                   [-1, 10]               0\n",
      "MultiLayerPerceptron-3997                   [-1, 10]               0\n",
      "         Linear-3998                   [-1, 10]             110\n",
      "    BatchNorm1d-3999                   [-1, 10]              20\n",
      "           ReLU-4000                   [-1, 10]               0\n",
      "        Dropout-4001                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4002                   [-1, 10]               0\n",
      "         Linear-4003                   [-1, 10]             110\n",
      "    BatchNorm1d-4004                   [-1, 10]              20\n",
      "           ReLU-4005                   [-1, 10]               0\n",
      "        Dropout-4006                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4007                   [-1, 10]               0\n",
      "         Linear-4008                   [-1, 10]             110\n",
      "    BatchNorm1d-4009                   [-1, 10]              20\n",
      "           ReLU-4010                   [-1, 10]               0\n",
      "        Dropout-4011                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4012                   [-1, 10]               0\n",
      "         Linear-4013                   [-1, 10]             110\n",
      "    BatchNorm1d-4014                   [-1, 10]              20\n",
      "           ReLU-4015                   [-1, 10]               0\n",
      "        Dropout-4016                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4017                   [-1, 10]               0\n",
      "         Linear-4018                   [-1, 10]             110\n",
      "    BatchNorm1d-4019                   [-1, 10]              20\n",
      "           ReLU-4020                   [-1, 10]               0\n",
      "        Dropout-4021                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4022                   [-1, 10]               0\n",
      "         Linear-4023                   [-1, 10]             110\n",
      "        Softmax-4024                   [-1, 10]               0\n",
      "         Linear-4025                   [-1, 10]             110\n",
      "    BatchNorm1d-4026                   [-1, 10]              20\n",
      "           ReLU-4027                   [-1, 10]               0\n",
      "        Dropout-4028                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4029                   [-1, 10]               0\n",
      "         Linear-4030                   [-1, 10]             110\n",
      "    BatchNorm1d-4031                   [-1, 10]              20\n",
      "           ReLU-4032                   [-1, 10]               0\n",
      "        Dropout-4033                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4034                   [-1, 10]               0\n",
      "         Linear-4035                   [-1, 10]             110\n",
      "    BatchNorm1d-4036                   [-1, 10]              20\n",
      "           ReLU-4037                   [-1, 10]               0\n",
      "        Dropout-4038                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4039                   [-1, 10]               0\n",
      "         Linear-4040                   [-1, 10]             110\n",
      "    BatchNorm1d-4041                   [-1, 10]              20\n",
      "           ReLU-4042                   [-1, 10]               0\n",
      "        Dropout-4043                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4044                   [-1, 10]               0\n",
      "         Linear-4045                   [-1, 10]             110\n",
      "    BatchNorm1d-4046                   [-1, 10]              20\n",
      "           ReLU-4047                   [-1, 10]               0\n",
      "        Dropout-4048                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4049                   [-1, 10]               0\n",
      "         Linear-4050                   [-1, 10]             110\n",
      "        Softmax-4051                   [-1, 10]               0\n",
      "         Linear-4052                   [-1, 15]             165\n",
      "        Softmax-4053                   [-1, 15]               0\n",
      "         Linear-4054                   [-1, 10]             110\n",
      "    BatchNorm1d-4055                   [-1, 10]              20\n",
      "           ReLU-4056                   [-1, 10]               0\n",
      "        Dropout-4057                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4058                   [-1, 10]               0\n",
      "         Linear-4059                   [-1, 10]             110\n",
      "    BatchNorm1d-4060                   [-1, 10]              20\n",
      "           ReLU-4061                   [-1, 10]               0\n",
      "        Dropout-4062                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4063                   [-1, 10]               0\n",
      "         Linear-4064                   [-1, 10]             110\n",
      "    BatchNorm1d-4065                   [-1, 10]              20\n",
      "           ReLU-4066                   [-1, 10]               0\n",
      "        Dropout-4067                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4068                   [-1, 10]               0\n",
      "         Linear-4069                   [-1, 10]             110\n",
      "    BatchNorm1d-4070                   [-1, 10]              20\n",
      "           ReLU-4071                   [-1, 10]               0\n",
      "        Dropout-4072                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4073                   [-1, 10]               0\n",
      "         Linear-4074                   [-1, 10]             110\n",
      "    BatchNorm1d-4075                   [-1, 10]              20\n",
      "           ReLU-4076                   [-1, 10]               0\n",
      "        Dropout-4077                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4078                   [-1, 10]               0\n",
      "         Linear-4079                   [-1, 10]             110\n",
      "    BatchNorm1d-4080                   [-1, 10]              20\n",
      "           ReLU-4081                   [-1, 10]               0\n",
      "        Dropout-4082                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4083                   [-1, 10]               0\n",
      "         Linear-4084                   [-1, 10]             110\n",
      "    BatchNorm1d-4085                   [-1, 10]              20\n",
      "           ReLU-4086                   [-1, 10]               0\n",
      "        Dropout-4087                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4088                   [-1, 10]               0\n",
      "         Linear-4089                   [-1, 10]             110\n",
      "    BatchNorm1d-4090                   [-1, 10]              20\n",
      "           ReLU-4091                   [-1, 10]               0\n",
      "        Dropout-4092                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4093                   [-1, 10]               0\n",
      "         Linear-4094                   [-1, 10]             110\n",
      "    BatchNorm1d-4095                   [-1, 10]              20\n",
      "           ReLU-4096                   [-1, 10]               0\n",
      "        Dropout-4097                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4098                   [-1, 10]               0\n",
      "         Linear-4099                   [-1, 10]             110\n",
      "    BatchNorm1d-4100                   [-1, 10]              20\n",
      "           ReLU-4101                   [-1, 10]               0\n",
      "        Dropout-4102                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4103                   [-1, 10]               0\n",
      "         Linear-4104                   [-1, 10]             110\n",
      "        Softmax-4105                   [-1, 10]               0\n",
      "         Linear-4106                   [-1, 10]             110\n",
      "    BatchNorm1d-4107                   [-1, 10]              20\n",
      "           ReLU-4108                   [-1, 10]               0\n",
      "        Dropout-4109                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4110                   [-1, 10]               0\n",
      "         Linear-4111                   [-1, 10]             110\n",
      "    BatchNorm1d-4112                   [-1, 10]              20\n",
      "           ReLU-4113                   [-1, 10]               0\n",
      "        Dropout-4114                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4115                   [-1, 10]               0\n",
      "         Linear-4116                   [-1, 10]             110\n",
      "    BatchNorm1d-4117                   [-1, 10]              20\n",
      "           ReLU-4118                   [-1, 10]               0\n",
      "        Dropout-4119                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4120                   [-1, 10]               0\n",
      "         Linear-4121                   [-1, 10]             110\n",
      "    BatchNorm1d-4122                   [-1, 10]              20\n",
      "           ReLU-4123                   [-1, 10]               0\n",
      "        Dropout-4124                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4125                   [-1, 10]               0\n",
      "         Linear-4126                   [-1, 10]             110\n",
      "    BatchNorm1d-4127                   [-1, 10]              20\n",
      "           ReLU-4128                   [-1, 10]               0\n",
      "        Dropout-4129                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4130                   [-1, 10]               0\n",
      "         Linear-4131                   [-1, 10]             110\n",
      "        Softmax-4132                   [-1, 10]               0\n",
      "         Linear-4133                   [-1, 15]             165\n",
      "        Softmax-4134                   [-1, 15]               0\n",
      "         Linear-4135                   [-1, 10]             110\n",
      "    BatchNorm1d-4136                   [-1, 10]              20\n",
      "           ReLU-4137                   [-1, 10]               0\n",
      "        Dropout-4138                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4139                   [-1, 10]               0\n",
      "         Linear-4140                   [-1, 10]             110\n",
      "    BatchNorm1d-4141                   [-1, 10]              20\n",
      "           ReLU-4142                   [-1, 10]               0\n",
      "        Dropout-4143                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4144                   [-1, 10]               0\n",
      "         Linear-4145                   [-1, 10]             110\n",
      "    BatchNorm1d-4146                   [-1, 10]              20\n",
      "           ReLU-4147                   [-1, 10]               0\n",
      "        Dropout-4148                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4149                   [-1, 10]               0\n",
      "         Linear-4150                   [-1, 10]             110\n",
      "    BatchNorm1d-4151                   [-1, 10]              20\n",
      "           ReLU-4152                   [-1, 10]               0\n",
      "        Dropout-4153                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4154                   [-1, 10]               0\n",
      "         Linear-4155                   [-1, 10]             110\n",
      "    BatchNorm1d-4156                   [-1, 10]              20\n",
      "           ReLU-4157                   [-1, 10]               0\n",
      "        Dropout-4158                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4159                   [-1, 10]               0\n",
      "         Linear-4160                   [-1, 10]             110\n",
      "    BatchNorm1d-4161                   [-1, 10]              20\n",
      "           ReLU-4162                   [-1, 10]               0\n",
      "        Dropout-4163                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4164                   [-1, 10]               0\n",
      "         Linear-4165                   [-1, 10]             110\n",
      "    BatchNorm1d-4166                   [-1, 10]              20\n",
      "           ReLU-4167                   [-1, 10]               0\n",
      "        Dropout-4168                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4169                   [-1, 10]               0\n",
      "         Linear-4170                   [-1, 10]             110\n",
      "    BatchNorm1d-4171                   [-1, 10]              20\n",
      "           ReLU-4172                   [-1, 10]               0\n",
      "        Dropout-4173                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4174                   [-1, 10]               0\n",
      "         Linear-4175                   [-1, 10]             110\n",
      "    BatchNorm1d-4176                   [-1, 10]              20\n",
      "           ReLU-4177                   [-1, 10]               0\n",
      "        Dropout-4178                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4179                   [-1, 10]               0\n",
      "         Linear-4180                   [-1, 10]             110\n",
      "    BatchNorm1d-4181                   [-1, 10]              20\n",
      "           ReLU-4182                   [-1, 10]               0\n",
      "        Dropout-4183                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4184                   [-1, 10]               0\n",
      "         Linear-4185                   [-1, 10]             110\n",
      "        Softmax-4186                   [-1, 10]               0\n",
      "         Linear-4187                   [-1, 10]             110\n",
      "    BatchNorm1d-4188                   [-1, 10]              20\n",
      "           ReLU-4189                   [-1, 10]               0\n",
      "        Dropout-4190                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4191                   [-1, 10]               0\n",
      "         Linear-4192                   [-1, 10]             110\n",
      "    BatchNorm1d-4193                   [-1, 10]              20\n",
      "           ReLU-4194                   [-1, 10]               0\n",
      "        Dropout-4195                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4196                   [-1, 10]               0\n",
      "         Linear-4197                   [-1, 10]             110\n",
      "    BatchNorm1d-4198                   [-1, 10]              20\n",
      "           ReLU-4199                   [-1, 10]               0\n",
      "        Dropout-4200                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4201                   [-1, 10]               0\n",
      "         Linear-4202                   [-1, 10]             110\n",
      "    BatchNorm1d-4203                   [-1, 10]              20\n",
      "           ReLU-4204                   [-1, 10]               0\n",
      "        Dropout-4205                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4206                   [-1, 10]               0\n",
      "         Linear-4207                   [-1, 10]             110\n",
      "    BatchNorm1d-4208                   [-1, 10]              20\n",
      "           ReLU-4209                   [-1, 10]               0\n",
      "        Dropout-4210                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4211                   [-1, 10]               0\n",
      "         Linear-4212                   [-1, 10]             110\n",
      "        Softmax-4213                   [-1, 10]               0\n",
      "         Linear-4214                   [-1, 15]             165\n",
      "        Softmax-4215                   [-1, 15]               0\n",
      "         Linear-4216                   [-1, 10]             110\n",
      "    BatchNorm1d-4217                   [-1, 10]              20\n",
      "           ReLU-4218                   [-1, 10]               0\n",
      "        Dropout-4219                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4220                   [-1, 10]               0\n",
      "         Linear-4221                   [-1, 10]             110\n",
      "    BatchNorm1d-4222                   [-1, 10]              20\n",
      "           ReLU-4223                   [-1, 10]               0\n",
      "        Dropout-4224                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4225                   [-1, 10]               0\n",
      "         Linear-4226                   [-1, 10]             110\n",
      "    BatchNorm1d-4227                   [-1, 10]              20\n",
      "           ReLU-4228                   [-1, 10]               0\n",
      "        Dropout-4229                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4230                   [-1, 10]               0\n",
      "         Linear-4231                   [-1, 10]             110\n",
      "    BatchNorm1d-4232                   [-1, 10]              20\n",
      "           ReLU-4233                   [-1, 10]               0\n",
      "        Dropout-4234                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4235                   [-1, 10]               0\n",
      "         Linear-4236                   [-1, 10]             110\n",
      "    BatchNorm1d-4237                   [-1, 10]              20\n",
      "           ReLU-4238                   [-1, 10]               0\n",
      "        Dropout-4239                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4240                   [-1, 10]               0\n",
      "         Linear-4241                   [-1, 10]             110\n",
      "    BatchNorm1d-4242                   [-1, 10]              20\n",
      "           ReLU-4243                   [-1, 10]               0\n",
      "        Dropout-4244                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4245                   [-1, 10]               0\n",
      "         Linear-4246                   [-1, 10]             110\n",
      "    BatchNorm1d-4247                   [-1, 10]              20\n",
      "           ReLU-4248                   [-1, 10]               0\n",
      "        Dropout-4249                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4250                   [-1, 10]               0\n",
      "         Linear-4251                   [-1, 10]             110\n",
      "    BatchNorm1d-4252                   [-1, 10]              20\n",
      "           ReLU-4253                   [-1, 10]               0\n",
      "        Dropout-4254                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4255                   [-1, 10]               0\n",
      "         Linear-4256                   [-1, 10]             110\n",
      "    BatchNorm1d-4257                   [-1, 10]              20\n",
      "           ReLU-4258                   [-1, 10]               0\n",
      "        Dropout-4259                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4260                   [-1, 10]               0\n",
      "         Linear-4261                   [-1, 10]             110\n",
      "    BatchNorm1d-4262                   [-1, 10]              20\n",
      "           ReLU-4263                   [-1, 10]               0\n",
      "        Dropout-4264                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4265                   [-1, 10]               0\n",
      "         Linear-4266                   [-1, 10]             110\n",
      "        Softmax-4267                   [-1, 10]               0\n",
      "         Linear-4268                   [-1, 10]             110\n",
      "    BatchNorm1d-4269                   [-1, 10]              20\n",
      "           ReLU-4270                   [-1, 10]               0\n",
      "        Dropout-4271                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4272                   [-1, 10]               0\n",
      "         Linear-4273                   [-1, 10]             110\n",
      "    BatchNorm1d-4274                   [-1, 10]              20\n",
      "           ReLU-4275                   [-1, 10]               0\n",
      "        Dropout-4276                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4277                   [-1, 10]               0\n",
      "         Linear-4278                   [-1, 10]             110\n",
      "    BatchNorm1d-4279                   [-1, 10]              20\n",
      "           ReLU-4280                   [-1, 10]               0\n",
      "        Dropout-4281                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4282                   [-1, 10]               0\n",
      "         Linear-4283                   [-1, 10]             110\n",
      "    BatchNorm1d-4284                   [-1, 10]              20\n",
      "           ReLU-4285                   [-1, 10]               0\n",
      "        Dropout-4286                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4287                   [-1, 10]               0\n",
      "         Linear-4288                   [-1, 10]             110\n",
      "    BatchNorm1d-4289                   [-1, 10]              20\n",
      "           ReLU-4290                   [-1, 10]               0\n",
      "        Dropout-4291                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4292                   [-1, 10]               0\n",
      "         Linear-4293                   [-1, 10]             110\n",
      "        Softmax-4294                   [-1, 10]               0\n",
      "         Linear-4295                   [-1, 15]             165\n",
      "        Softmax-4296                   [-1, 15]               0\n",
      "         Linear-4297                   [-1, 10]             110\n",
      "    BatchNorm1d-4298                   [-1, 10]              20\n",
      "           ReLU-4299                   [-1, 10]               0\n",
      "        Dropout-4300                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4301                   [-1, 10]               0\n",
      "         Linear-4302                   [-1, 10]             110\n",
      "    BatchNorm1d-4303                   [-1, 10]              20\n",
      "           ReLU-4304                   [-1, 10]               0\n",
      "        Dropout-4305                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4306                   [-1, 10]               0\n",
      "         Linear-4307                   [-1, 10]             110\n",
      "    BatchNorm1d-4308                   [-1, 10]              20\n",
      "           ReLU-4309                   [-1, 10]               0\n",
      "        Dropout-4310                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4311                   [-1, 10]               0\n",
      "         Linear-4312                   [-1, 10]             110\n",
      "    BatchNorm1d-4313                   [-1, 10]              20\n",
      "           ReLU-4314                   [-1, 10]               0\n",
      "        Dropout-4315                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4316                   [-1, 10]               0\n",
      "         Linear-4317                   [-1, 10]             110\n",
      "    BatchNorm1d-4318                   [-1, 10]              20\n",
      "           ReLU-4319                   [-1, 10]               0\n",
      "        Dropout-4320                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4321                   [-1, 10]               0\n",
      "         Linear-4322                   [-1, 10]             110\n",
      "    BatchNorm1d-4323                   [-1, 10]              20\n",
      "           ReLU-4324                   [-1, 10]               0\n",
      "        Dropout-4325                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4326                   [-1, 10]               0\n",
      "         Linear-4327                   [-1, 10]             110\n",
      "    BatchNorm1d-4328                   [-1, 10]              20\n",
      "           ReLU-4329                   [-1, 10]               0\n",
      "        Dropout-4330                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4331                   [-1, 10]               0\n",
      "         Linear-4332                   [-1, 10]             110\n",
      "    BatchNorm1d-4333                   [-1, 10]              20\n",
      "           ReLU-4334                   [-1, 10]               0\n",
      "        Dropout-4335                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4336                   [-1, 10]               0\n",
      "         Linear-4337                   [-1, 10]             110\n",
      "    BatchNorm1d-4338                   [-1, 10]              20\n",
      "           ReLU-4339                   [-1, 10]               0\n",
      "        Dropout-4340                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4341                   [-1, 10]               0\n",
      "         Linear-4342                   [-1, 10]             110\n",
      "    BatchNorm1d-4343                   [-1, 10]              20\n",
      "           ReLU-4344                   [-1, 10]               0\n",
      "        Dropout-4345                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4346                   [-1, 10]               0\n",
      "         Linear-4347                   [-1, 10]             110\n",
      "        Softmax-4348                   [-1, 10]               0\n",
      "         Linear-4349                   [-1, 10]             110\n",
      "    BatchNorm1d-4350                   [-1, 10]              20\n",
      "           ReLU-4351                   [-1, 10]               0\n",
      "        Dropout-4352                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4353                   [-1, 10]               0\n",
      "         Linear-4354                   [-1, 10]             110\n",
      "    BatchNorm1d-4355                   [-1, 10]              20\n",
      "           ReLU-4356                   [-1, 10]               0\n",
      "        Dropout-4357                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4358                   [-1, 10]               0\n",
      "         Linear-4359                   [-1, 10]             110\n",
      "    BatchNorm1d-4360                   [-1, 10]              20\n",
      "           ReLU-4361                   [-1, 10]               0\n",
      "        Dropout-4362                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4363                   [-1, 10]               0\n",
      "         Linear-4364                   [-1, 10]             110\n",
      "    BatchNorm1d-4365                   [-1, 10]              20\n",
      "           ReLU-4366                   [-1, 10]               0\n",
      "        Dropout-4367                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4368                   [-1, 10]               0\n",
      "         Linear-4369                   [-1, 10]             110\n",
      "    BatchNorm1d-4370                   [-1, 10]              20\n",
      "           ReLU-4371                   [-1, 10]               0\n",
      "        Dropout-4372                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4373                   [-1, 10]               0\n",
      "         Linear-4374                   [-1, 10]             110\n",
      "        Softmax-4375                   [-1, 10]               0\n",
      "         Linear-4376                   [-1, 15]             165\n",
      "        Softmax-4377                   [-1, 15]               0\n",
      "         Linear-4378                   [-1, 10]             110\n",
      "    BatchNorm1d-4379                   [-1, 10]              20\n",
      "           ReLU-4380                   [-1, 10]               0\n",
      "        Dropout-4381                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4382                   [-1, 10]               0\n",
      "         Linear-4383                   [-1, 10]             110\n",
      "    BatchNorm1d-4384                   [-1, 10]              20\n",
      "           ReLU-4385                   [-1, 10]               0\n",
      "        Dropout-4386                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4387                   [-1, 10]               0\n",
      "         Linear-4388                   [-1, 10]             110\n",
      "    BatchNorm1d-4389                   [-1, 10]              20\n",
      "           ReLU-4390                   [-1, 10]               0\n",
      "        Dropout-4391                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4392                   [-1, 10]               0\n",
      "         Linear-4393                   [-1, 10]             110\n",
      "    BatchNorm1d-4394                   [-1, 10]              20\n",
      "           ReLU-4395                   [-1, 10]               0\n",
      "        Dropout-4396                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4397                   [-1, 10]               0\n",
      "         Linear-4398                   [-1, 10]             110\n",
      "    BatchNorm1d-4399                   [-1, 10]              20\n",
      "           ReLU-4400                   [-1, 10]               0\n",
      "        Dropout-4401                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4402                   [-1, 10]               0\n",
      "         Linear-4403                   [-1, 10]             110\n",
      "    BatchNorm1d-4404                   [-1, 10]              20\n",
      "           ReLU-4405                   [-1, 10]               0\n",
      "        Dropout-4406                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4407                   [-1, 10]               0\n",
      "         Linear-4408                   [-1, 10]             110\n",
      "    BatchNorm1d-4409                   [-1, 10]              20\n",
      "           ReLU-4410                   [-1, 10]               0\n",
      "        Dropout-4411                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4412                   [-1, 10]               0\n",
      "         Linear-4413                   [-1, 10]             110\n",
      "    BatchNorm1d-4414                   [-1, 10]              20\n",
      "           ReLU-4415                   [-1, 10]               0\n",
      "        Dropout-4416                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4417                   [-1, 10]               0\n",
      "         Linear-4418                   [-1, 10]             110\n",
      "    BatchNorm1d-4419                   [-1, 10]              20\n",
      "           ReLU-4420                   [-1, 10]               0\n",
      "        Dropout-4421                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4422                   [-1, 10]               0\n",
      "         Linear-4423                   [-1, 10]             110\n",
      "    BatchNorm1d-4424                   [-1, 10]              20\n",
      "           ReLU-4425                   [-1, 10]               0\n",
      "        Dropout-4426                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4427                   [-1, 10]               0\n",
      "         Linear-4428                   [-1, 10]             110\n",
      "        Softmax-4429                   [-1, 10]               0\n",
      "         Linear-4430                   [-1, 10]             110\n",
      "    BatchNorm1d-4431                   [-1, 10]              20\n",
      "           ReLU-4432                   [-1, 10]               0\n",
      "        Dropout-4433                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4434                   [-1, 10]               0\n",
      "         Linear-4435                   [-1, 10]             110\n",
      "    BatchNorm1d-4436                   [-1, 10]              20\n",
      "           ReLU-4437                   [-1, 10]               0\n",
      "        Dropout-4438                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4439                   [-1, 10]               0\n",
      "         Linear-4440                   [-1, 10]             110\n",
      "    BatchNorm1d-4441                   [-1, 10]              20\n",
      "           ReLU-4442                   [-1, 10]               0\n",
      "        Dropout-4443                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4444                   [-1, 10]               0\n",
      "         Linear-4445                   [-1, 10]             110\n",
      "    BatchNorm1d-4446                   [-1, 10]              20\n",
      "           ReLU-4447                   [-1, 10]               0\n",
      "        Dropout-4448                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4449                   [-1, 10]               0\n",
      "         Linear-4450                   [-1, 10]             110\n",
      "    BatchNorm1d-4451                   [-1, 10]              20\n",
      "           ReLU-4452                   [-1, 10]               0\n",
      "        Dropout-4453                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4454                   [-1, 10]               0\n",
      "         Linear-4455                   [-1, 10]             110\n",
      "        Softmax-4456                   [-1, 10]               0\n",
      "         Linear-4457                   [-1, 15]             165\n",
      "        Softmax-4458                   [-1, 15]               0\n",
      "         Linear-4459                   [-1, 10]             110\n",
      "    BatchNorm1d-4460                   [-1, 10]              20\n",
      "           ReLU-4461                   [-1, 10]               0\n",
      "        Dropout-4462                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4463                   [-1, 10]               0\n",
      "         Linear-4464                   [-1, 10]             110\n",
      "    BatchNorm1d-4465                   [-1, 10]              20\n",
      "           ReLU-4466                   [-1, 10]               0\n",
      "        Dropout-4467                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4468                   [-1, 10]               0\n",
      "         Linear-4469                   [-1, 10]             110\n",
      "    BatchNorm1d-4470                   [-1, 10]              20\n",
      "           ReLU-4471                   [-1, 10]               0\n",
      "        Dropout-4472                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4473                   [-1, 10]               0\n",
      "         Linear-4474                   [-1, 10]             110\n",
      "    BatchNorm1d-4475                   [-1, 10]              20\n",
      "           ReLU-4476                   [-1, 10]               0\n",
      "        Dropout-4477                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4478                   [-1, 10]               0\n",
      "         Linear-4479                   [-1, 10]             110\n",
      "    BatchNorm1d-4480                   [-1, 10]              20\n",
      "           ReLU-4481                   [-1, 10]               0\n",
      "        Dropout-4482                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4483                   [-1, 10]               0\n",
      "         Linear-4484                   [-1, 10]             110\n",
      "    BatchNorm1d-4485                   [-1, 10]              20\n",
      "           ReLU-4486                   [-1, 10]               0\n",
      "        Dropout-4487                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4488                   [-1, 10]               0\n",
      "         Linear-4489                   [-1, 10]             110\n",
      "    BatchNorm1d-4490                   [-1, 10]              20\n",
      "           ReLU-4491                   [-1, 10]               0\n",
      "        Dropout-4492                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4493                   [-1, 10]               0\n",
      "         Linear-4494                   [-1, 10]             110\n",
      "    BatchNorm1d-4495                   [-1, 10]              20\n",
      "           ReLU-4496                   [-1, 10]               0\n",
      "        Dropout-4497                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4498                   [-1, 10]               0\n",
      "         Linear-4499                   [-1, 10]             110\n",
      "    BatchNorm1d-4500                   [-1, 10]              20\n",
      "           ReLU-4501                   [-1, 10]               0\n",
      "        Dropout-4502                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4503                   [-1, 10]               0\n",
      "         Linear-4504                   [-1, 10]             110\n",
      "    BatchNorm1d-4505                   [-1, 10]              20\n",
      "           ReLU-4506                   [-1, 10]               0\n",
      "        Dropout-4507                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4508                   [-1, 10]               0\n",
      "         Linear-4509                   [-1, 10]             110\n",
      "        Softmax-4510                   [-1, 10]               0\n",
      "         Linear-4511                   [-1, 10]             110\n",
      "    BatchNorm1d-4512                   [-1, 10]              20\n",
      "           ReLU-4513                   [-1, 10]               0\n",
      "        Dropout-4514                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4515                   [-1, 10]               0\n",
      "         Linear-4516                   [-1, 10]             110\n",
      "    BatchNorm1d-4517                   [-1, 10]              20\n",
      "           ReLU-4518                   [-1, 10]               0\n",
      "        Dropout-4519                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4520                   [-1, 10]               0\n",
      "         Linear-4521                   [-1, 10]             110\n",
      "    BatchNorm1d-4522                   [-1, 10]              20\n",
      "           ReLU-4523                   [-1, 10]               0\n",
      "        Dropout-4524                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4525                   [-1, 10]               0\n",
      "         Linear-4526                   [-1, 10]             110\n",
      "    BatchNorm1d-4527                   [-1, 10]              20\n",
      "           ReLU-4528                   [-1, 10]               0\n",
      "        Dropout-4529                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4530                   [-1, 10]               0\n",
      "         Linear-4531                   [-1, 10]             110\n",
      "    BatchNorm1d-4532                   [-1, 10]              20\n",
      "           ReLU-4533                   [-1, 10]               0\n",
      "        Dropout-4534                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4535                   [-1, 10]               0\n",
      "         Linear-4536                   [-1, 10]             110\n",
      "        Softmax-4537                   [-1, 10]               0\n",
      "         Linear-4538                   [-1, 15]             165\n",
      "        Softmax-4539                   [-1, 15]               0\n",
      "         Linear-4540                   [-1, 10]             110\n",
      "    BatchNorm1d-4541                   [-1, 10]              20\n",
      "           ReLU-4542                   [-1, 10]               0\n",
      "        Dropout-4543                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4544                   [-1, 10]               0\n",
      "         Linear-4545                   [-1, 10]             110\n",
      "    BatchNorm1d-4546                   [-1, 10]              20\n",
      "           ReLU-4547                   [-1, 10]               0\n",
      "        Dropout-4548                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4549                   [-1, 10]               0\n",
      "         Linear-4550                   [-1, 10]             110\n",
      "    BatchNorm1d-4551                   [-1, 10]              20\n",
      "           ReLU-4552                   [-1, 10]               0\n",
      "        Dropout-4553                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4554                   [-1, 10]               0\n",
      "         Linear-4555                   [-1, 10]             110\n",
      "    BatchNorm1d-4556                   [-1, 10]              20\n",
      "           ReLU-4557                   [-1, 10]               0\n",
      "        Dropout-4558                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4559                   [-1, 10]               0\n",
      "         Linear-4560                   [-1, 10]             110\n",
      "    BatchNorm1d-4561                   [-1, 10]              20\n",
      "           ReLU-4562                   [-1, 10]               0\n",
      "        Dropout-4563                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4564                   [-1, 10]               0\n",
      "         Linear-4565                   [-1, 10]             110\n",
      "    BatchNorm1d-4566                   [-1, 10]              20\n",
      "           ReLU-4567                   [-1, 10]               0\n",
      "        Dropout-4568                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4569                   [-1, 10]               0\n",
      "         Linear-4570                   [-1, 10]             110\n",
      "    BatchNorm1d-4571                   [-1, 10]              20\n",
      "           ReLU-4572                   [-1, 10]               0\n",
      "        Dropout-4573                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4574                   [-1, 10]               0\n",
      "         Linear-4575                   [-1, 10]             110\n",
      "    BatchNorm1d-4576                   [-1, 10]              20\n",
      "           ReLU-4577                   [-1, 10]               0\n",
      "        Dropout-4578                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4579                   [-1, 10]               0\n",
      "         Linear-4580                   [-1, 10]             110\n",
      "    BatchNorm1d-4581                   [-1, 10]              20\n",
      "           ReLU-4582                   [-1, 10]               0\n",
      "        Dropout-4583                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4584                   [-1, 10]               0\n",
      "         Linear-4585                   [-1, 10]             110\n",
      "    BatchNorm1d-4586                   [-1, 10]              20\n",
      "           ReLU-4587                   [-1, 10]               0\n",
      "        Dropout-4588                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4589                   [-1, 10]               0\n",
      "         Linear-4590                   [-1, 10]             110\n",
      "        Softmax-4591                   [-1, 10]               0\n",
      "         Linear-4592                   [-1, 10]             110\n",
      "    BatchNorm1d-4593                   [-1, 10]              20\n",
      "           ReLU-4594                   [-1, 10]               0\n",
      "        Dropout-4595                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4596                   [-1, 10]               0\n",
      "         Linear-4597                   [-1, 10]             110\n",
      "    BatchNorm1d-4598                   [-1, 10]              20\n",
      "           ReLU-4599                   [-1, 10]               0\n",
      "        Dropout-4600                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4601                   [-1, 10]               0\n",
      "         Linear-4602                   [-1, 10]             110\n",
      "    BatchNorm1d-4603                   [-1, 10]              20\n",
      "           ReLU-4604                   [-1, 10]               0\n",
      "        Dropout-4605                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4606                   [-1, 10]               0\n",
      "         Linear-4607                   [-1, 10]             110\n",
      "    BatchNorm1d-4608                   [-1, 10]              20\n",
      "           ReLU-4609                   [-1, 10]               0\n",
      "        Dropout-4610                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4611                   [-1, 10]               0\n",
      "         Linear-4612                   [-1, 10]             110\n",
      "    BatchNorm1d-4613                   [-1, 10]              20\n",
      "           ReLU-4614                   [-1, 10]               0\n",
      "        Dropout-4615                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4616                   [-1, 10]               0\n",
      "         Linear-4617                   [-1, 10]             110\n",
      "        Softmax-4618                   [-1, 10]               0\n",
      "         Linear-4619                   [-1, 15]             165\n",
      "        Softmax-4620                   [-1, 15]               0\n",
      "         Linear-4621                   [-1, 10]             110\n",
      "    BatchNorm1d-4622                   [-1, 10]              20\n",
      "           ReLU-4623                   [-1, 10]               0\n",
      "        Dropout-4624                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4625                   [-1, 10]               0\n",
      "         Linear-4626                   [-1, 10]             110\n",
      "    BatchNorm1d-4627                   [-1, 10]              20\n",
      "           ReLU-4628                   [-1, 10]               0\n",
      "        Dropout-4629                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4630                   [-1, 10]               0\n",
      "         Linear-4631                   [-1, 10]             110\n",
      "    BatchNorm1d-4632                   [-1, 10]              20\n",
      "           ReLU-4633                   [-1, 10]               0\n",
      "        Dropout-4634                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4635                   [-1, 10]               0\n",
      "         Linear-4636                   [-1, 10]             110\n",
      "    BatchNorm1d-4637                   [-1, 10]              20\n",
      "           ReLU-4638                   [-1, 10]               0\n",
      "        Dropout-4639                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4640                   [-1, 10]               0\n",
      "         Linear-4641                   [-1, 10]             110\n",
      "    BatchNorm1d-4642                   [-1, 10]              20\n",
      "           ReLU-4643                   [-1, 10]               0\n",
      "        Dropout-4644                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4645                   [-1, 10]               0\n",
      "         Linear-4646                   [-1, 10]             110\n",
      "    BatchNorm1d-4647                   [-1, 10]              20\n",
      "           ReLU-4648                   [-1, 10]               0\n",
      "        Dropout-4649                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4650                   [-1, 10]               0\n",
      "         Linear-4651                   [-1, 10]             110\n",
      "    BatchNorm1d-4652                   [-1, 10]              20\n",
      "           ReLU-4653                   [-1, 10]               0\n",
      "        Dropout-4654                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4655                   [-1, 10]               0\n",
      "         Linear-4656                   [-1, 10]             110\n",
      "    BatchNorm1d-4657                   [-1, 10]              20\n",
      "           ReLU-4658                   [-1, 10]               0\n",
      "        Dropout-4659                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4660                   [-1, 10]               0\n",
      "         Linear-4661                   [-1, 10]             110\n",
      "    BatchNorm1d-4662                   [-1, 10]              20\n",
      "           ReLU-4663                   [-1, 10]               0\n",
      "        Dropout-4664                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4665                   [-1, 10]               0\n",
      "         Linear-4666                   [-1, 10]             110\n",
      "    BatchNorm1d-4667                   [-1, 10]              20\n",
      "           ReLU-4668                   [-1, 10]               0\n",
      "        Dropout-4669                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4670                   [-1, 10]               0\n",
      "         Linear-4671                   [-1, 10]             110\n",
      "        Softmax-4672                   [-1, 10]               0\n",
      "         Linear-4673                   [-1, 10]             110\n",
      "    BatchNorm1d-4674                   [-1, 10]              20\n",
      "           ReLU-4675                   [-1, 10]               0\n",
      "        Dropout-4676                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4677                   [-1, 10]               0\n",
      "         Linear-4678                   [-1, 10]             110\n",
      "    BatchNorm1d-4679                   [-1, 10]              20\n",
      "           ReLU-4680                   [-1, 10]               0\n",
      "        Dropout-4681                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4682                   [-1, 10]               0\n",
      "         Linear-4683                   [-1, 10]             110\n",
      "    BatchNorm1d-4684                   [-1, 10]              20\n",
      "           ReLU-4685                   [-1, 10]               0\n",
      "        Dropout-4686                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4687                   [-1, 10]               0\n",
      "         Linear-4688                   [-1, 10]             110\n",
      "    BatchNorm1d-4689                   [-1, 10]              20\n",
      "           ReLU-4690                   [-1, 10]               0\n",
      "        Dropout-4691                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4692                   [-1, 10]               0\n",
      "         Linear-4693                   [-1, 10]             110\n",
      "    BatchNorm1d-4694                   [-1, 10]              20\n",
      "           ReLU-4695                   [-1, 10]               0\n",
      "        Dropout-4696                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4697                   [-1, 10]               0\n",
      "         Linear-4698                   [-1, 10]             110\n",
      "        Softmax-4699                   [-1, 10]               0\n",
      "         Linear-4700                   [-1, 15]             165\n",
      "        Softmax-4701                   [-1, 15]               0\n",
      "         Linear-4702                   [-1, 10]             110\n",
      "    BatchNorm1d-4703                   [-1, 10]              20\n",
      "           ReLU-4704                   [-1, 10]               0\n",
      "        Dropout-4705                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4706                   [-1, 10]               0\n",
      "         Linear-4707                   [-1, 10]             110\n",
      "    BatchNorm1d-4708                   [-1, 10]              20\n",
      "           ReLU-4709                   [-1, 10]               0\n",
      "        Dropout-4710                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4711                   [-1, 10]               0\n",
      "         Linear-4712                   [-1, 10]             110\n",
      "    BatchNorm1d-4713                   [-1, 10]              20\n",
      "           ReLU-4714                   [-1, 10]               0\n",
      "        Dropout-4715                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4716                   [-1, 10]               0\n",
      "         Linear-4717                   [-1, 10]             110\n",
      "    BatchNorm1d-4718                   [-1, 10]              20\n",
      "           ReLU-4719                   [-1, 10]               0\n",
      "        Dropout-4720                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4721                   [-1, 10]               0\n",
      "         Linear-4722                   [-1, 10]             110\n",
      "    BatchNorm1d-4723                   [-1, 10]              20\n",
      "           ReLU-4724                   [-1, 10]               0\n",
      "        Dropout-4725                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4726                   [-1, 10]               0\n",
      "         Linear-4727                   [-1, 10]             110\n",
      "    BatchNorm1d-4728                   [-1, 10]              20\n",
      "           ReLU-4729                   [-1, 10]               0\n",
      "        Dropout-4730                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4731                   [-1, 10]               0\n",
      "         Linear-4732                   [-1, 10]             110\n",
      "    BatchNorm1d-4733                   [-1, 10]              20\n",
      "           ReLU-4734                   [-1, 10]               0\n",
      "        Dropout-4735                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4736                   [-1, 10]               0\n",
      "         Linear-4737                   [-1, 10]             110\n",
      "    BatchNorm1d-4738                   [-1, 10]              20\n",
      "           ReLU-4739                   [-1, 10]               0\n",
      "        Dropout-4740                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4741                   [-1, 10]               0\n",
      "         Linear-4742                   [-1, 10]             110\n",
      "    BatchNorm1d-4743                   [-1, 10]              20\n",
      "           ReLU-4744                   [-1, 10]               0\n",
      "        Dropout-4745                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4746                   [-1, 10]               0\n",
      "         Linear-4747                   [-1, 10]             110\n",
      "    BatchNorm1d-4748                   [-1, 10]              20\n",
      "           ReLU-4749                   [-1, 10]               0\n",
      "        Dropout-4750                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4751                   [-1, 10]               0\n",
      "         Linear-4752                   [-1, 10]             110\n",
      "        Softmax-4753                   [-1, 10]               0\n",
      "         Linear-4754                   [-1, 10]             110\n",
      "    BatchNorm1d-4755                   [-1, 10]              20\n",
      "           ReLU-4756                   [-1, 10]               0\n",
      "        Dropout-4757                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4758                   [-1, 10]               0\n",
      "         Linear-4759                   [-1, 10]             110\n",
      "    BatchNorm1d-4760                   [-1, 10]              20\n",
      "           ReLU-4761                   [-1, 10]               0\n",
      "        Dropout-4762                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4763                   [-1, 10]               0\n",
      "         Linear-4764                   [-1, 10]             110\n",
      "    BatchNorm1d-4765                   [-1, 10]              20\n",
      "           ReLU-4766                   [-1, 10]               0\n",
      "        Dropout-4767                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4768                   [-1, 10]               0\n",
      "         Linear-4769                   [-1, 10]             110\n",
      "    BatchNorm1d-4770                   [-1, 10]              20\n",
      "           ReLU-4771                   [-1, 10]               0\n",
      "        Dropout-4772                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4773                   [-1, 10]               0\n",
      "         Linear-4774                   [-1, 10]             110\n",
      "    BatchNorm1d-4775                   [-1, 10]              20\n",
      "           ReLU-4776                   [-1, 10]               0\n",
      "        Dropout-4777                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4778                   [-1, 10]               0\n",
      "         Linear-4779                   [-1, 10]             110\n",
      "        Softmax-4780                   [-1, 10]               0\n",
      "         Linear-4781                   [-1, 15]             165\n",
      "        Softmax-4782                   [-1, 15]               0\n",
      "         Linear-4783                   [-1, 10]             110\n",
      "    BatchNorm1d-4784                   [-1, 10]              20\n",
      "           ReLU-4785                   [-1, 10]               0\n",
      "        Dropout-4786                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4787                   [-1, 10]               0\n",
      "         Linear-4788                   [-1, 10]             110\n",
      "    BatchNorm1d-4789                   [-1, 10]              20\n",
      "           ReLU-4790                   [-1, 10]               0\n",
      "        Dropout-4791                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4792                   [-1, 10]               0\n",
      "         Linear-4793                   [-1, 10]             110\n",
      "    BatchNorm1d-4794                   [-1, 10]              20\n",
      "           ReLU-4795                   [-1, 10]               0\n",
      "        Dropout-4796                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4797                   [-1, 10]               0\n",
      "         Linear-4798                   [-1, 10]             110\n",
      "    BatchNorm1d-4799                   [-1, 10]              20\n",
      "           ReLU-4800                   [-1, 10]               0\n",
      "        Dropout-4801                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4802                   [-1, 10]               0\n",
      "         Linear-4803                   [-1, 10]             110\n",
      "    BatchNorm1d-4804                   [-1, 10]              20\n",
      "           ReLU-4805                   [-1, 10]               0\n",
      "        Dropout-4806                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4807                   [-1, 10]               0\n",
      "         Linear-4808                   [-1, 10]             110\n",
      "    BatchNorm1d-4809                   [-1, 10]              20\n",
      "           ReLU-4810                   [-1, 10]               0\n",
      "        Dropout-4811                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4812                   [-1, 10]               0\n",
      "         Linear-4813                   [-1, 10]             110\n",
      "    BatchNorm1d-4814                   [-1, 10]              20\n",
      "           ReLU-4815                   [-1, 10]               0\n",
      "        Dropout-4816                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4817                   [-1, 10]               0\n",
      "         Linear-4818                   [-1, 10]             110\n",
      "    BatchNorm1d-4819                   [-1, 10]              20\n",
      "           ReLU-4820                   [-1, 10]               0\n",
      "        Dropout-4821                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4822                   [-1, 10]               0\n",
      "         Linear-4823                   [-1, 10]             110\n",
      "    BatchNorm1d-4824                   [-1, 10]              20\n",
      "           ReLU-4825                   [-1, 10]               0\n",
      "        Dropout-4826                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4827                   [-1, 10]               0\n",
      "         Linear-4828                   [-1, 10]             110\n",
      "    BatchNorm1d-4829                   [-1, 10]              20\n",
      "           ReLU-4830                   [-1, 10]               0\n",
      "        Dropout-4831                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4832                   [-1, 10]               0\n",
      "         Linear-4833                   [-1, 10]             110\n",
      "        Softmax-4834                   [-1, 10]               0\n",
      "         Linear-4835                   [-1, 10]             110\n",
      "    BatchNorm1d-4836                   [-1, 10]              20\n",
      "           ReLU-4837                   [-1, 10]               0\n",
      "        Dropout-4838                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4839                   [-1, 10]               0\n",
      "         Linear-4840                   [-1, 10]             110\n",
      "    BatchNorm1d-4841                   [-1, 10]              20\n",
      "           ReLU-4842                   [-1, 10]               0\n",
      "        Dropout-4843                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4844                   [-1, 10]               0\n",
      "         Linear-4845                   [-1, 10]             110\n",
      "    BatchNorm1d-4846                   [-1, 10]              20\n",
      "           ReLU-4847                   [-1, 10]               0\n",
      "        Dropout-4848                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4849                   [-1, 10]               0\n",
      "         Linear-4850                   [-1, 10]             110\n",
      "    BatchNorm1d-4851                   [-1, 10]              20\n",
      "           ReLU-4852                   [-1, 10]               0\n",
      "        Dropout-4853                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4854                   [-1, 10]               0\n",
      "         Linear-4855                   [-1, 10]             110\n",
      "    BatchNorm1d-4856                   [-1, 10]              20\n",
      "           ReLU-4857                   [-1, 10]               0\n",
      "        Dropout-4858                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4859                   [-1, 10]               0\n",
      "         Linear-4860                   [-1, 10]             110\n",
      "        Softmax-4861                   [-1, 10]               0\n",
      "         Linear-4862                   [-1, 15]             165\n",
      "        Softmax-4863                   [-1, 15]               0\n",
      "         Linear-4864                   [-1, 10]             110\n",
      "    BatchNorm1d-4865                   [-1, 10]              20\n",
      "           ReLU-4866                   [-1, 10]               0\n",
      "        Dropout-4867                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4868                   [-1, 10]               0\n",
      "         Linear-4869                   [-1, 10]             110\n",
      "    BatchNorm1d-4870                   [-1, 10]              20\n",
      "           ReLU-4871                   [-1, 10]               0\n",
      "        Dropout-4872                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4873                   [-1, 10]               0\n",
      "         Linear-4874                   [-1, 10]             110\n",
      "    BatchNorm1d-4875                   [-1, 10]              20\n",
      "           ReLU-4876                   [-1, 10]               0\n",
      "        Dropout-4877                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4878                   [-1, 10]               0\n",
      "         Linear-4879                   [-1, 10]             110\n",
      "    BatchNorm1d-4880                   [-1, 10]              20\n",
      "           ReLU-4881                   [-1, 10]               0\n",
      "        Dropout-4882                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4883                   [-1, 10]               0\n",
      "         Linear-4884                   [-1, 10]             110\n",
      "    BatchNorm1d-4885                   [-1, 10]              20\n",
      "           ReLU-4886                   [-1, 10]               0\n",
      "        Dropout-4887                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4888                   [-1, 10]               0\n",
      "         Linear-4889                   [-1, 10]             110\n",
      "    BatchNorm1d-4890                   [-1, 10]              20\n",
      "           ReLU-4891                   [-1, 10]               0\n",
      "        Dropout-4892                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4893                   [-1, 10]               0\n",
      "         Linear-4894                   [-1, 10]             110\n",
      "    BatchNorm1d-4895                   [-1, 10]              20\n",
      "           ReLU-4896                   [-1, 10]               0\n",
      "        Dropout-4897                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4898                   [-1, 10]               0\n",
      "         Linear-4899                   [-1, 10]             110\n",
      "    BatchNorm1d-4900                   [-1, 10]              20\n",
      "           ReLU-4901                   [-1, 10]               0\n",
      "        Dropout-4902                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4903                   [-1, 10]               0\n",
      "         Linear-4904                   [-1, 10]             110\n",
      "    BatchNorm1d-4905                   [-1, 10]              20\n",
      "           ReLU-4906                   [-1, 10]               0\n",
      "        Dropout-4907                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4908                   [-1, 10]               0\n",
      "         Linear-4909                   [-1, 10]             110\n",
      "    BatchNorm1d-4910                   [-1, 10]              20\n",
      "           ReLU-4911                   [-1, 10]               0\n",
      "        Dropout-4912                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4913                   [-1, 10]               0\n",
      "         Linear-4914                   [-1, 10]             110\n",
      "        Softmax-4915                   [-1, 10]               0\n",
      "         Linear-4916                   [-1, 10]             110\n",
      "    BatchNorm1d-4917                   [-1, 10]              20\n",
      "           ReLU-4918                   [-1, 10]               0\n",
      "        Dropout-4919                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4920                   [-1, 10]               0\n",
      "         Linear-4921                   [-1, 10]             110\n",
      "    BatchNorm1d-4922                   [-1, 10]              20\n",
      "           ReLU-4923                   [-1, 10]               0\n",
      "        Dropout-4924                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4925                   [-1, 10]               0\n",
      "         Linear-4926                   [-1, 10]             110\n",
      "    BatchNorm1d-4927                   [-1, 10]              20\n",
      "           ReLU-4928                   [-1, 10]               0\n",
      "        Dropout-4929                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4930                   [-1, 10]               0\n",
      "         Linear-4931                   [-1, 10]             110\n",
      "    BatchNorm1d-4932                   [-1, 10]              20\n",
      "           ReLU-4933                   [-1, 10]               0\n",
      "        Dropout-4934                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4935                   [-1, 10]               0\n",
      "         Linear-4936                   [-1, 10]             110\n",
      "    BatchNorm1d-4937                   [-1, 10]              20\n",
      "           ReLU-4938                   [-1, 10]               0\n",
      "        Dropout-4939                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4940                   [-1, 10]               0\n",
      "         Linear-4941                   [-1, 10]             110\n",
      "        Softmax-4942                   [-1, 10]               0\n",
      "         Linear-4943                   [-1, 15]             165\n",
      "        Softmax-4944                   [-1, 15]               0\n",
      "         Linear-4945                   [-1, 10]             110\n",
      "    BatchNorm1d-4946                   [-1, 10]              20\n",
      "           ReLU-4947                   [-1, 10]               0\n",
      "        Dropout-4948                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4949                   [-1, 10]               0\n",
      "         Linear-4950                   [-1, 10]             110\n",
      "    BatchNorm1d-4951                   [-1, 10]              20\n",
      "           ReLU-4952                   [-1, 10]               0\n",
      "        Dropout-4953                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4954                   [-1, 10]               0\n",
      "         Linear-4955                   [-1, 10]             110\n",
      "    BatchNorm1d-4956                   [-1, 10]              20\n",
      "           ReLU-4957                   [-1, 10]               0\n",
      "        Dropout-4958                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4959                   [-1, 10]               0\n",
      "         Linear-4960                   [-1, 10]             110\n",
      "    BatchNorm1d-4961                   [-1, 10]              20\n",
      "           ReLU-4962                   [-1, 10]               0\n",
      "        Dropout-4963                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4964                   [-1, 10]               0\n",
      "         Linear-4965                   [-1, 10]             110\n",
      "    BatchNorm1d-4966                   [-1, 10]              20\n",
      "           ReLU-4967                   [-1, 10]               0\n",
      "        Dropout-4968                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4969                   [-1, 10]               0\n",
      "         Linear-4970                   [-1, 10]             110\n",
      "    BatchNorm1d-4971                   [-1, 10]              20\n",
      "           ReLU-4972                   [-1, 10]               0\n",
      "        Dropout-4973                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4974                   [-1, 10]               0\n",
      "         Linear-4975                   [-1, 10]             110\n",
      "    BatchNorm1d-4976                   [-1, 10]              20\n",
      "           ReLU-4977                   [-1, 10]               0\n",
      "        Dropout-4978                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4979                   [-1, 10]               0\n",
      "         Linear-4980                   [-1, 10]             110\n",
      "    BatchNorm1d-4981                   [-1, 10]              20\n",
      "           ReLU-4982                   [-1, 10]               0\n",
      "        Dropout-4983                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4984                   [-1, 10]               0\n",
      "         Linear-4985                   [-1, 10]             110\n",
      "    BatchNorm1d-4986                   [-1, 10]              20\n",
      "           ReLU-4987                   [-1, 10]               0\n",
      "        Dropout-4988                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4989                   [-1, 10]               0\n",
      "         Linear-4990                   [-1, 10]             110\n",
      "    BatchNorm1d-4991                   [-1, 10]              20\n",
      "           ReLU-4992                   [-1, 10]               0\n",
      "        Dropout-4993                   [-1, 10]               0\n",
      "MultiLayerPerceptron-4994                   [-1, 10]               0\n",
      "         Linear-4995                   [-1, 10]             110\n",
      "        Softmax-4996                   [-1, 10]               0\n",
      "         Linear-4997                   [-1, 10]             110\n",
      "    BatchNorm1d-4998                   [-1, 10]              20\n",
      "           ReLU-4999                   [-1, 10]               0\n",
      "        Dropout-5000                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5001                   [-1, 10]               0\n",
      "         Linear-5002                   [-1, 10]             110\n",
      "    BatchNorm1d-5003                   [-1, 10]              20\n",
      "           ReLU-5004                   [-1, 10]               0\n",
      "        Dropout-5005                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5006                   [-1, 10]               0\n",
      "         Linear-5007                   [-1, 10]             110\n",
      "    BatchNorm1d-5008                   [-1, 10]              20\n",
      "           ReLU-5009                   [-1, 10]               0\n",
      "        Dropout-5010                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5011                   [-1, 10]               0\n",
      "         Linear-5012                   [-1, 10]             110\n",
      "    BatchNorm1d-5013                   [-1, 10]              20\n",
      "           ReLU-5014                   [-1, 10]               0\n",
      "        Dropout-5015                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5016                   [-1, 10]               0\n",
      "         Linear-5017                   [-1, 10]             110\n",
      "    BatchNorm1d-5018                   [-1, 10]              20\n",
      "           ReLU-5019                   [-1, 10]               0\n",
      "        Dropout-5020                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5021                   [-1, 10]               0\n",
      "         Linear-5022                   [-1, 10]             110\n",
      "        Softmax-5023                   [-1, 10]               0\n",
      "         Linear-5024                   [-1, 15]             165\n",
      "        Softmax-5025                   [-1, 15]               0\n",
      "         Linear-5026                   [-1, 10]             110\n",
      "    BatchNorm1d-5027                   [-1, 10]              20\n",
      "           ReLU-5028                   [-1, 10]               0\n",
      "        Dropout-5029                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5030                   [-1, 10]               0\n",
      "         Linear-5031                   [-1, 10]             110\n",
      "    BatchNorm1d-5032                   [-1, 10]              20\n",
      "           ReLU-5033                   [-1, 10]               0\n",
      "        Dropout-5034                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5035                   [-1, 10]               0\n",
      "         Linear-5036                   [-1, 10]             110\n",
      "    BatchNorm1d-5037                   [-1, 10]              20\n",
      "           ReLU-5038                   [-1, 10]               0\n",
      "        Dropout-5039                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5040                   [-1, 10]               0\n",
      "         Linear-5041                   [-1, 10]             110\n",
      "    BatchNorm1d-5042                   [-1, 10]              20\n",
      "           ReLU-5043                   [-1, 10]               0\n",
      "        Dropout-5044                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5045                   [-1, 10]               0\n",
      "         Linear-5046                   [-1, 10]             110\n",
      "    BatchNorm1d-5047                   [-1, 10]              20\n",
      "           ReLU-5048                   [-1, 10]               0\n",
      "        Dropout-5049                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5050                   [-1, 10]               0\n",
      "         Linear-5051                   [-1, 10]             110\n",
      "    BatchNorm1d-5052                   [-1, 10]              20\n",
      "           ReLU-5053                   [-1, 10]               0\n",
      "        Dropout-5054                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5055                   [-1, 10]               0\n",
      "         Linear-5056                   [-1, 10]             110\n",
      "    BatchNorm1d-5057                   [-1, 10]              20\n",
      "           ReLU-5058                   [-1, 10]               0\n",
      "        Dropout-5059                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5060                   [-1, 10]               0\n",
      "         Linear-5061                   [-1, 10]             110\n",
      "    BatchNorm1d-5062                   [-1, 10]              20\n",
      "           ReLU-5063                   [-1, 10]               0\n",
      "        Dropout-5064                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5065                   [-1, 10]               0\n",
      "         Linear-5066                   [-1, 10]             110\n",
      "    BatchNorm1d-5067                   [-1, 10]              20\n",
      "           ReLU-5068                   [-1, 10]               0\n",
      "        Dropout-5069                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5070                   [-1, 10]               0\n",
      "         Linear-5071                   [-1, 10]             110\n",
      "    BatchNorm1d-5072                   [-1, 10]              20\n",
      "           ReLU-5073                   [-1, 10]               0\n",
      "        Dropout-5074                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5075                   [-1, 10]               0\n",
      "         Linear-5076                   [-1, 10]             110\n",
      "        Softmax-5077                   [-1, 10]               0\n",
      "         Linear-5078                   [-1, 10]             110\n",
      "    BatchNorm1d-5079                   [-1, 10]              20\n",
      "           ReLU-5080                   [-1, 10]               0\n",
      "        Dropout-5081                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5082                   [-1, 10]               0\n",
      "         Linear-5083                   [-1, 10]             110\n",
      "    BatchNorm1d-5084                   [-1, 10]              20\n",
      "           ReLU-5085                   [-1, 10]               0\n",
      "        Dropout-5086                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5087                   [-1, 10]               0\n",
      "         Linear-5088                   [-1, 10]             110\n",
      "    BatchNorm1d-5089                   [-1, 10]              20\n",
      "           ReLU-5090                   [-1, 10]               0\n",
      "        Dropout-5091                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5092                   [-1, 10]               0\n",
      "         Linear-5093                   [-1, 10]             110\n",
      "    BatchNorm1d-5094                   [-1, 10]              20\n",
      "           ReLU-5095                   [-1, 10]               0\n",
      "        Dropout-5096                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5097                   [-1, 10]               0\n",
      "         Linear-5098                   [-1, 10]             110\n",
      "    BatchNorm1d-5099                   [-1, 10]              20\n",
      "           ReLU-5100                   [-1, 10]               0\n",
      "        Dropout-5101                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5102                   [-1, 10]               0\n",
      "         Linear-5103                   [-1, 10]             110\n",
      "        Softmax-5104                   [-1, 10]               0\n",
      "         Linear-5105                   [-1, 15]             165\n",
      "        Softmax-5106                   [-1, 15]               0\n",
      "         Linear-5107                   [-1, 10]             110\n",
      "    BatchNorm1d-5108                   [-1, 10]              20\n",
      "           ReLU-5109                   [-1, 10]               0\n",
      "        Dropout-5110                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5111                   [-1, 10]               0\n",
      "         Linear-5112                   [-1, 10]             110\n",
      "    BatchNorm1d-5113                   [-1, 10]              20\n",
      "           ReLU-5114                   [-1, 10]               0\n",
      "        Dropout-5115                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5116                   [-1, 10]               0\n",
      "         Linear-5117                   [-1, 10]             110\n",
      "    BatchNorm1d-5118                   [-1, 10]              20\n",
      "           ReLU-5119                   [-1, 10]               0\n",
      "        Dropout-5120                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5121                   [-1, 10]               0\n",
      "         Linear-5122                   [-1, 10]             110\n",
      "    BatchNorm1d-5123                   [-1, 10]              20\n",
      "           ReLU-5124                   [-1, 10]               0\n",
      "        Dropout-5125                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5126                   [-1, 10]               0\n",
      "         Linear-5127                   [-1, 10]             110\n",
      "    BatchNorm1d-5128                   [-1, 10]              20\n",
      "           ReLU-5129                   [-1, 10]               0\n",
      "        Dropout-5130                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5131                   [-1, 10]               0\n",
      "         Linear-5132                   [-1, 10]             110\n",
      "    BatchNorm1d-5133                   [-1, 10]              20\n",
      "           ReLU-5134                   [-1, 10]               0\n",
      "        Dropout-5135                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5136                   [-1, 10]               0\n",
      "         Linear-5137                   [-1, 10]             110\n",
      "    BatchNorm1d-5138                   [-1, 10]              20\n",
      "           ReLU-5139                   [-1, 10]               0\n",
      "        Dropout-5140                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5141                   [-1, 10]               0\n",
      "         Linear-5142                   [-1, 10]             110\n",
      "    BatchNorm1d-5143                   [-1, 10]              20\n",
      "           ReLU-5144                   [-1, 10]               0\n",
      "        Dropout-5145                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5146                   [-1, 10]               0\n",
      "         Linear-5147                   [-1, 10]             110\n",
      "    BatchNorm1d-5148                   [-1, 10]              20\n",
      "           ReLU-5149                   [-1, 10]               0\n",
      "        Dropout-5150                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5151                   [-1, 10]               0\n",
      "         Linear-5152                   [-1, 10]             110\n",
      "    BatchNorm1d-5153                   [-1, 10]              20\n",
      "           ReLU-5154                   [-1, 10]               0\n",
      "        Dropout-5155                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5156                   [-1, 10]               0\n",
      "         Linear-5157                   [-1, 10]             110\n",
      "        Softmax-5158                   [-1, 10]               0\n",
      "         Linear-5159                   [-1, 10]             110\n",
      "    BatchNorm1d-5160                   [-1, 10]              20\n",
      "           ReLU-5161                   [-1, 10]               0\n",
      "        Dropout-5162                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5163                   [-1, 10]               0\n",
      "         Linear-5164                   [-1, 10]             110\n",
      "    BatchNorm1d-5165                   [-1, 10]              20\n",
      "           ReLU-5166                   [-1, 10]               0\n",
      "        Dropout-5167                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5168                   [-1, 10]               0\n",
      "         Linear-5169                   [-1, 10]             110\n",
      "    BatchNorm1d-5170                   [-1, 10]              20\n",
      "           ReLU-5171                   [-1, 10]               0\n",
      "        Dropout-5172                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5173                   [-1, 10]               0\n",
      "         Linear-5174                   [-1, 10]             110\n",
      "    BatchNorm1d-5175                   [-1, 10]              20\n",
      "           ReLU-5176                   [-1, 10]               0\n",
      "        Dropout-5177                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5178                   [-1, 10]               0\n",
      "         Linear-5179                   [-1, 10]             110\n",
      "    BatchNorm1d-5180                   [-1, 10]              20\n",
      "           ReLU-5181                   [-1, 10]               0\n",
      "        Dropout-5182                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5183                   [-1, 10]               0\n",
      "         Linear-5184                   [-1, 10]             110\n",
      "        Softmax-5185                   [-1, 10]               0\n",
      "         Linear-5186                   [-1, 15]             165\n",
      "        Softmax-5187                   [-1, 15]               0\n",
      "         Linear-5188                   [-1, 10]             110\n",
      "    BatchNorm1d-5189                   [-1, 10]              20\n",
      "           ReLU-5190                   [-1, 10]               0\n",
      "        Dropout-5191                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5192                   [-1, 10]               0\n",
      "         Linear-5193                   [-1, 10]             110\n",
      "    BatchNorm1d-5194                   [-1, 10]              20\n",
      "           ReLU-5195                   [-1, 10]               0\n",
      "        Dropout-5196                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5197                   [-1, 10]               0\n",
      "         Linear-5198                   [-1, 10]             110\n",
      "    BatchNorm1d-5199                   [-1, 10]              20\n",
      "           ReLU-5200                   [-1, 10]               0\n",
      "        Dropout-5201                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5202                   [-1, 10]               0\n",
      "         Linear-5203                   [-1, 10]             110\n",
      "    BatchNorm1d-5204                   [-1, 10]              20\n",
      "           ReLU-5205                   [-1, 10]               0\n",
      "        Dropout-5206                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5207                   [-1, 10]               0\n",
      "         Linear-5208                   [-1, 10]             110\n",
      "    BatchNorm1d-5209                   [-1, 10]              20\n",
      "           ReLU-5210                   [-1, 10]               0\n",
      "        Dropout-5211                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5212                   [-1, 10]               0\n",
      "         Linear-5213                   [-1, 10]             110\n",
      "    BatchNorm1d-5214                   [-1, 10]              20\n",
      "           ReLU-5215                   [-1, 10]               0\n",
      "        Dropout-5216                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5217                   [-1, 10]               0\n",
      "         Linear-5218                   [-1, 10]             110\n",
      "    BatchNorm1d-5219                   [-1, 10]              20\n",
      "           ReLU-5220                   [-1, 10]               0\n",
      "        Dropout-5221                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5222                   [-1, 10]               0\n",
      "         Linear-5223                   [-1, 10]             110\n",
      "    BatchNorm1d-5224                   [-1, 10]              20\n",
      "           ReLU-5225                   [-1, 10]               0\n",
      "        Dropout-5226                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5227                   [-1, 10]               0\n",
      "         Linear-5228                   [-1, 10]             110\n",
      "    BatchNorm1d-5229                   [-1, 10]              20\n",
      "           ReLU-5230                   [-1, 10]               0\n",
      "        Dropout-5231                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5232                   [-1, 10]               0\n",
      "         Linear-5233                   [-1, 10]             110\n",
      "    BatchNorm1d-5234                   [-1, 10]              20\n",
      "           ReLU-5235                   [-1, 10]               0\n",
      "        Dropout-5236                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5237                   [-1, 10]               0\n",
      "         Linear-5238                   [-1, 10]             110\n",
      "        Softmax-5239                   [-1, 10]               0\n",
      "         Linear-5240                   [-1, 10]             110\n",
      "    BatchNorm1d-5241                   [-1, 10]              20\n",
      "           ReLU-5242                   [-1, 10]               0\n",
      "        Dropout-5243                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5244                   [-1, 10]               0\n",
      "         Linear-5245                   [-1, 10]             110\n",
      "    BatchNorm1d-5246                   [-1, 10]              20\n",
      "           ReLU-5247                   [-1, 10]               0\n",
      "        Dropout-5248                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5249                   [-1, 10]               0\n",
      "         Linear-5250                   [-1, 10]             110\n",
      "    BatchNorm1d-5251                   [-1, 10]              20\n",
      "           ReLU-5252                   [-1, 10]               0\n",
      "        Dropout-5253                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5254                   [-1, 10]               0\n",
      "         Linear-5255                   [-1, 10]             110\n",
      "    BatchNorm1d-5256                   [-1, 10]              20\n",
      "           ReLU-5257                   [-1, 10]               0\n",
      "        Dropout-5258                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5259                   [-1, 10]               0\n",
      "         Linear-5260                   [-1, 10]             110\n",
      "    BatchNorm1d-5261                   [-1, 10]              20\n",
      "           ReLU-5262                   [-1, 10]               0\n",
      "        Dropout-5263                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5264                   [-1, 10]               0\n",
      "         Linear-5265                   [-1, 10]             110\n",
      "        Softmax-5266                   [-1, 10]               0\n",
      "         Linear-5267                   [-1, 15]             165\n",
      "        Softmax-5268                   [-1, 15]               0\n",
      "         Linear-5269                   [-1, 10]             110\n",
      "    BatchNorm1d-5270                   [-1, 10]              20\n",
      "           ReLU-5271                   [-1, 10]               0\n",
      "        Dropout-5272                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5273                   [-1, 10]               0\n",
      "         Linear-5274                   [-1, 10]             110\n",
      "    BatchNorm1d-5275                   [-1, 10]              20\n",
      "           ReLU-5276                   [-1, 10]               0\n",
      "        Dropout-5277                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5278                   [-1, 10]               0\n",
      "         Linear-5279                   [-1, 10]             110\n",
      "    BatchNorm1d-5280                   [-1, 10]              20\n",
      "           ReLU-5281                   [-1, 10]               0\n",
      "        Dropout-5282                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5283                   [-1, 10]               0\n",
      "         Linear-5284                   [-1, 10]             110\n",
      "    BatchNorm1d-5285                   [-1, 10]              20\n",
      "           ReLU-5286                   [-1, 10]               0\n",
      "        Dropout-5287                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5288                   [-1, 10]               0\n",
      "         Linear-5289                   [-1, 10]             110\n",
      "    BatchNorm1d-5290                   [-1, 10]              20\n",
      "           ReLU-5291                   [-1, 10]               0\n",
      "        Dropout-5292                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5293                   [-1, 10]               0\n",
      "         Linear-5294                   [-1, 10]             110\n",
      "    BatchNorm1d-5295                   [-1, 10]              20\n",
      "           ReLU-5296                   [-1, 10]               0\n",
      "        Dropout-5297                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5298                   [-1, 10]               0\n",
      "         Linear-5299                   [-1, 10]             110\n",
      "    BatchNorm1d-5300                   [-1, 10]              20\n",
      "           ReLU-5301                   [-1, 10]               0\n",
      "        Dropout-5302                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5303                   [-1, 10]               0\n",
      "         Linear-5304                   [-1, 10]             110\n",
      "    BatchNorm1d-5305                   [-1, 10]              20\n",
      "           ReLU-5306                   [-1, 10]               0\n",
      "        Dropout-5307                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5308                   [-1, 10]               0\n",
      "         Linear-5309                   [-1, 10]             110\n",
      "    BatchNorm1d-5310                   [-1, 10]              20\n",
      "           ReLU-5311                   [-1, 10]               0\n",
      "        Dropout-5312                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5313                   [-1, 10]               0\n",
      "         Linear-5314                   [-1, 10]             110\n",
      "    BatchNorm1d-5315                   [-1, 10]              20\n",
      "           ReLU-5316                   [-1, 10]               0\n",
      "        Dropout-5317                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5318                   [-1, 10]               0\n",
      "         Linear-5319                   [-1, 10]             110\n",
      "        Softmax-5320                   [-1, 10]               0\n",
      "         Linear-5321                   [-1, 10]             110\n",
      "    BatchNorm1d-5322                   [-1, 10]              20\n",
      "           ReLU-5323                   [-1, 10]               0\n",
      "        Dropout-5324                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5325                   [-1, 10]               0\n",
      "         Linear-5326                   [-1, 10]             110\n",
      "    BatchNorm1d-5327                   [-1, 10]              20\n",
      "           ReLU-5328                   [-1, 10]               0\n",
      "        Dropout-5329                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5330                   [-1, 10]               0\n",
      "         Linear-5331                   [-1, 10]             110\n",
      "    BatchNorm1d-5332                   [-1, 10]              20\n",
      "           ReLU-5333                   [-1, 10]               0\n",
      "        Dropout-5334                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5335                   [-1, 10]               0\n",
      "         Linear-5336                   [-1, 10]             110\n",
      "    BatchNorm1d-5337                   [-1, 10]              20\n",
      "           ReLU-5338                   [-1, 10]               0\n",
      "        Dropout-5339                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5340                   [-1, 10]               0\n",
      "         Linear-5341                   [-1, 10]             110\n",
      "    BatchNorm1d-5342                   [-1, 10]              20\n",
      "           ReLU-5343                   [-1, 10]               0\n",
      "        Dropout-5344                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5345                   [-1, 10]               0\n",
      "         Linear-5346                   [-1, 10]             110\n",
      "        Softmax-5347                   [-1, 10]               0\n",
      "         Linear-5348                   [-1, 15]             165\n",
      "        Softmax-5349                   [-1, 15]               0\n",
      "         Linear-5350                   [-1, 10]             110\n",
      "    BatchNorm1d-5351                   [-1, 10]              20\n",
      "           ReLU-5352                   [-1, 10]               0\n",
      "        Dropout-5353                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5354                   [-1, 10]               0\n",
      "         Linear-5355                   [-1, 10]             110\n",
      "    BatchNorm1d-5356                   [-1, 10]              20\n",
      "           ReLU-5357                   [-1, 10]               0\n",
      "        Dropout-5358                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5359                   [-1, 10]               0\n",
      "         Linear-5360                   [-1, 10]             110\n",
      "    BatchNorm1d-5361                   [-1, 10]              20\n",
      "           ReLU-5362                   [-1, 10]               0\n",
      "        Dropout-5363                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5364                   [-1, 10]               0\n",
      "         Linear-5365                   [-1, 10]             110\n",
      "    BatchNorm1d-5366                   [-1, 10]              20\n",
      "           ReLU-5367                   [-1, 10]               0\n",
      "        Dropout-5368                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5369                   [-1, 10]               0\n",
      "         Linear-5370                   [-1, 10]             110\n",
      "    BatchNorm1d-5371                   [-1, 10]              20\n",
      "           ReLU-5372                   [-1, 10]               0\n",
      "        Dropout-5373                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5374                   [-1, 10]               0\n",
      "         Linear-5375                   [-1, 10]             110\n",
      "    BatchNorm1d-5376                   [-1, 10]              20\n",
      "           ReLU-5377                   [-1, 10]               0\n",
      "        Dropout-5378                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5379                   [-1, 10]               0\n",
      "         Linear-5380                   [-1, 10]             110\n",
      "    BatchNorm1d-5381                   [-1, 10]              20\n",
      "           ReLU-5382                   [-1, 10]               0\n",
      "        Dropout-5383                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5384                   [-1, 10]               0\n",
      "         Linear-5385                   [-1, 10]             110\n",
      "    BatchNorm1d-5386                   [-1, 10]              20\n",
      "           ReLU-5387                   [-1, 10]               0\n",
      "        Dropout-5388                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5389                   [-1, 10]               0\n",
      "         Linear-5390                   [-1, 10]             110\n",
      "    BatchNorm1d-5391                   [-1, 10]              20\n",
      "           ReLU-5392                   [-1, 10]               0\n",
      "        Dropout-5393                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5394                   [-1, 10]               0\n",
      "         Linear-5395                   [-1, 10]             110\n",
      "    BatchNorm1d-5396                   [-1, 10]              20\n",
      "           ReLU-5397                   [-1, 10]               0\n",
      "        Dropout-5398                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5399                   [-1, 10]               0\n",
      "         Linear-5400                   [-1, 10]             110\n",
      "        Softmax-5401                   [-1, 10]               0\n",
      "         Linear-5402                   [-1, 10]             110\n",
      "    BatchNorm1d-5403                   [-1, 10]              20\n",
      "           ReLU-5404                   [-1, 10]               0\n",
      "        Dropout-5405                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5406                   [-1, 10]               0\n",
      "         Linear-5407                   [-1, 10]             110\n",
      "    BatchNorm1d-5408                   [-1, 10]              20\n",
      "           ReLU-5409                   [-1, 10]               0\n",
      "        Dropout-5410                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5411                   [-1, 10]               0\n",
      "         Linear-5412                   [-1, 10]             110\n",
      "    BatchNorm1d-5413                   [-1, 10]              20\n",
      "           ReLU-5414                   [-1, 10]               0\n",
      "        Dropout-5415                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5416                   [-1, 10]               0\n",
      "         Linear-5417                   [-1, 10]             110\n",
      "    BatchNorm1d-5418                   [-1, 10]              20\n",
      "           ReLU-5419                   [-1, 10]               0\n",
      "        Dropout-5420                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5421                   [-1, 10]               0\n",
      "         Linear-5422                   [-1, 10]             110\n",
      "    BatchNorm1d-5423                   [-1, 10]              20\n",
      "           ReLU-5424                   [-1, 10]               0\n",
      "        Dropout-5425                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5426                   [-1, 10]               0\n",
      "         Linear-5427                   [-1, 10]             110\n",
      "        Softmax-5428                   [-1, 10]               0\n",
      "         Linear-5429                   [-1, 15]             165\n",
      "        Softmax-5430                   [-1, 15]               0\n",
      "         Linear-5431                   [-1, 10]             110\n",
      "    BatchNorm1d-5432                   [-1, 10]              20\n",
      "           ReLU-5433                   [-1, 10]               0\n",
      "        Dropout-5434                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5435                   [-1, 10]               0\n",
      "         Linear-5436                   [-1, 10]             110\n",
      "    BatchNorm1d-5437                   [-1, 10]              20\n",
      "           ReLU-5438                   [-1, 10]               0\n",
      "        Dropout-5439                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5440                   [-1, 10]               0\n",
      "         Linear-5441                   [-1, 10]             110\n",
      "    BatchNorm1d-5442                   [-1, 10]              20\n",
      "           ReLU-5443                   [-1, 10]               0\n",
      "        Dropout-5444                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5445                   [-1, 10]               0\n",
      "         Linear-5446                   [-1, 10]             110\n",
      "    BatchNorm1d-5447                   [-1, 10]              20\n",
      "           ReLU-5448                   [-1, 10]               0\n",
      "        Dropout-5449                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5450                   [-1, 10]               0\n",
      "         Linear-5451                   [-1, 10]             110\n",
      "    BatchNorm1d-5452                   [-1, 10]              20\n",
      "           ReLU-5453                   [-1, 10]               0\n",
      "        Dropout-5454                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5455                   [-1, 10]               0\n",
      "         Linear-5456                   [-1, 10]             110\n",
      "    BatchNorm1d-5457                   [-1, 10]              20\n",
      "           ReLU-5458                   [-1, 10]               0\n",
      "        Dropout-5459                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5460                   [-1, 10]               0\n",
      "         Linear-5461                   [-1, 10]             110\n",
      "    BatchNorm1d-5462                   [-1, 10]              20\n",
      "           ReLU-5463                   [-1, 10]               0\n",
      "        Dropout-5464                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5465                   [-1, 10]               0\n",
      "         Linear-5466                   [-1, 10]             110\n",
      "    BatchNorm1d-5467                   [-1, 10]              20\n",
      "           ReLU-5468                   [-1, 10]               0\n",
      "        Dropout-5469                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5470                   [-1, 10]               0\n",
      "         Linear-5471                   [-1, 10]             110\n",
      "    BatchNorm1d-5472                   [-1, 10]              20\n",
      "           ReLU-5473                   [-1, 10]               0\n",
      "        Dropout-5474                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5475                   [-1, 10]               0\n",
      "         Linear-5476                   [-1, 10]             110\n",
      "    BatchNorm1d-5477                   [-1, 10]              20\n",
      "           ReLU-5478                   [-1, 10]               0\n",
      "        Dropout-5479                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5480                   [-1, 10]               0\n",
      "         Linear-5481                   [-1, 10]             110\n",
      "        Softmax-5482                   [-1, 10]               0\n",
      "         Linear-5483                   [-1, 10]             110\n",
      "    BatchNorm1d-5484                   [-1, 10]              20\n",
      "           ReLU-5485                   [-1, 10]               0\n",
      "        Dropout-5486                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5487                   [-1, 10]               0\n",
      "         Linear-5488                   [-1, 10]             110\n",
      "    BatchNorm1d-5489                   [-1, 10]              20\n",
      "           ReLU-5490                   [-1, 10]               0\n",
      "        Dropout-5491                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5492                   [-1, 10]               0\n",
      "         Linear-5493                   [-1, 10]             110\n",
      "    BatchNorm1d-5494                   [-1, 10]              20\n",
      "           ReLU-5495                   [-1, 10]               0\n",
      "        Dropout-5496                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5497                   [-1, 10]               0\n",
      "         Linear-5498                   [-1, 10]             110\n",
      "    BatchNorm1d-5499                   [-1, 10]              20\n",
      "           ReLU-5500                   [-1, 10]               0\n",
      "        Dropout-5501                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5502                   [-1, 10]               0\n",
      "         Linear-5503                   [-1, 10]             110\n",
      "    BatchNorm1d-5504                   [-1, 10]              20\n",
      "           ReLU-5505                   [-1, 10]               0\n",
      "        Dropout-5506                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5507                   [-1, 10]               0\n",
      "         Linear-5508                   [-1, 10]             110\n",
      "        Softmax-5509                   [-1, 10]               0\n",
      "         Linear-5510                   [-1, 15]             165\n",
      "        Softmax-5511                   [-1, 15]               0\n",
      "         Linear-5512                   [-1, 10]             110\n",
      "    BatchNorm1d-5513                   [-1, 10]              20\n",
      "           ReLU-5514                   [-1, 10]               0\n",
      "        Dropout-5515                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5516                   [-1, 10]               0\n",
      "         Linear-5517                   [-1, 10]             110\n",
      "    BatchNorm1d-5518                   [-1, 10]              20\n",
      "           ReLU-5519                   [-1, 10]               0\n",
      "        Dropout-5520                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5521                   [-1, 10]               0\n",
      "         Linear-5522                   [-1, 10]             110\n",
      "    BatchNorm1d-5523                   [-1, 10]              20\n",
      "           ReLU-5524                   [-1, 10]               0\n",
      "        Dropout-5525                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5526                   [-1, 10]               0\n",
      "         Linear-5527                   [-1, 10]             110\n",
      "    BatchNorm1d-5528                   [-1, 10]              20\n",
      "           ReLU-5529                   [-1, 10]               0\n",
      "        Dropout-5530                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5531                   [-1, 10]               0\n",
      "         Linear-5532                   [-1, 10]             110\n",
      "    BatchNorm1d-5533                   [-1, 10]              20\n",
      "           ReLU-5534                   [-1, 10]               0\n",
      "        Dropout-5535                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5536                   [-1, 10]               0\n",
      "         Linear-5537                   [-1, 10]             110\n",
      "    BatchNorm1d-5538                   [-1, 10]              20\n",
      "           ReLU-5539                   [-1, 10]               0\n",
      "        Dropout-5540                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5541                   [-1, 10]               0\n",
      "         Linear-5542                   [-1, 10]             110\n",
      "    BatchNorm1d-5543                   [-1, 10]              20\n",
      "           ReLU-5544                   [-1, 10]               0\n",
      "        Dropout-5545                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5546                   [-1, 10]               0\n",
      "         Linear-5547                   [-1, 10]             110\n",
      "    BatchNorm1d-5548                   [-1, 10]              20\n",
      "           ReLU-5549                   [-1, 10]               0\n",
      "        Dropout-5550                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5551                   [-1, 10]               0\n",
      "         Linear-5552                   [-1, 10]             110\n",
      "    BatchNorm1d-5553                   [-1, 10]              20\n",
      "           ReLU-5554                   [-1, 10]               0\n",
      "        Dropout-5555                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5556                   [-1, 10]               0\n",
      "         Linear-5557                   [-1, 10]             110\n",
      "    BatchNorm1d-5558                   [-1, 10]              20\n",
      "           ReLU-5559                   [-1, 10]               0\n",
      "        Dropout-5560                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5561                   [-1, 10]               0\n",
      "         Linear-5562                   [-1, 10]             110\n",
      "        Softmax-5563                   [-1, 10]               0\n",
      "         Linear-5564                   [-1, 10]             110\n",
      "    BatchNorm1d-5565                   [-1, 10]              20\n",
      "           ReLU-5566                   [-1, 10]               0\n",
      "        Dropout-5567                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5568                   [-1, 10]               0\n",
      "         Linear-5569                   [-1, 10]             110\n",
      "    BatchNorm1d-5570                   [-1, 10]              20\n",
      "           ReLU-5571                   [-1, 10]               0\n",
      "        Dropout-5572                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5573                   [-1, 10]               0\n",
      "         Linear-5574                   [-1, 10]             110\n",
      "    BatchNorm1d-5575                   [-1, 10]              20\n",
      "           ReLU-5576                   [-1, 10]               0\n",
      "        Dropout-5577                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5578                   [-1, 10]               0\n",
      "         Linear-5579                   [-1, 10]             110\n",
      "    BatchNorm1d-5580                   [-1, 10]              20\n",
      "           ReLU-5581                   [-1, 10]               0\n",
      "        Dropout-5582                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5583                   [-1, 10]               0\n",
      "         Linear-5584                   [-1, 10]             110\n",
      "    BatchNorm1d-5585                   [-1, 10]              20\n",
      "           ReLU-5586                   [-1, 10]               0\n",
      "        Dropout-5587                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5588                   [-1, 10]               0\n",
      "         Linear-5589                   [-1, 10]             110\n",
      "        Softmax-5590                   [-1, 10]               0\n",
      "         Linear-5591                   [-1, 15]             165\n",
      "        Softmax-5592                   [-1, 15]               0\n",
      "         Linear-5593                   [-1, 10]             110\n",
      "    BatchNorm1d-5594                   [-1, 10]              20\n",
      "           ReLU-5595                   [-1, 10]               0\n",
      "        Dropout-5596                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5597                   [-1, 10]               0\n",
      "         Linear-5598                   [-1, 10]             110\n",
      "    BatchNorm1d-5599                   [-1, 10]              20\n",
      "           ReLU-5600                   [-1, 10]               0\n",
      "        Dropout-5601                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5602                   [-1, 10]               0\n",
      "         Linear-5603                   [-1, 10]             110\n",
      "    BatchNorm1d-5604                   [-1, 10]              20\n",
      "           ReLU-5605                   [-1, 10]               0\n",
      "        Dropout-5606                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5607                   [-1, 10]               0\n",
      "         Linear-5608                   [-1, 10]             110\n",
      "    BatchNorm1d-5609                   [-1, 10]              20\n",
      "           ReLU-5610                   [-1, 10]               0\n",
      "        Dropout-5611                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5612                   [-1, 10]               0\n",
      "         Linear-5613                   [-1, 10]             110\n",
      "    BatchNorm1d-5614                   [-1, 10]              20\n",
      "           ReLU-5615                   [-1, 10]               0\n",
      "        Dropout-5616                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5617                   [-1, 10]               0\n",
      "         Linear-5618                   [-1, 10]             110\n",
      "    BatchNorm1d-5619                   [-1, 10]              20\n",
      "           ReLU-5620                   [-1, 10]               0\n",
      "        Dropout-5621                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5622                   [-1, 10]               0\n",
      "         Linear-5623                   [-1, 10]             110\n",
      "    BatchNorm1d-5624                   [-1, 10]              20\n",
      "           ReLU-5625                   [-1, 10]               0\n",
      "        Dropout-5626                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5627                   [-1, 10]               0\n",
      "         Linear-5628                   [-1, 10]             110\n",
      "    BatchNorm1d-5629                   [-1, 10]              20\n",
      "           ReLU-5630                   [-1, 10]               0\n",
      "        Dropout-5631                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5632                   [-1, 10]               0\n",
      "         Linear-5633                   [-1, 10]             110\n",
      "    BatchNorm1d-5634                   [-1, 10]              20\n",
      "           ReLU-5635                   [-1, 10]               0\n",
      "        Dropout-5636                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5637                   [-1, 10]               0\n",
      "         Linear-5638                   [-1, 10]             110\n",
      "    BatchNorm1d-5639                   [-1, 10]              20\n",
      "           ReLU-5640                   [-1, 10]               0\n",
      "        Dropout-5641                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5642                   [-1, 10]               0\n",
      "         Linear-5643                   [-1, 10]             110\n",
      "        Softmax-5644                   [-1, 10]               0\n",
      "         Linear-5645                   [-1, 10]             110\n",
      "    BatchNorm1d-5646                   [-1, 10]              20\n",
      "           ReLU-5647                   [-1, 10]               0\n",
      "        Dropout-5648                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5649                   [-1, 10]               0\n",
      "         Linear-5650                   [-1, 10]             110\n",
      "    BatchNorm1d-5651                   [-1, 10]              20\n",
      "           ReLU-5652                   [-1, 10]               0\n",
      "        Dropout-5653                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5654                   [-1, 10]               0\n",
      "         Linear-5655                   [-1, 10]             110\n",
      "    BatchNorm1d-5656                   [-1, 10]              20\n",
      "           ReLU-5657                   [-1, 10]               0\n",
      "        Dropout-5658                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5659                   [-1, 10]               0\n",
      "         Linear-5660                   [-1, 10]             110\n",
      "    BatchNorm1d-5661                   [-1, 10]              20\n",
      "           ReLU-5662                   [-1, 10]               0\n",
      "        Dropout-5663                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5664                   [-1, 10]               0\n",
      "         Linear-5665                   [-1, 10]             110\n",
      "    BatchNorm1d-5666                   [-1, 10]              20\n",
      "           ReLU-5667                   [-1, 10]               0\n",
      "        Dropout-5668                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5669                   [-1, 10]               0\n",
      "         Linear-5670                   [-1, 10]             110\n",
      "        Softmax-5671                   [-1, 10]               0\n",
      "         Linear-5672                   [-1, 15]             165\n",
      "        Softmax-5673                   [-1, 15]               0\n",
      "         Linear-5674                   [-1, 10]             110\n",
      "    BatchNorm1d-5675                   [-1, 10]              20\n",
      "           ReLU-5676                   [-1, 10]               0\n",
      "        Dropout-5677                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5678                   [-1, 10]               0\n",
      "         Linear-5679                   [-1, 10]             110\n",
      "    BatchNorm1d-5680                   [-1, 10]              20\n",
      "           ReLU-5681                   [-1, 10]               0\n",
      "        Dropout-5682                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5683                   [-1, 10]               0\n",
      "         Linear-5684                   [-1, 10]             110\n",
      "    BatchNorm1d-5685                   [-1, 10]              20\n",
      "           ReLU-5686                   [-1, 10]               0\n",
      "        Dropout-5687                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5688                   [-1, 10]               0\n",
      "         Linear-5689                   [-1, 10]             110\n",
      "    BatchNorm1d-5690                   [-1, 10]              20\n",
      "           ReLU-5691                   [-1, 10]               0\n",
      "        Dropout-5692                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5693                   [-1, 10]               0\n",
      "         Linear-5694                   [-1, 10]             110\n",
      "    BatchNorm1d-5695                   [-1, 10]              20\n",
      "           ReLU-5696                   [-1, 10]               0\n",
      "        Dropout-5697                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5698                   [-1, 10]               0\n",
      "         Linear-5699                   [-1, 10]             110\n",
      "    BatchNorm1d-5700                   [-1, 10]              20\n",
      "           ReLU-5701                   [-1, 10]               0\n",
      "        Dropout-5702                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5703                   [-1, 10]               0\n",
      "         Linear-5704                   [-1, 10]             110\n",
      "    BatchNorm1d-5705                   [-1, 10]              20\n",
      "           ReLU-5706                   [-1, 10]               0\n",
      "        Dropout-5707                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5708                   [-1, 10]               0\n",
      "         Linear-5709                   [-1, 10]             110\n",
      "    BatchNorm1d-5710                   [-1, 10]              20\n",
      "           ReLU-5711                   [-1, 10]               0\n",
      "        Dropout-5712                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5713                   [-1, 10]               0\n",
      "         Linear-5714                   [-1, 10]             110\n",
      "    BatchNorm1d-5715                   [-1, 10]              20\n",
      "           ReLU-5716                   [-1, 10]               0\n",
      "        Dropout-5717                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5718                   [-1, 10]               0\n",
      "         Linear-5719                   [-1, 10]             110\n",
      "    BatchNorm1d-5720                   [-1, 10]              20\n",
      "           ReLU-5721                   [-1, 10]               0\n",
      "        Dropout-5722                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5723                   [-1, 10]               0\n",
      "         Linear-5724                   [-1, 10]             110\n",
      "        Softmax-5725                   [-1, 10]               0\n",
      "         Linear-5726                   [-1, 10]             110\n",
      "    BatchNorm1d-5727                   [-1, 10]              20\n",
      "           ReLU-5728                   [-1, 10]               0\n",
      "        Dropout-5729                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5730                   [-1, 10]               0\n",
      "         Linear-5731                   [-1, 10]             110\n",
      "    BatchNorm1d-5732                   [-1, 10]              20\n",
      "           ReLU-5733                   [-1, 10]               0\n",
      "        Dropout-5734                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5735                   [-1, 10]               0\n",
      "         Linear-5736                   [-1, 10]             110\n",
      "    BatchNorm1d-5737                   [-1, 10]              20\n",
      "           ReLU-5738                   [-1, 10]               0\n",
      "        Dropout-5739                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5740                   [-1, 10]               0\n",
      "         Linear-5741                   [-1, 10]             110\n",
      "    BatchNorm1d-5742                   [-1, 10]              20\n",
      "           ReLU-5743                   [-1, 10]               0\n",
      "        Dropout-5744                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5745                   [-1, 10]               0\n",
      "         Linear-5746                   [-1, 10]             110\n",
      "    BatchNorm1d-5747                   [-1, 10]              20\n",
      "           ReLU-5748                   [-1, 10]               0\n",
      "        Dropout-5749                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5750                   [-1, 10]               0\n",
      "         Linear-5751                   [-1, 10]             110\n",
      "        Softmax-5752                   [-1, 10]               0\n",
      "         Linear-5753                   [-1, 15]             165\n",
      "        Softmax-5754                   [-1, 15]               0\n",
      "         Linear-5755                   [-1, 10]             110\n",
      "    BatchNorm1d-5756                   [-1, 10]              20\n",
      "           ReLU-5757                   [-1, 10]               0\n",
      "        Dropout-5758                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5759                   [-1, 10]               0\n",
      "         Linear-5760                   [-1, 10]             110\n",
      "    BatchNorm1d-5761                   [-1, 10]              20\n",
      "           ReLU-5762                   [-1, 10]               0\n",
      "        Dropout-5763                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5764                   [-1, 10]               0\n",
      "         Linear-5765                   [-1, 10]             110\n",
      "    BatchNorm1d-5766                   [-1, 10]              20\n",
      "           ReLU-5767                   [-1, 10]               0\n",
      "        Dropout-5768                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5769                   [-1, 10]               0\n",
      "         Linear-5770                   [-1, 10]             110\n",
      "    BatchNorm1d-5771                   [-1, 10]              20\n",
      "           ReLU-5772                   [-1, 10]               0\n",
      "        Dropout-5773                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5774                   [-1, 10]               0\n",
      "         Linear-5775                   [-1, 10]             110\n",
      "    BatchNorm1d-5776                   [-1, 10]              20\n",
      "           ReLU-5777                   [-1, 10]               0\n",
      "        Dropout-5778                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5779                   [-1, 10]               0\n",
      "         Linear-5780                   [-1, 10]             110\n",
      "    BatchNorm1d-5781                   [-1, 10]              20\n",
      "           ReLU-5782                   [-1, 10]               0\n",
      "        Dropout-5783                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5784                   [-1, 10]               0\n",
      "         Linear-5785                   [-1, 10]             110\n",
      "    BatchNorm1d-5786                   [-1, 10]              20\n",
      "           ReLU-5787                   [-1, 10]               0\n",
      "        Dropout-5788                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5789                   [-1, 10]               0\n",
      "         Linear-5790                   [-1, 10]             110\n",
      "    BatchNorm1d-5791                   [-1, 10]              20\n",
      "           ReLU-5792                   [-1, 10]               0\n",
      "        Dropout-5793                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5794                   [-1, 10]               0\n",
      "         Linear-5795                   [-1, 10]             110\n",
      "    BatchNorm1d-5796                   [-1, 10]              20\n",
      "           ReLU-5797                   [-1, 10]               0\n",
      "        Dropout-5798                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5799                   [-1, 10]               0\n",
      "         Linear-5800                   [-1, 10]             110\n",
      "    BatchNorm1d-5801                   [-1, 10]              20\n",
      "           ReLU-5802                   [-1, 10]               0\n",
      "        Dropout-5803                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5804                   [-1, 10]               0\n",
      "         Linear-5805                   [-1, 10]             110\n",
      "        Softmax-5806                   [-1, 10]               0\n",
      "         Linear-5807                   [-1, 10]             110\n",
      "    BatchNorm1d-5808                   [-1, 10]              20\n",
      "           ReLU-5809                   [-1, 10]               0\n",
      "        Dropout-5810                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5811                   [-1, 10]               0\n",
      "         Linear-5812                   [-1, 10]             110\n",
      "    BatchNorm1d-5813                   [-1, 10]              20\n",
      "           ReLU-5814                   [-1, 10]               0\n",
      "        Dropout-5815                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5816                   [-1, 10]               0\n",
      "         Linear-5817                   [-1, 10]             110\n",
      "    BatchNorm1d-5818                   [-1, 10]              20\n",
      "           ReLU-5819                   [-1, 10]               0\n",
      "        Dropout-5820                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5821                   [-1, 10]               0\n",
      "         Linear-5822                   [-1, 10]             110\n",
      "    BatchNorm1d-5823                   [-1, 10]              20\n",
      "           ReLU-5824                   [-1, 10]               0\n",
      "        Dropout-5825                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5826                   [-1, 10]               0\n",
      "         Linear-5827                   [-1, 10]             110\n",
      "    BatchNorm1d-5828                   [-1, 10]              20\n",
      "           ReLU-5829                   [-1, 10]               0\n",
      "        Dropout-5830                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5831                   [-1, 10]               0\n",
      "         Linear-5832                   [-1, 10]             110\n",
      "        Softmax-5833                   [-1, 10]               0\n",
      "         Linear-5834                   [-1, 15]             165\n",
      "        Softmax-5835                   [-1, 15]               0\n",
      "         Linear-5836                   [-1, 10]             110\n",
      "    BatchNorm1d-5837                   [-1, 10]              20\n",
      "           ReLU-5838                   [-1, 10]               0\n",
      "        Dropout-5839                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5840                   [-1, 10]               0\n",
      "         Linear-5841                   [-1, 10]             110\n",
      "    BatchNorm1d-5842                   [-1, 10]              20\n",
      "           ReLU-5843                   [-1, 10]               0\n",
      "        Dropout-5844                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5845                   [-1, 10]               0\n",
      "         Linear-5846                   [-1, 10]             110\n",
      "    BatchNorm1d-5847                   [-1, 10]              20\n",
      "           ReLU-5848                   [-1, 10]               0\n",
      "        Dropout-5849                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5850                   [-1, 10]               0\n",
      "         Linear-5851                   [-1, 10]             110\n",
      "    BatchNorm1d-5852                   [-1, 10]              20\n",
      "           ReLU-5853                   [-1, 10]               0\n",
      "        Dropout-5854                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5855                   [-1, 10]               0\n",
      "         Linear-5856                   [-1, 10]             110\n",
      "    BatchNorm1d-5857                   [-1, 10]              20\n",
      "           ReLU-5858                   [-1, 10]               0\n",
      "        Dropout-5859                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5860                   [-1, 10]               0\n",
      "         Linear-5861                   [-1, 10]             110\n",
      "    BatchNorm1d-5862                   [-1, 10]              20\n",
      "           ReLU-5863                   [-1, 10]               0\n",
      "        Dropout-5864                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5865                   [-1, 10]               0\n",
      "         Linear-5866                   [-1, 10]             110\n",
      "    BatchNorm1d-5867                   [-1, 10]              20\n",
      "           ReLU-5868                   [-1, 10]               0\n",
      "        Dropout-5869                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5870                   [-1, 10]               0\n",
      "         Linear-5871                   [-1, 10]             110\n",
      "    BatchNorm1d-5872                   [-1, 10]              20\n",
      "           ReLU-5873                   [-1, 10]               0\n",
      "        Dropout-5874                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5875                   [-1, 10]               0\n",
      "         Linear-5876                   [-1, 10]             110\n",
      "    BatchNorm1d-5877                   [-1, 10]              20\n",
      "           ReLU-5878                   [-1, 10]               0\n",
      "        Dropout-5879                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5880                   [-1, 10]               0\n",
      "         Linear-5881                   [-1, 10]             110\n",
      "    BatchNorm1d-5882                   [-1, 10]              20\n",
      "           ReLU-5883                   [-1, 10]               0\n",
      "        Dropout-5884                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5885                   [-1, 10]               0\n",
      "         Linear-5886                   [-1, 10]             110\n",
      "        Softmax-5887                   [-1, 10]               0\n",
      "         Linear-5888                   [-1, 10]             110\n",
      "    BatchNorm1d-5889                   [-1, 10]              20\n",
      "           ReLU-5890                   [-1, 10]               0\n",
      "        Dropout-5891                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5892                   [-1, 10]               0\n",
      "         Linear-5893                   [-1, 10]             110\n",
      "    BatchNorm1d-5894                   [-1, 10]              20\n",
      "           ReLU-5895                   [-1, 10]               0\n",
      "        Dropout-5896                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5897                   [-1, 10]               0\n",
      "         Linear-5898                   [-1, 10]             110\n",
      "    BatchNorm1d-5899                   [-1, 10]              20\n",
      "           ReLU-5900                   [-1, 10]               0\n",
      "        Dropout-5901                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5902                   [-1, 10]               0\n",
      "         Linear-5903                   [-1, 10]             110\n",
      "    BatchNorm1d-5904                   [-1, 10]              20\n",
      "           ReLU-5905                   [-1, 10]               0\n",
      "        Dropout-5906                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5907                   [-1, 10]               0\n",
      "         Linear-5908                   [-1, 10]             110\n",
      "    BatchNorm1d-5909                   [-1, 10]              20\n",
      "           ReLU-5910                   [-1, 10]               0\n",
      "        Dropout-5911                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5912                   [-1, 10]               0\n",
      "         Linear-5913                   [-1, 10]             110\n",
      "        Softmax-5914                   [-1, 10]               0\n",
      "         Linear-5915                   [-1, 15]             165\n",
      "        Softmax-5916                   [-1, 15]               0\n",
      "         Linear-5917                   [-1, 10]             110\n",
      "    BatchNorm1d-5918                   [-1, 10]              20\n",
      "           ReLU-5919                   [-1, 10]               0\n",
      "        Dropout-5920                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5921                   [-1, 10]               0\n",
      "         Linear-5922                   [-1, 10]             110\n",
      "    BatchNorm1d-5923                   [-1, 10]              20\n",
      "           ReLU-5924                   [-1, 10]               0\n",
      "        Dropout-5925                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5926                   [-1, 10]               0\n",
      "         Linear-5927                   [-1, 10]             110\n",
      "    BatchNorm1d-5928                   [-1, 10]              20\n",
      "           ReLU-5929                   [-1, 10]               0\n",
      "        Dropout-5930                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5931                   [-1, 10]               0\n",
      "         Linear-5932                   [-1, 10]             110\n",
      "    BatchNorm1d-5933                   [-1, 10]              20\n",
      "           ReLU-5934                   [-1, 10]               0\n",
      "        Dropout-5935                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5936                   [-1, 10]               0\n",
      "         Linear-5937                   [-1, 10]             110\n",
      "    BatchNorm1d-5938                   [-1, 10]              20\n",
      "           ReLU-5939                   [-1, 10]               0\n",
      "        Dropout-5940                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5941                   [-1, 10]               0\n",
      "         Linear-5942                   [-1, 10]             110\n",
      "    BatchNorm1d-5943                   [-1, 10]              20\n",
      "           ReLU-5944                   [-1, 10]               0\n",
      "        Dropout-5945                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5946                   [-1, 10]               0\n",
      "         Linear-5947                   [-1, 10]             110\n",
      "    BatchNorm1d-5948                   [-1, 10]              20\n",
      "           ReLU-5949                   [-1, 10]               0\n",
      "        Dropout-5950                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5951                   [-1, 10]               0\n",
      "         Linear-5952                   [-1, 10]             110\n",
      "    BatchNorm1d-5953                   [-1, 10]              20\n",
      "           ReLU-5954                   [-1, 10]               0\n",
      "        Dropout-5955                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5956                   [-1, 10]               0\n",
      "         Linear-5957                   [-1, 10]             110\n",
      "    BatchNorm1d-5958                   [-1, 10]              20\n",
      "           ReLU-5959                   [-1, 10]               0\n",
      "        Dropout-5960                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5961                   [-1, 10]               0\n",
      "         Linear-5962                   [-1, 10]             110\n",
      "    BatchNorm1d-5963                   [-1, 10]              20\n",
      "           ReLU-5964                   [-1, 10]               0\n",
      "        Dropout-5965                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5966                   [-1, 10]               0\n",
      "         Linear-5967                   [-1, 10]             110\n",
      "        Softmax-5968                   [-1, 10]               0\n",
      "         Linear-5969                   [-1, 10]             110\n",
      "    BatchNorm1d-5970                   [-1, 10]              20\n",
      "           ReLU-5971                   [-1, 10]               0\n",
      "        Dropout-5972                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5973                   [-1, 10]               0\n",
      "         Linear-5974                   [-1, 10]             110\n",
      "    BatchNorm1d-5975                   [-1, 10]              20\n",
      "           ReLU-5976                   [-1, 10]               0\n",
      "        Dropout-5977                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5978                   [-1, 10]               0\n",
      "         Linear-5979                   [-1, 10]             110\n",
      "    BatchNorm1d-5980                   [-1, 10]              20\n",
      "           ReLU-5981                   [-1, 10]               0\n",
      "        Dropout-5982                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5983                   [-1, 10]               0\n",
      "         Linear-5984                   [-1, 10]             110\n",
      "    BatchNorm1d-5985                   [-1, 10]              20\n",
      "           ReLU-5986                   [-1, 10]               0\n",
      "        Dropout-5987                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5988                   [-1, 10]               0\n",
      "         Linear-5989                   [-1, 10]             110\n",
      "    BatchNorm1d-5990                   [-1, 10]              20\n",
      "           ReLU-5991                   [-1, 10]               0\n",
      "        Dropout-5992                   [-1, 10]               0\n",
      "MultiLayerPerceptron-5993                   [-1, 10]               0\n",
      "         Linear-5994                   [-1, 10]             110\n",
      "        Softmax-5995                   [-1, 10]               0\n",
      "         Linear-5996                   [-1, 15]             165\n",
      "        Softmax-5997                   [-1, 15]               0\n",
      "         Linear-5998                   [-1, 10]             110\n",
      "    BatchNorm1d-5999                   [-1, 10]              20\n",
      "           ReLU-6000                   [-1, 10]               0\n",
      "        Dropout-6001                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6002                   [-1, 10]               0\n",
      "         Linear-6003                   [-1, 10]             110\n",
      "    BatchNorm1d-6004                   [-1, 10]              20\n",
      "           ReLU-6005                   [-1, 10]               0\n",
      "        Dropout-6006                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6007                   [-1, 10]               0\n",
      "         Linear-6008                   [-1, 10]             110\n",
      "    BatchNorm1d-6009                   [-1, 10]              20\n",
      "           ReLU-6010                   [-1, 10]               0\n",
      "        Dropout-6011                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6012                   [-1, 10]               0\n",
      "         Linear-6013                   [-1, 10]             110\n",
      "    BatchNorm1d-6014                   [-1, 10]              20\n",
      "           ReLU-6015                   [-1, 10]               0\n",
      "        Dropout-6016                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6017                   [-1, 10]               0\n",
      "         Linear-6018                   [-1, 10]             110\n",
      "    BatchNorm1d-6019                   [-1, 10]              20\n",
      "           ReLU-6020                   [-1, 10]               0\n",
      "        Dropout-6021                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6022                   [-1, 10]               0\n",
      "         Linear-6023                   [-1, 10]             110\n",
      "    BatchNorm1d-6024                   [-1, 10]              20\n",
      "           ReLU-6025                   [-1, 10]               0\n",
      "        Dropout-6026                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6027                   [-1, 10]               0\n",
      "         Linear-6028                   [-1, 10]             110\n",
      "    BatchNorm1d-6029                   [-1, 10]              20\n",
      "           ReLU-6030                   [-1, 10]               0\n",
      "        Dropout-6031                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6032                   [-1, 10]               0\n",
      "         Linear-6033                   [-1, 10]             110\n",
      "    BatchNorm1d-6034                   [-1, 10]              20\n",
      "           ReLU-6035                   [-1, 10]               0\n",
      "        Dropout-6036                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6037                   [-1, 10]               0\n",
      "         Linear-6038                   [-1, 10]             110\n",
      "    BatchNorm1d-6039                   [-1, 10]              20\n",
      "           ReLU-6040                   [-1, 10]               0\n",
      "        Dropout-6041                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6042                   [-1, 10]               0\n",
      "         Linear-6043                   [-1, 10]             110\n",
      "    BatchNorm1d-6044                   [-1, 10]              20\n",
      "           ReLU-6045                   [-1, 10]               0\n",
      "        Dropout-6046                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6047                   [-1, 10]               0\n",
      "         Linear-6048                   [-1, 10]             110\n",
      "        Softmax-6049                   [-1, 10]               0\n",
      "         Linear-6050                   [-1, 10]             110\n",
      "    BatchNorm1d-6051                   [-1, 10]              20\n",
      "           ReLU-6052                   [-1, 10]               0\n",
      "        Dropout-6053                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6054                   [-1, 10]               0\n",
      "         Linear-6055                   [-1, 10]             110\n",
      "    BatchNorm1d-6056                   [-1, 10]              20\n",
      "           ReLU-6057                   [-1, 10]               0\n",
      "        Dropout-6058                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6059                   [-1, 10]               0\n",
      "         Linear-6060                   [-1, 10]             110\n",
      "    BatchNorm1d-6061                   [-1, 10]              20\n",
      "           ReLU-6062                   [-1, 10]               0\n",
      "        Dropout-6063                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6064                   [-1, 10]               0\n",
      "         Linear-6065                   [-1, 10]             110\n",
      "    BatchNorm1d-6066                   [-1, 10]              20\n",
      "           ReLU-6067                   [-1, 10]               0\n",
      "        Dropout-6068                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6069                   [-1, 10]               0\n",
      "         Linear-6070                   [-1, 10]             110\n",
      "    BatchNorm1d-6071                   [-1, 10]              20\n",
      "           ReLU-6072                   [-1, 10]               0\n",
      "        Dropout-6073                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6074                   [-1, 10]               0\n",
      "         Linear-6075                   [-1, 10]             110\n",
      "        Softmax-6076                   [-1, 10]               0\n",
      "         Linear-6077                   [-1, 15]             165\n",
      "        Softmax-6078                   [-1, 15]               0\n",
      "         Linear-6079                   [-1, 10]             110\n",
      "    BatchNorm1d-6080                   [-1, 10]              20\n",
      "           ReLU-6081                   [-1, 10]               0\n",
      "        Dropout-6082                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6083                   [-1, 10]               0\n",
      "         Linear-6084                   [-1, 10]             110\n",
      "    BatchNorm1d-6085                   [-1, 10]              20\n",
      "           ReLU-6086                   [-1, 10]               0\n",
      "        Dropout-6087                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6088                   [-1, 10]               0\n",
      "         Linear-6089                   [-1, 10]             110\n",
      "    BatchNorm1d-6090                   [-1, 10]              20\n",
      "           ReLU-6091                   [-1, 10]               0\n",
      "        Dropout-6092                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6093                   [-1, 10]               0\n",
      "         Linear-6094                   [-1, 10]             110\n",
      "    BatchNorm1d-6095                   [-1, 10]              20\n",
      "           ReLU-6096                   [-1, 10]               0\n",
      "        Dropout-6097                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6098                   [-1, 10]               0\n",
      "         Linear-6099                   [-1, 10]             110\n",
      "    BatchNorm1d-6100                   [-1, 10]              20\n",
      "           ReLU-6101                   [-1, 10]               0\n",
      "        Dropout-6102                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6103                   [-1, 10]               0\n",
      "         Linear-6104                   [-1, 10]             110\n",
      "    BatchNorm1d-6105                   [-1, 10]              20\n",
      "           ReLU-6106                   [-1, 10]               0\n",
      "        Dropout-6107                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6108                   [-1, 10]               0\n",
      "         Linear-6109                   [-1, 10]             110\n",
      "    BatchNorm1d-6110                   [-1, 10]              20\n",
      "           ReLU-6111                   [-1, 10]               0\n",
      "        Dropout-6112                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6113                   [-1, 10]               0\n",
      "         Linear-6114                   [-1, 10]             110\n",
      "    BatchNorm1d-6115                   [-1, 10]              20\n",
      "           ReLU-6116                   [-1, 10]               0\n",
      "        Dropout-6117                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6118                   [-1, 10]               0\n",
      "         Linear-6119                   [-1, 10]             110\n",
      "    BatchNorm1d-6120                   [-1, 10]              20\n",
      "           ReLU-6121                   [-1, 10]               0\n",
      "        Dropout-6122                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6123                   [-1, 10]               0\n",
      "         Linear-6124                   [-1, 10]             110\n",
      "    BatchNorm1d-6125                   [-1, 10]              20\n",
      "           ReLU-6126                   [-1, 10]               0\n",
      "        Dropout-6127                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6128                   [-1, 10]               0\n",
      "         Linear-6129                   [-1, 10]             110\n",
      "        Softmax-6130                   [-1, 10]               0\n",
      "         Linear-6131                   [-1, 10]             110\n",
      "    BatchNorm1d-6132                   [-1, 10]              20\n",
      "           ReLU-6133                   [-1, 10]               0\n",
      "        Dropout-6134                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6135                   [-1, 10]               0\n",
      "         Linear-6136                   [-1, 10]             110\n",
      "    BatchNorm1d-6137                   [-1, 10]              20\n",
      "           ReLU-6138                   [-1, 10]               0\n",
      "        Dropout-6139                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6140                   [-1, 10]               0\n",
      "         Linear-6141                   [-1, 10]             110\n",
      "    BatchNorm1d-6142                   [-1, 10]              20\n",
      "           ReLU-6143                   [-1, 10]               0\n",
      "        Dropout-6144                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6145                   [-1, 10]               0\n",
      "         Linear-6146                   [-1, 10]             110\n",
      "    BatchNorm1d-6147                   [-1, 10]              20\n",
      "           ReLU-6148                   [-1, 10]               0\n",
      "        Dropout-6149                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6150                   [-1, 10]               0\n",
      "         Linear-6151                   [-1, 10]             110\n",
      "    BatchNorm1d-6152                   [-1, 10]              20\n",
      "           ReLU-6153                   [-1, 10]               0\n",
      "        Dropout-6154                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6155                   [-1, 10]               0\n",
      "         Linear-6156                   [-1, 10]             110\n",
      "        Softmax-6157                   [-1, 10]               0\n",
      "         Linear-6158                   [-1, 15]             165\n",
      "        Softmax-6159                   [-1, 15]               0\n",
      "         Linear-6160                   [-1, 10]             110\n",
      "    BatchNorm1d-6161                   [-1, 10]              20\n",
      "           ReLU-6162                   [-1, 10]               0\n",
      "        Dropout-6163                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6164                   [-1, 10]               0\n",
      "         Linear-6165                   [-1, 10]             110\n",
      "    BatchNorm1d-6166                   [-1, 10]              20\n",
      "           ReLU-6167                   [-1, 10]               0\n",
      "        Dropout-6168                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6169                   [-1, 10]               0\n",
      "         Linear-6170                   [-1, 10]             110\n",
      "    BatchNorm1d-6171                   [-1, 10]              20\n",
      "           ReLU-6172                   [-1, 10]               0\n",
      "        Dropout-6173                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6174                   [-1, 10]               0\n",
      "         Linear-6175                   [-1, 10]             110\n",
      "    BatchNorm1d-6176                   [-1, 10]              20\n",
      "           ReLU-6177                   [-1, 10]               0\n",
      "        Dropout-6178                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6179                   [-1, 10]               0\n",
      "         Linear-6180                   [-1, 10]             110\n",
      "    BatchNorm1d-6181                   [-1, 10]              20\n",
      "           ReLU-6182                   [-1, 10]               0\n",
      "        Dropout-6183                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6184                   [-1, 10]               0\n",
      "         Linear-6185                   [-1, 10]             110\n",
      "    BatchNorm1d-6186                   [-1, 10]              20\n",
      "           ReLU-6187                   [-1, 10]               0\n",
      "        Dropout-6188                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6189                   [-1, 10]               0\n",
      "         Linear-6190                   [-1, 10]             110\n",
      "    BatchNorm1d-6191                   [-1, 10]              20\n",
      "           ReLU-6192                   [-1, 10]               0\n",
      "        Dropout-6193                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6194                   [-1, 10]               0\n",
      "         Linear-6195                   [-1, 10]             110\n",
      "    BatchNorm1d-6196                   [-1, 10]              20\n",
      "           ReLU-6197                   [-1, 10]               0\n",
      "        Dropout-6198                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6199                   [-1, 10]               0\n",
      "         Linear-6200                   [-1, 10]             110\n",
      "    BatchNorm1d-6201                   [-1, 10]              20\n",
      "           ReLU-6202                   [-1, 10]               0\n",
      "        Dropout-6203                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6204                   [-1, 10]               0\n",
      "         Linear-6205                   [-1, 10]             110\n",
      "    BatchNorm1d-6206                   [-1, 10]              20\n",
      "           ReLU-6207                   [-1, 10]               0\n",
      "        Dropout-6208                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6209                   [-1, 10]               0\n",
      "         Linear-6210                   [-1, 10]             110\n",
      "        Softmax-6211                   [-1, 10]               0\n",
      "         Linear-6212                   [-1, 10]             110\n",
      "    BatchNorm1d-6213                   [-1, 10]              20\n",
      "           ReLU-6214                   [-1, 10]               0\n",
      "        Dropout-6215                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6216                   [-1, 10]               0\n",
      "         Linear-6217                   [-1, 10]             110\n",
      "    BatchNorm1d-6218                   [-1, 10]              20\n",
      "           ReLU-6219                   [-1, 10]               0\n",
      "        Dropout-6220                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6221                   [-1, 10]               0\n",
      "         Linear-6222                   [-1, 10]             110\n",
      "    BatchNorm1d-6223                   [-1, 10]              20\n",
      "           ReLU-6224                   [-1, 10]               0\n",
      "        Dropout-6225                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6226                   [-1, 10]               0\n",
      "         Linear-6227                   [-1, 10]             110\n",
      "    BatchNorm1d-6228                   [-1, 10]              20\n",
      "           ReLU-6229                   [-1, 10]               0\n",
      "        Dropout-6230                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6231                   [-1, 10]               0\n",
      "         Linear-6232                   [-1, 10]             110\n",
      "    BatchNorm1d-6233                   [-1, 10]              20\n",
      "           ReLU-6234                   [-1, 10]               0\n",
      "        Dropout-6235                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6236                   [-1, 10]               0\n",
      "         Linear-6237                   [-1, 10]             110\n",
      "        Softmax-6238                   [-1, 10]               0\n",
      "         Linear-6239                   [-1, 15]             165\n",
      "        Softmax-6240                   [-1, 15]               0\n",
      "         Linear-6241                   [-1, 10]             110\n",
      "    BatchNorm1d-6242                   [-1, 10]              20\n",
      "           ReLU-6243                   [-1, 10]               0\n",
      "        Dropout-6244                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6245                   [-1, 10]               0\n",
      "         Linear-6246                   [-1, 10]             110\n",
      "    BatchNorm1d-6247                   [-1, 10]              20\n",
      "           ReLU-6248                   [-1, 10]               0\n",
      "        Dropout-6249                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6250                   [-1, 10]               0\n",
      "         Linear-6251                   [-1, 10]             110\n",
      "    BatchNorm1d-6252                   [-1, 10]              20\n",
      "           ReLU-6253                   [-1, 10]               0\n",
      "        Dropout-6254                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6255                   [-1, 10]               0\n",
      "         Linear-6256                   [-1, 10]             110\n",
      "    BatchNorm1d-6257                   [-1, 10]              20\n",
      "           ReLU-6258                   [-1, 10]               0\n",
      "        Dropout-6259                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6260                   [-1, 10]               0\n",
      "         Linear-6261                   [-1, 10]             110\n",
      "    BatchNorm1d-6262                   [-1, 10]              20\n",
      "           ReLU-6263                   [-1, 10]               0\n",
      "        Dropout-6264                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6265                   [-1, 10]               0\n",
      "         Linear-6266                   [-1, 10]             110\n",
      "    BatchNorm1d-6267                   [-1, 10]              20\n",
      "           ReLU-6268                   [-1, 10]               0\n",
      "        Dropout-6269                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6270                   [-1, 10]               0\n",
      "         Linear-6271                   [-1, 10]             110\n",
      "    BatchNorm1d-6272                   [-1, 10]              20\n",
      "           ReLU-6273                   [-1, 10]               0\n",
      "        Dropout-6274                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6275                   [-1, 10]               0\n",
      "         Linear-6276                   [-1, 10]             110\n",
      "    BatchNorm1d-6277                   [-1, 10]              20\n",
      "           ReLU-6278                   [-1, 10]               0\n",
      "        Dropout-6279                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6280                   [-1, 10]               0\n",
      "         Linear-6281                   [-1, 10]             110\n",
      "    BatchNorm1d-6282                   [-1, 10]              20\n",
      "           ReLU-6283                   [-1, 10]               0\n",
      "        Dropout-6284                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6285                   [-1, 10]               0\n",
      "         Linear-6286                   [-1, 10]             110\n",
      "    BatchNorm1d-6287                   [-1, 10]              20\n",
      "           ReLU-6288                   [-1, 10]               0\n",
      "        Dropout-6289                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6290                   [-1, 10]               0\n",
      "         Linear-6291                   [-1, 10]             110\n",
      "        Softmax-6292                   [-1, 10]               0\n",
      "         Linear-6293                   [-1, 10]             110\n",
      "    BatchNorm1d-6294                   [-1, 10]              20\n",
      "           ReLU-6295                   [-1, 10]               0\n",
      "        Dropout-6296                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6297                   [-1, 10]               0\n",
      "         Linear-6298                   [-1, 10]             110\n",
      "    BatchNorm1d-6299                   [-1, 10]              20\n",
      "           ReLU-6300                   [-1, 10]               0\n",
      "        Dropout-6301                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6302                   [-1, 10]               0\n",
      "         Linear-6303                   [-1, 10]             110\n",
      "    BatchNorm1d-6304                   [-1, 10]              20\n",
      "           ReLU-6305                   [-1, 10]               0\n",
      "        Dropout-6306                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6307                   [-1, 10]               0\n",
      "         Linear-6308                   [-1, 10]             110\n",
      "    BatchNorm1d-6309                   [-1, 10]              20\n",
      "           ReLU-6310                   [-1, 10]               0\n",
      "        Dropout-6311                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6312                   [-1, 10]               0\n",
      "         Linear-6313                   [-1, 10]             110\n",
      "    BatchNorm1d-6314                   [-1, 10]              20\n",
      "           ReLU-6315                   [-1, 10]               0\n",
      "        Dropout-6316                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6317                   [-1, 10]               0\n",
      "         Linear-6318                   [-1, 10]             110\n",
      "        Softmax-6319                   [-1, 10]               0\n",
      "         Linear-6320                   [-1, 15]             165\n",
      "        Softmax-6321                   [-1, 15]               0\n",
      "         Linear-6322                   [-1, 10]             110\n",
      "    BatchNorm1d-6323                   [-1, 10]              20\n",
      "           ReLU-6324                   [-1, 10]               0\n",
      "        Dropout-6325                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6326                   [-1, 10]               0\n",
      "         Linear-6327                   [-1, 10]             110\n",
      "    BatchNorm1d-6328                   [-1, 10]              20\n",
      "           ReLU-6329                   [-1, 10]               0\n",
      "        Dropout-6330                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6331                   [-1, 10]               0\n",
      "         Linear-6332                   [-1, 10]             110\n",
      "    BatchNorm1d-6333                   [-1, 10]              20\n",
      "           ReLU-6334                   [-1, 10]               0\n",
      "        Dropout-6335                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6336                   [-1, 10]               0\n",
      "         Linear-6337                   [-1, 10]             110\n",
      "    BatchNorm1d-6338                   [-1, 10]              20\n",
      "           ReLU-6339                   [-1, 10]               0\n",
      "        Dropout-6340                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6341                   [-1, 10]               0\n",
      "         Linear-6342                   [-1, 10]             110\n",
      "    BatchNorm1d-6343                   [-1, 10]              20\n",
      "           ReLU-6344                   [-1, 10]               0\n",
      "        Dropout-6345                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6346                   [-1, 10]               0\n",
      "         Linear-6347                   [-1, 10]             110\n",
      "    BatchNorm1d-6348                   [-1, 10]              20\n",
      "           ReLU-6349                   [-1, 10]               0\n",
      "        Dropout-6350                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6351                   [-1, 10]               0\n",
      "         Linear-6352                   [-1, 10]             110\n",
      "    BatchNorm1d-6353                   [-1, 10]              20\n",
      "           ReLU-6354                   [-1, 10]               0\n",
      "        Dropout-6355                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6356                   [-1, 10]               0\n",
      "         Linear-6357                   [-1, 10]             110\n",
      "    BatchNorm1d-6358                   [-1, 10]              20\n",
      "           ReLU-6359                   [-1, 10]               0\n",
      "        Dropout-6360                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6361                   [-1, 10]               0\n",
      "         Linear-6362                   [-1, 10]             110\n",
      "    BatchNorm1d-6363                   [-1, 10]              20\n",
      "           ReLU-6364                   [-1, 10]               0\n",
      "        Dropout-6365                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6366                   [-1, 10]               0\n",
      "         Linear-6367                   [-1, 10]             110\n",
      "    BatchNorm1d-6368                   [-1, 10]              20\n",
      "           ReLU-6369                   [-1, 10]               0\n",
      "        Dropout-6370                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6371                   [-1, 10]               0\n",
      "         Linear-6372                   [-1, 10]             110\n",
      "        Softmax-6373                   [-1, 10]               0\n",
      "         Linear-6374                   [-1, 10]             110\n",
      "    BatchNorm1d-6375                   [-1, 10]              20\n",
      "           ReLU-6376                   [-1, 10]               0\n",
      "        Dropout-6377                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6378                   [-1, 10]               0\n",
      "         Linear-6379                   [-1, 10]             110\n",
      "    BatchNorm1d-6380                   [-1, 10]              20\n",
      "           ReLU-6381                   [-1, 10]               0\n",
      "        Dropout-6382                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6383                   [-1, 10]               0\n",
      "         Linear-6384                   [-1, 10]             110\n",
      "    BatchNorm1d-6385                   [-1, 10]              20\n",
      "           ReLU-6386                   [-1, 10]               0\n",
      "        Dropout-6387                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6388                   [-1, 10]               0\n",
      "         Linear-6389                   [-1, 10]             110\n",
      "    BatchNorm1d-6390                   [-1, 10]              20\n",
      "           ReLU-6391                   [-1, 10]               0\n",
      "        Dropout-6392                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6393                   [-1, 10]               0\n",
      "         Linear-6394                   [-1, 10]             110\n",
      "    BatchNorm1d-6395                   [-1, 10]              20\n",
      "           ReLU-6396                   [-1, 10]               0\n",
      "        Dropout-6397                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6398                   [-1, 10]               0\n",
      "         Linear-6399                   [-1, 10]             110\n",
      "        Softmax-6400                   [-1, 10]               0\n",
      "         Linear-6401                   [-1, 15]             165\n",
      "        Softmax-6402                   [-1, 15]               0\n",
      "         Linear-6403                   [-1, 10]             110\n",
      "    BatchNorm1d-6404                   [-1, 10]              20\n",
      "           ReLU-6405                   [-1, 10]               0\n",
      "        Dropout-6406                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6407                   [-1, 10]               0\n",
      "         Linear-6408                   [-1, 10]             110\n",
      "    BatchNorm1d-6409                   [-1, 10]              20\n",
      "           ReLU-6410                   [-1, 10]               0\n",
      "        Dropout-6411                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6412                   [-1, 10]               0\n",
      "         Linear-6413                   [-1, 10]             110\n",
      "    BatchNorm1d-6414                   [-1, 10]              20\n",
      "           ReLU-6415                   [-1, 10]               0\n",
      "        Dropout-6416                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6417                   [-1, 10]               0\n",
      "         Linear-6418                   [-1, 10]             110\n",
      "    BatchNorm1d-6419                   [-1, 10]              20\n",
      "           ReLU-6420                   [-1, 10]               0\n",
      "        Dropout-6421                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6422                   [-1, 10]               0\n",
      "         Linear-6423                   [-1, 10]             110\n",
      "    BatchNorm1d-6424                   [-1, 10]              20\n",
      "           ReLU-6425                   [-1, 10]               0\n",
      "        Dropout-6426                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6427                   [-1, 10]               0\n",
      "         Linear-6428                   [-1, 10]             110\n",
      "    BatchNorm1d-6429                   [-1, 10]              20\n",
      "           ReLU-6430                   [-1, 10]               0\n",
      "        Dropout-6431                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6432                   [-1, 10]               0\n",
      "         Linear-6433                   [-1, 10]             110\n",
      "    BatchNorm1d-6434                   [-1, 10]              20\n",
      "           ReLU-6435                   [-1, 10]               0\n",
      "        Dropout-6436                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6437                   [-1, 10]               0\n",
      "         Linear-6438                   [-1, 10]             110\n",
      "    BatchNorm1d-6439                   [-1, 10]              20\n",
      "           ReLU-6440                   [-1, 10]               0\n",
      "        Dropout-6441                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6442                   [-1, 10]               0\n",
      "         Linear-6443                   [-1, 10]             110\n",
      "    BatchNorm1d-6444                   [-1, 10]              20\n",
      "           ReLU-6445                   [-1, 10]               0\n",
      "        Dropout-6446                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6447                   [-1, 10]               0\n",
      "         Linear-6448                   [-1, 10]             110\n",
      "    BatchNorm1d-6449                   [-1, 10]              20\n",
      "           ReLU-6450                   [-1, 10]               0\n",
      "        Dropout-6451                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6452                   [-1, 10]               0\n",
      "         Linear-6453                   [-1, 10]             110\n",
      "        Softmax-6454                   [-1, 10]               0\n",
      "         Linear-6455                   [-1, 10]             110\n",
      "    BatchNorm1d-6456                   [-1, 10]              20\n",
      "           ReLU-6457                   [-1, 10]               0\n",
      "        Dropout-6458                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6459                   [-1, 10]               0\n",
      "         Linear-6460                   [-1, 10]             110\n",
      "    BatchNorm1d-6461                   [-1, 10]              20\n",
      "           ReLU-6462                   [-1, 10]               0\n",
      "        Dropout-6463                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6464                   [-1, 10]               0\n",
      "         Linear-6465                   [-1, 10]             110\n",
      "    BatchNorm1d-6466                   [-1, 10]              20\n",
      "           ReLU-6467                   [-1, 10]               0\n",
      "        Dropout-6468                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6469                   [-1, 10]               0\n",
      "         Linear-6470                   [-1, 10]             110\n",
      "    BatchNorm1d-6471                   [-1, 10]              20\n",
      "           ReLU-6472                   [-1, 10]               0\n",
      "        Dropout-6473                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6474                   [-1, 10]               0\n",
      "         Linear-6475                   [-1, 10]             110\n",
      "    BatchNorm1d-6476                   [-1, 10]              20\n",
      "           ReLU-6477                   [-1, 10]               0\n",
      "        Dropout-6478                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6479                   [-1, 10]               0\n",
      "         Linear-6480                   [-1, 10]             110\n",
      "        Softmax-6481                   [-1, 10]               0\n",
      "         Linear-6482                   [-1, 15]             165\n",
      "        Softmax-6483                   [-1, 15]               0\n",
      "         Linear-6484                   [-1, 10]             110\n",
      "    BatchNorm1d-6485                   [-1, 10]              20\n",
      "           ReLU-6486                   [-1, 10]               0\n",
      "        Dropout-6487                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6488                   [-1, 10]               0\n",
      "         Linear-6489                   [-1, 10]             110\n",
      "    BatchNorm1d-6490                   [-1, 10]              20\n",
      "           ReLU-6491                   [-1, 10]               0\n",
      "        Dropout-6492                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6493                   [-1, 10]               0\n",
      "         Linear-6494                   [-1, 10]             110\n",
      "    BatchNorm1d-6495                   [-1, 10]              20\n",
      "           ReLU-6496                   [-1, 10]               0\n",
      "        Dropout-6497                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6498                   [-1, 10]               0\n",
      "         Linear-6499                   [-1, 10]             110\n",
      "    BatchNorm1d-6500                   [-1, 10]              20\n",
      "           ReLU-6501                   [-1, 10]               0\n",
      "        Dropout-6502                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6503                   [-1, 10]               0\n",
      "         Linear-6504                   [-1, 10]             110\n",
      "    BatchNorm1d-6505                   [-1, 10]              20\n",
      "           ReLU-6506                   [-1, 10]               0\n",
      "        Dropout-6507                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6508                   [-1, 10]               0\n",
      "         Linear-6509                   [-1, 10]             110\n",
      "    BatchNorm1d-6510                   [-1, 10]              20\n",
      "           ReLU-6511                   [-1, 10]               0\n",
      "        Dropout-6512                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6513                   [-1, 10]               0\n",
      "         Linear-6514                   [-1, 10]             110\n",
      "    BatchNorm1d-6515                   [-1, 10]              20\n",
      "           ReLU-6516                   [-1, 10]               0\n",
      "        Dropout-6517                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6518                   [-1, 10]               0\n",
      "         Linear-6519                   [-1, 10]             110\n",
      "    BatchNorm1d-6520                   [-1, 10]              20\n",
      "           ReLU-6521                   [-1, 10]               0\n",
      "        Dropout-6522                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6523                   [-1, 10]               0\n",
      "         Linear-6524                   [-1, 10]             110\n",
      "    BatchNorm1d-6525                   [-1, 10]              20\n",
      "           ReLU-6526                   [-1, 10]               0\n",
      "        Dropout-6527                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6528                   [-1, 10]               0\n",
      "         Linear-6529                   [-1, 10]             110\n",
      "    BatchNorm1d-6530                   [-1, 10]              20\n",
      "           ReLU-6531                   [-1, 10]               0\n",
      "        Dropout-6532                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6533                   [-1, 10]               0\n",
      "         Linear-6534                   [-1, 10]             110\n",
      "        Softmax-6535                   [-1, 10]               0\n",
      "         Linear-6536                   [-1, 10]             110\n",
      "    BatchNorm1d-6537                   [-1, 10]              20\n",
      "           ReLU-6538                   [-1, 10]               0\n",
      "        Dropout-6539                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6540                   [-1, 10]               0\n",
      "         Linear-6541                   [-1, 10]             110\n",
      "    BatchNorm1d-6542                   [-1, 10]              20\n",
      "           ReLU-6543                   [-1, 10]               0\n",
      "        Dropout-6544                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6545                   [-1, 10]               0\n",
      "         Linear-6546                   [-1, 10]             110\n",
      "    BatchNorm1d-6547                   [-1, 10]              20\n",
      "           ReLU-6548                   [-1, 10]               0\n",
      "        Dropout-6549                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6550                   [-1, 10]               0\n",
      "         Linear-6551                   [-1, 10]             110\n",
      "    BatchNorm1d-6552                   [-1, 10]              20\n",
      "           ReLU-6553                   [-1, 10]               0\n",
      "        Dropout-6554                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6555                   [-1, 10]               0\n",
      "         Linear-6556                   [-1, 10]             110\n",
      "    BatchNorm1d-6557                   [-1, 10]              20\n",
      "           ReLU-6558                   [-1, 10]               0\n",
      "        Dropout-6559                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6560                   [-1, 10]               0\n",
      "         Linear-6561                   [-1, 10]             110\n",
      "        Softmax-6562                   [-1, 10]               0\n",
      "         Linear-6563                   [-1, 15]             165\n",
      "        Softmax-6564                   [-1, 15]               0\n",
      "         Linear-6565                   [-1, 10]             110\n",
      "    BatchNorm1d-6566                   [-1, 10]              20\n",
      "           ReLU-6567                   [-1, 10]               0\n",
      "        Dropout-6568                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6569                   [-1, 10]               0\n",
      "         Linear-6570                   [-1, 10]             110\n",
      "    BatchNorm1d-6571                   [-1, 10]              20\n",
      "           ReLU-6572                   [-1, 10]               0\n",
      "        Dropout-6573                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6574                   [-1, 10]               0\n",
      "         Linear-6575                   [-1, 10]             110\n",
      "    BatchNorm1d-6576                   [-1, 10]              20\n",
      "           ReLU-6577                   [-1, 10]               0\n",
      "        Dropout-6578                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6579                   [-1, 10]               0\n",
      "         Linear-6580                   [-1, 10]             110\n",
      "    BatchNorm1d-6581                   [-1, 10]              20\n",
      "           ReLU-6582                   [-1, 10]               0\n",
      "        Dropout-6583                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6584                   [-1, 10]               0\n",
      "         Linear-6585                   [-1, 10]             110\n",
      "    BatchNorm1d-6586                   [-1, 10]              20\n",
      "           ReLU-6587                   [-1, 10]               0\n",
      "        Dropout-6588                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6589                   [-1, 10]               0\n",
      "         Linear-6590                   [-1, 10]             110\n",
      "    BatchNorm1d-6591                   [-1, 10]              20\n",
      "           ReLU-6592                   [-1, 10]               0\n",
      "        Dropout-6593                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6594                   [-1, 10]               0\n",
      "         Linear-6595                   [-1, 10]             110\n",
      "    BatchNorm1d-6596                   [-1, 10]              20\n",
      "           ReLU-6597                   [-1, 10]               0\n",
      "        Dropout-6598                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6599                   [-1, 10]               0\n",
      "         Linear-6600                   [-1, 10]             110\n",
      "    BatchNorm1d-6601                   [-1, 10]              20\n",
      "           ReLU-6602                   [-1, 10]               0\n",
      "        Dropout-6603                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6604                   [-1, 10]               0\n",
      "         Linear-6605                   [-1, 10]             110\n",
      "    BatchNorm1d-6606                   [-1, 10]              20\n",
      "           ReLU-6607                   [-1, 10]               0\n",
      "        Dropout-6608                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6609                   [-1, 10]               0\n",
      "         Linear-6610                   [-1, 10]             110\n",
      "    BatchNorm1d-6611                   [-1, 10]              20\n",
      "           ReLU-6612                   [-1, 10]               0\n",
      "        Dropout-6613                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6614                   [-1, 10]               0\n",
      "         Linear-6615                   [-1, 10]             110\n",
      "        Softmax-6616                   [-1, 10]               0\n",
      "         Linear-6617                   [-1, 10]             110\n",
      "    BatchNorm1d-6618                   [-1, 10]              20\n",
      "           ReLU-6619                   [-1, 10]               0\n",
      "        Dropout-6620                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6621                   [-1, 10]               0\n",
      "         Linear-6622                   [-1, 10]             110\n",
      "    BatchNorm1d-6623                   [-1, 10]              20\n",
      "           ReLU-6624                   [-1, 10]               0\n",
      "        Dropout-6625                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6626                   [-1, 10]               0\n",
      "         Linear-6627                   [-1, 10]             110\n",
      "    BatchNorm1d-6628                   [-1, 10]              20\n",
      "           ReLU-6629                   [-1, 10]               0\n",
      "        Dropout-6630                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6631                   [-1, 10]               0\n",
      "         Linear-6632                   [-1, 10]             110\n",
      "    BatchNorm1d-6633                   [-1, 10]              20\n",
      "           ReLU-6634                   [-1, 10]               0\n",
      "        Dropout-6635                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6636                   [-1, 10]               0\n",
      "         Linear-6637                   [-1, 10]             110\n",
      "    BatchNorm1d-6638                   [-1, 10]              20\n",
      "           ReLU-6639                   [-1, 10]               0\n",
      "        Dropout-6640                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6641                   [-1, 10]               0\n",
      "         Linear-6642                   [-1, 10]             110\n",
      "        Softmax-6643                   [-1, 10]               0\n",
      "         Linear-6644                   [-1, 15]             165\n",
      "        Softmax-6645                   [-1, 15]               0\n",
      "         Linear-6646                   [-1, 10]             110\n",
      "    BatchNorm1d-6647                   [-1, 10]              20\n",
      "           ReLU-6648                   [-1, 10]               0\n",
      "        Dropout-6649                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6650                   [-1, 10]               0\n",
      "         Linear-6651                   [-1, 10]             110\n",
      "    BatchNorm1d-6652                   [-1, 10]              20\n",
      "           ReLU-6653                   [-1, 10]               0\n",
      "        Dropout-6654                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6655                   [-1, 10]               0\n",
      "         Linear-6656                   [-1, 10]             110\n",
      "    BatchNorm1d-6657                   [-1, 10]              20\n",
      "           ReLU-6658                   [-1, 10]               0\n",
      "        Dropout-6659                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6660                   [-1, 10]               0\n",
      "         Linear-6661                   [-1, 10]             110\n",
      "    BatchNorm1d-6662                   [-1, 10]              20\n",
      "           ReLU-6663                   [-1, 10]               0\n",
      "        Dropout-6664                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6665                   [-1, 10]               0\n",
      "         Linear-6666                   [-1, 10]             110\n",
      "    BatchNorm1d-6667                   [-1, 10]              20\n",
      "           ReLU-6668                   [-1, 10]               0\n",
      "        Dropout-6669                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6670                   [-1, 10]               0\n",
      "         Linear-6671                   [-1, 10]             110\n",
      "    BatchNorm1d-6672                   [-1, 10]              20\n",
      "           ReLU-6673                   [-1, 10]               0\n",
      "        Dropout-6674                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6675                   [-1, 10]               0\n",
      "         Linear-6676                   [-1, 10]             110\n",
      "    BatchNorm1d-6677                   [-1, 10]              20\n",
      "           ReLU-6678                   [-1, 10]               0\n",
      "        Dropout-6679                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6680                   [-1, 10]               0\n",
      "         Linear-6681                   [-1, 10]             110\n",
      "    BatchNorm1d-6682                   [-1, 10]              20\n",
      "           ReLU-6683                   [-1, 10]               0\n",
      "        Dropout-6684                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6685                   [-1, 10]               0\n",
      "         Linear-6686                   [-1, 10]             110\n",
      "    BatchNorm1d-6687                   [-1, 10]              20\n",
      "           ReLU-6688                   [-1, 10]               0\n",
      "        Dropout-6689                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6690                   [-1, 10]               0\n",
      "         Linear-6691                   [-1, 10]             110\n",
      "    BatchNorm1d-6692                   [-1, 10]              20\n",
      "           ReLU-6693                   [-1, 10]               0\n",
      "        Dropout-6694                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6695                   [-1, 10]               0\n",
      "         Linear-6696                   [-1, 10]             110\n",
      "        Softmax-6697                   [-1, 10]               0\n",
      "         Linear-6698                   [-1, 10]             110\n",
      "    BatchNorm1d-6699                   [-1, 10]              20\n",
      "           ReLU-6700                   [-1, 10]               0\n",
      "        Dropout-6701                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6702                   [-1, 10]               0\n",
      "         Linear-6703                   [-1, 10]             110\n",
      "    BatchNorm1d-6704                   [-1, 10]              20\n",
      "           ReLU-6705                   [-1, 10]               0\n",
      "        Dropout-6706                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6707                   [-1, 10]               0\n",
      "         Linear-6708                   [-1, 10]             110\n",
      "    BatchNorm1d-6709                   [-1, 10]              20\n",
      "           ReLU-6710                   [-1, 10]               0\n",
      "        Dropout-6711                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6712                   [-1, 10]               0\n",
      "         Linear-6713                   [-1, 10]             110\n",
      "    BatchNorm1d-6714                   [-1, 10]              20\n",
      "           ReLU-6715                   [-1, 10]               0\n",
      "        Dropout-6716                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6717                   [-1, 10]               0\n",
      "         Linear-6718                   [-1, 10]             110\n",
      "    BatchNorm1d-6719                   [-1, 10]              20\n",
      "           ReLU-6720                   [-1, 10]               0\n",
      "        Dropout-6721                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6722                   [-1, 10]               0\n",
      "         Linear-6723                   [-1, 10]             110\n",
      "        Softmax-6724                   [-1, 10]               0\n",
      "         Linear-6725                   [-1, 15]             165\n",
      "        Softmax-6726                   [-1, 15]               0\n",
      "         Linear-6727                   [-1, 10]             110\n",
      "    BatchNorm1d-6728                   [-1, 10]              20\n",
      "           ReLU-6729                   [-1, 10]               0\n",
      "        Dropout-6730                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6731                   [-1, 10]               0\n",
      "         Linear-6732                   [-1, 10]             110\n",
      "    BatchNorm1d-6733                   [-1, 10]              20\n",
      "           ReLU-6734                   [-1, 10]               0\n",
      "        Dropout-6735                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6736                   [-1, 10]               0\n",
      "         Linear-6737                   [-1, 10]             110\n",
      "    BatchNorm1d-6738                   [-1, 10]              20\n",
      "           ReLU-6739                   [-1, 10]               0\n",
      "        Dropout-6740                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6741                   [-1, 10]               0\n",
      "         Linear-6742                   [-1, 10]             110\n",
      "    BatchNorm1d-6743                   [-1, 10]              20\n",
      "           ReLU-6744                   [-1, 10]               0\n",
      "        Dropout-6745                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6746                   [-1, 10]               0\n",
      "         Linear-6747                   [-1, 10]             110\n",
      "    BatchNorm1d-6748                   [-1, 10]              20\n",
      "           ReLU-6749                   [-1, 10]               0\n",
      "        Dropout-6750                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6751                   [-1, 10]               0\n",
      "         Linear-6752                   [-1, 10]             110\n",
      "    BatchNorm1d-6753                   [-1, 10]              20\n",
      "           ReLU-6754                   [-1, 10]               0\n",
      "        Dropout-6755                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6756                   [-1, 10]               0\n",
      "         Linear-6757                   [-1, 10]             110\n",
      "    BatchNorm1d-6758                   [-1, 10]              20\n",
      "           ReLU-6759                   [-1, 10]               0\n",
      "        Dropout-6760                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6761                   [-1, 10]               0\n",
      "         Linear-6762                   [-1, 10]             110\n",
      "    BatchNorm1d-6763                   [-1, 10]              20\n",
      "           ReLU-6764                   [-1, 10]               0\n",
      "        Dropout-6765                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6766                   [-1, 10]               0\n",
      "         Linear-6767                   [-1, 10]             110\n",
      "    BatchNorm1d-6768                   [-1, 10]              20\n",
      "           ReLU-6769                   [-1, 10]               0\n",
      "        Dropout-6770                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6771                   [-1, 10]               0\n",
      "         Linear-6772                   [-1, 10]             110\n",
      "    BatchNorm1d-6773                   [-1, 10]              20\n",
      "           ReLU-6774                   [-1, 10]               0\n",
      "        Dropout-6775                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6776                   [-1, 10]               0\n",
      "         Linear-6777                   [-1, 10]             110\n",
      "        Softmax-6778                   [-1, 10]               0\n",
      "         Linear-6779                   [-1, 10]             110\n",
      "    BatchNorm1d-6780                   [-1, 10]              20\n",
      "           ReLU-6781                   [-1, 10]               0\n",
      "        Dropout-6782                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6783                   [-1, 10]               0\n",
      "         Linear-6784                   [-1, 10]             110\n",
      "    BatchNorm1d-6785                   [-1, 10]              20\n",
      "           ReLU-6786                   [-1, 10]               0\n",
      "        Dropout-6787                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6788                   [-1, 10]               0\n",
      "         Linear-6789                   [-1, 10]             110\n",
      "    BatchNorm1d-6790                   [-1, 10]              20\n",
      "           ReLU-6791                   [-1, 10]               0\n",
      "        Dropout-6792                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6793                   [-1, 10]               0\n",
      "         Linear-6794                   [-1, 10]             110\n",
      "    BatchNorm1d-6795                   [-1, 10]              20\n",
      "           ReLU-6796                   [-1, 10]               0\n",
      "        Dropout-6797                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6798                   [-1, 10]               0\n",
      "         Linear-6799                   [-1, 10]             110\n",
      "    BatchNorm1d-6800                   [-1, 10]              20\n",
      "           ReLU-6801                   [-1, 10]               0\n",
      "        Dropout-6802                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6803                   [-1, 10]               0\n",
      "         Linear-6804                   [-1, 10]             110\n",
      "        Softmax-6805                   [-1, 10]               0\n",
      "         Linear-6806                   [-1, 15]             165\n",
      "        Softmax-6807                   [-1, 15]               0\n",
      "         Linear-6808                   [-1, 10]             110\n",
      "    BatchNorm1d-6809                   [-1, 10]              20\n",
      "           ReLU-6810                   [-1, 10]               0\n",
      "        Dropout-6811                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6812                   [-1, 10]               0\n",
      "         Linear-6813                   [-1, 10]             110\n",
      "    BatchNorm1d-6814                   [-1, 10]              20\n",
      "           ReLU-6815                   [-1, 10]               0\n",
      "        Dropout-6816                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6817                   [-1, 10]               0\n",
      "         Linear-6818                   [-1, 10]             110\n",
      "    BatchNorm1d-6819                   [-1, 10]              20\n",
      "           ReLU-6820                   [-1, 10]               0\n",
      "        Dropout-6821                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6822                   [-1, 10]               0\n",
      "         Linear-6823                   [-1, 10]             110\n",
      "    BatchNorm1d-6824                   [-1, 10]              20\n",
      "           ReLU-6825                   [-1, 10]               0\n",
      "        Dropout-6826                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6827                   [-1, 10]               0\n",
      "         Linear-6828                   [-1, 10]             110\n",
      "    BatchNorm1d-6829                   [-1, 10]              20\n",
      "           ReLU-6830                   [-1, 10]               0\n",
      "        Dropout-6831                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6832                   [-1, 10]               0\n",
      "         Linear-6833                   [-1, 10]             110\n",
      "    BatchNorm1d-6834                   [-1, 10]              20\n",
      "           ReLU-6835                   [-1, 10]               0\n",
      "        Dropout-6836                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6837                   [-1, 10]               0\n",
      "         Linear-6838                   [-1, 10]             110\n",
      "    BatchNorm1d-6839                   [-1, 10]              20\n",
      "           ReLU-6840                   [-1, 10]               0\n",
      "        Dropout-6841                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6842                   [-1, 10]               0\n",
      "         Linear-6843                   [-1, 10]             110\n",
      "    BatchNorm1d-6844                   [-1, 10]              20\n",
      "           ReLU-6845                   [-1, 10]               0\n",
      "        Dropout-6846                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6847                   [-1, 10]               0\n",
      "         Linear-6848                   [-1, 10]             110\n",
      "    BatchNorm1d-6849                   [-1, 10]              20\n",
      "           ReLU-6850                   [-1, 10]               0\n",
      "        Dropout-6851                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6852                   [-1, 10]               0\n",
      "         Linear-6853                   [-1, 10]             110\n",
      "    BatchNorm1d-6854                   [-1, 10]              20\n",
      "           ReLU-6855                   [-1, 10]               0\n",
      "        Dropout-6856                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6857                   [-1, 10]               0\n",
      "         Linear-6858                   [-1, 10]             110\n",
      "        Softmax-6859                   [-1, 10]               0\n",
      "         Linear-6860                   [-1, 10]             110\n",
      "    BatchNorm1d-6861                   [-1, 10]              20\n",
      "           ReLU-6862                   [-1, 10]               0\n",
      "        Dropout-6863                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6864                   [-1, 10]               0\n",
      "         Linear-6865                   [-1, 10]             110\n",
      "    BatchNorm1d-6866                   [-1, 10]              20\n",
      "           ReLU-6867                   [-1, 10]               0\n",
      "        Dropout-6868                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6869                   [-1, 10]               0\n",
      "         Linear-6870                   [-1, 10]             110\n",
      "    BatchNorm1d-6871                   [-1, 10]              20\n",
      "           ReLU-6872                   [-1, 10]               0\n",
      "        Dropout-6873                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6874                   [-1, 10]               0\n",
      "         Linear-6875                   [-1, 10]             110\n",
      "    BatchNorm1d-6876                   [-1, 10]              20\n",
      "           ReLU-6877                   [-1, 10]               0\n",
      "        Dropout-6878                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6879                   [-1, 10]               0\n",
      "         Linear-6880                   [-1, 10]             110\n",
      "    BatchNorm1d-6881                   [-1, 10]              20\n",
      "           ReLU-6882                   [-1, 10]               0\n",
      "        Dropout-6883                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6884                   [-1, 10]               0\n",
      "         Linear-6885                   [-1, 10]             110\n",
      "        Softmax-6886                   [-1, 10]               0\n",
      "         Linear-6887                   [-1, 15]             165\n",
      "        Softmax-6888                   [-1, 15]               0\n",
      "         Linear-6889                   [-1, 10]             110\n",
      "    BatchNorm1d-6890                   [-1, 10]              20\n",
      "           ReLU-6891                   [-1, 10]               0\n",
      "        Dropout-6892                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6893                   [-1, 10]               0\n",
      "         Linear-6894                   [-1, 10]             110\n",
      "    BatchNorm1d-6895                   [-1, 10]              20\n",
      "           ReLU-6896                   [-1, 10]               0\n",
      "        Dropout-6897                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6898                   [-1, 10]               0\n",
      "         Linear-6899                   [-1, 10]             110\n",
      "    BatchNorm1d-6900                   [-1, 10]              20\n",
      "           ReLU-6901                   [-1, 10]               0\n",
      "        Dropout-6902                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6903                   [-1, 10]               0\n",
      "         Linear-6904                   [-1, 10]             110\n",
      "    BatchNorm1d-6905                   [-1, 10]              20\n",
      "           ReLU-6906                   [-1, 10]               0\n",
      "        Dropout-6907                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6908                   [-1, 10]               0\n",
      "         Linear-6909                   [-1, 10]             110\n",
      "    BatchNorm1d-6910                   [-1, 10]              20\n",
      "           ReLU-6911                   [-1, 10]               0\n",
      "        Dropout-6912                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6913                   [-1, 10]               0\n",
      "         Linear-6914                   [-1, 10]             110\n",
      "    BatchNorm1d-6915                   [-1, 10]              20\n",
      "           ReLU-6916                   [-1, 10]               0\n",
      "        Dropout-6917                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6918                   [-1, 10]               0\n",
      "         Linear-6919                   [-1, 10]             110\n",
      "    BatchNorm1d-6920                   [-1, 10]              20\n",
      "           ReLU-6921                   [-1, 10]               0\n",
      "        Dropout-6922                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6923                   [-1, 10]               0\n",
      "         Linear-6924                   [-1, 10]             110\n",
      "    BatchNorm1d-6925                   [-1, 10]              20\n",
      "           ReLU-6926                   [-1, 10]               0\n",
      "        Dropout-6927                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6928                   [-1, 10]               0\n",
      "         Linear-6929                   [-1, 10]             110\n",
      "    BatchNorm1d-6930                   [-1, 10]              20\n",
      "           ReLU-6931                   [-1, 10]               0\n",
      "        Dropout-6932                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6933                   [-1, 10]               0\n",
      "         Linear-6934                   [-1, 10]             110\n",
      "    BatchNorm1d-6935                   [-1, 10]              20\n",
      "           ReLU-6936                   [-1, 10]               0\n",
      "        Dropout-6937                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6938                   [-1, 10]               0\n",
      "         Linear-6939                   [-1, 10]             110\n",
      "        Softmax-6940                   [-1, 10]               0\n",
      "         Linear-6941                   [-1, 10]             110\n",
      "    BatchNorm1d-6942                   [-1, 10]              20\n",
      "           ReLU-6943                   [-1, 10]               0\n",
      "        Dropout-6944                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6945                   [-1, 10]               0\n",
      "         Linear-6946                   [-1, 10]             110\n",
      "    BatchNorm1d-6947                   [-1, 10]              20\n",
      "           ReLU-6948                   [-1, 10]               0\n",
      "        Dropout-6949                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6950                   [-1, 10]               0\n",
      "         Linear-6951                   [-1, 10]             110\n",
      "    BatchNorm1d-6952                   [-1, 10]              20\n",
      "           ReLU-6953                   [-1, 10]               0\n",
      "        Dropout-6954                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6955                   [-1, 10]               0\n",
      "         Linear-6956                   [-1, 10]             110\n",
      "    BatchNorm1d-6957                   [-1, 10]              20\n",
      "           ReLU-6958                   [-1, 10]               0\n",
      "        Dropout-6959                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6960                   [-1, 10]               0\n",
      "         Linear-6961                   [-1, 10]             110\n",
      "    BatchNorm1d-6962                   [-1, 10]              20\n",
      "           ReLU-6963                   [-1, 10]               0\n",
      "        Dropout-6964                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6965                   [-1, 10]               0\n",
      "         Linear-6966                   [-1, 10]             110\n",
      "        Softmax-6967                   [-1, 10]               0\n",
      "         Linear-6968                   [-1, 15]             165\n",
      "        Softmax-6969                   [-1, 15]               0\n",
      "         Linear-6970                   [-1, 10]             110\n",
      "    BatchNorm1d-6971                   [-1, 10]              20\n",
      "           ReLU-6972                   [-1, 10]               0\n",
      "        Dropout-6973                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6974                   [-1, 10]               0\n",
      "         Linear-6975                   [-1, 10]             110\n",
      "    BatchNorm1d-6976                   [-1, 10]              20\n",
      "           ReLU-6977                   [-1, 10]               0\n",
      "        Dropout-6978                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6979                   [-1, 10]               0\n",
      "         Linear-6980                   [-1, 10]             110\n",
      "    BatchNorm1d-6981                   [-1, 10]              20\n",
      "           ReLU-6982                   [-1, 10]               0\n",
      "        Dropout-6983                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6984                   [-1, 10]               0\n",
      "         Linear-6985                   [-1, 10]             110\n",
      "    BatchNorm1d-6986                   [-1, 10]              20\n",
      "           ReLU-6987                   [-1, 10]               0\n",
      "        Dropout-6988                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6989                   [-1, 10]               0\n",
      "         Linear-6990                   [-1, 10]             110\n",
      "    BatchNorm1d-6991                   [-1, 10]              20\n",
      "           ReLU-6992                   [-1, 10]               0\n",
      "        Dropout-6993                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6994                   [-1, 10]               0\n",
      "         Linear-6995                   [-1, 10]             110\n",
      "    BatchNorm1d-6996                   [-1, 10]              20\n",
      "           ReLU-6997                   [-1, 10]               0\n",
      "        Dropout-6998                   [-1, 10]               0\n",
      "MultiLayerPerceptron-6999                   [-1, 10]               0\n",
      "         Linear-7000                   [-1, 10]             110\n",
      "    BatchNorm1d-7001                   [-1, 10]              20\n",
      "           ReLU-7002                   [-1, 10]               0\n",
      "        Dropout-7003                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7004                   [-1, 10]               0\n",
      "         Linear-7005                   [-1, 10]             110\n",
      "    BatchNorm1d-7006                   [-1, 10]              20\n",
      "           ReLU-7007                   [-1, 10]               0\n",
      "        Dropout-7008                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7009                   [-1, 10]               0\n",
      "         Linear-7010                   [-1, 10]             110\n",
      "    BatchNorm1d-7011                   [-1, 10]              20\n",
      "           ReLU-7012                   [-1, 10]               0\n",
      "        Dropout-7013                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7014                   [-1, 10]               0\n",
      "         Linear-7015                   [-1, 10]             110\n",
      "    BatchNorm1d-7016                   [-1, 10]              20\n",
      "           ReLU-7017                   [-1, 10]               0\n",
      "        Dropout-7018                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7019                   [-1, 10]               0\n",
      "         Linear-7020                   [-1, 10]             110\n",
      "        Softmax-7021                   [-1, 10]               0\n",
      "         Linear-7022                   [-1, 10]             110\n",
      "    BatchNorm1d-7023                   [-1, 10]              20\n",
      "           ReLU-7024                   [-1, 10]               0\n",
      "        Dropout-7025                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7026                   [-1, 10]               0\n",
      "         Linear-7027                   [-1, 10]             110\n",
      "    BatchNorm1d-7028                   [-1, 10]              20\n",
      "           ReLU-7029                   [-1, 10]               0\n",
      "        Dropout-7030                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7031                   [-1, 10]               0\n",
      "         Linear-7032                   [-1, 10]             110\n",
      "    BatchNorm1d-7033                   [-1, 10]              20\n",
      "           ReLU-7034                   [-1, 10]               0\n",
      "        Dropout-7035                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7036                   [-1, 10]               0\n",
      "         Linear-7037                   [-1, 10]             110\n",
      "    BatchNorm1d-7038                   [-1, 10]              20\n",
      "           ReLU-7039                   [-1, 10]               0\n",
      "        Dropout-7040                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7041                   [-1, 10]               0\n",
      "         Linear-7042                   [-1, 10]             110\n",
      "    BatchNorm1d-7043                   [-1, 10]              20\n",
      "           ReLU-7044                   [-1, 10]               0\n",
      "        Dropout-7045                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7046                   [-1, 10]               0\n",
      "         Linear-7047                   [-1, 10]             110\n",
      "        Softmax-7048                   [-1, 10]               0\n",
      "         Linear-7049                   [-1, 15]             165\n",
      "        Softmax-7050                   [-1, 15]               0\n",
      "         Linear-7051                   [-1, 10]             110\n",
      "    BatchNorm1d-7052                   [-1, 10]              20\n",
      "           ReLU-7053                   [-1, 10]               0\n",
      "        Dropout-7054                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7055                   [-1, 10]               0\n",
      "         Linear-7056                   [-1, 10]             110\n",
      "    BatchNorm1d-7057                   [-1, 10]              20\n",
      "           ReLU-7058                   [-1, 10]               0\n",
      "        Dropout-7059                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7060                   [-1, 10]               0\n",
      "         Linear-7061                   [-1, 10]             110\n",
      "    BatchNorm1d-7062                   [-1, 10]              20\n",
      "           ReLU-7063                   [-1, 10]               0\n",
      "        Dropout-7064                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7065                   [-1, 10]               0\n",
      "         Linear-7066                   [-1, 10]             110\n",
      "    BatchNorm1d-7067                   [-1, 10]              20\n",
      "           ReLU-7068                   [-1, 10]               0\n",
      "        Dropout-7069                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7070                   [-1, 10]               0\n",
      "         Linear-7071                   [-1, 10]             110\n",
      "    BatchNorm1d-7072                   [-1, 10]              20\n",
      "           ReLU-7073                   [-1, 10]               0\n",
      "        Dropout-7074                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7075                   [-1, 10]               0\n",
      "         Linear-7076                   [-1, 10]             110\n",
      "    BatchNorm1d-7077                   [-1, 10]              20\n",
      "           ReLU-7078                   [-1, 10]               0\n",
      "        Dropout-7079                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7080                   [-1, 10]               0\n",
      "         Linear-7081                   [-1, 10]             110\n",
      "    BatchNorm1d-7082                   [-1, 10]              20\n",
      "           ReLU-7083                   [-1, 10]               0\n",
      "        Dropout-7084                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7085                   [-1, 10]               0\n",
      "         Linear-7086                   [-1, 10]             110\n",
      "    BatchNorm1d-7087                   [-1, 10]              20\n",
      "           ReLU-7088                   [-1, 10]               0\n",
      "        Dropout-7089                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7090                   [-1, 10]               0\n",
      "         Linear-7091                   [-1, 10]             110\n",
      "    BatchNorm1d-7092                   [-1, 10]              20\n",
      "           ReLU-7093                   [-1, 10]               0\n",
      "        Dropout-7094                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7095                   [-1, 10]               0\n",
      "         Linear-7096                   [-1, 10]             110\n",
      "    BatchNorm1d-7097                   [-1, 10]              20\n",
      "           ReLU-7098                   [-1, 10]               0\n",
      "        Dropout-7099                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7100                   [-1, 10]               0\n",
      "         Linear-7101                   [-1, 10]             110\n",
      "        Softmax-7102                   [-1, 10]               0\n",
      "         Linear-7103                   [-1, 10]             110\n",
      "    BatchNorm1d-7104                   [-1, 10]              20\n",
      "           ReLU-7105                   [-1, 10]               0\n",
      "        Dropout-7106                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7107                   [-1, 10]               0\n",
      "         Linear-7108                   [-1, 10]             110\n",
      "    BatchNorm1d-7109                   [-1, 10]              20\n",
      "           ReLU-7110                   [-1, 10]               0\n",
      "        Dropout-7111                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7112                   [-1, 10]               0\n",
      "         Linear-7113                   [-1, 10]             110\n",
      "    BatchNorm1d-7114                   [-1, 10]              20\n",
      "           ReLU-7115                   [-1, 10]               0\n",
      "        Dropout-7116                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7117                   [-1, 10]               0\n",
      "         Linear-7118                   [-1, 10]             110\n",
      "    BatchNorm1d-7119                   [-1, 10]              20\n",
      "           ReLU-7120                   [-1, 10]               0\n",
      "        Dropout-7121                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7122                   [-1, 10]               0\n",
      "         Linear-7123                   [-1, 10]             110\n",
      "    BatchNorm1d-7124                   [-1, 10]              20\n",
      "           ReLU-7125                   [-1, 10]               0\n",
      "        Dropout-7126                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7127                   [-1, 10]               0\n",
      "         Linear-7128                   [-1, 10]             110\n",
      "        Softmax-7129                   [-1, 10]               0\n",
      "         Linear-7130                   [-1, 15]             165\n",
      "        Softmax-7131                   [-1, 15]               0\n",
      "         Linear-7132                   [-1, 10]             110\n",
      "    BatchNorm1d-7133                   [-1, 10]              20\n",
      "           ReLU-7134                   [-1, 10]               0\n",
      "        Dropout-7135                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7136                   [-1, 10]               0\n",
      "         Linear-7137                   [-1, 10]             110\n",
      "    BatchNorm1d-7138                   [-1, 10]              20\n",
      "           ReLU-7139                   [-1, 10]               0\n",
      "        Dropout-7140                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7141                   [-1, 10]               0\n",
      "         Linear-7142                   [-1, 10]             110\n",
      "    BatchNorm1d-7143                   [-1, 10]              20\n",
      "           ReLU-7144                   [-1, 10]               0\n",
      "        Dropout-7145                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7146                   [-1, 10]               0\n",
      "         Linear-7147                   [-1, 10]             110\n",
      "    BatchNorm1d-7148                   [-1, 10]              20\n",
      "           ReLU-7149                   [-1, 10]               0\n",
      "        Dropout-7150                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7151                   [-1, 10]               0\n",
      "         Linear-7152                   [-1, 10]             110\n",
      "    BatchNorm1d-7153                   [-1, 10]              20\n",
      "           ReLU-7154                   [-1, 10]               0\n",
      "        Dropout-7155                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7156                   [-1, 10]               0\n",
      "         Linear-7157                   [-1, 10]             110\n",
      "    BatchNorm1d-7158                   [-1, 10]              20\n",
      "           ReLU-7159                   [-1, 10]               0\n",
      "        Dropout-7160                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7161                   [-1, 10]               0\n",
      "         Linear-7162                   [-1, 10]             110\n",
      "    BatchNorm1d-7163                   [-1, 10]              20\n",
      "           ReLU-7164                   [-1, 10]               0\n",
      "        Dropout-7165                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7166                   [-1, 10]               0\n",
      "         Linear-7167                   [-1, 10]             110\n",
      "    BatchNorm1d-7168                   [-1, 10]              20\n",
      "           ReLU-7169                   [-1, 10]               0\n",
      "        Dropout-7170                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7171                   [-1, 10]               0\n",
      "         Linear-7172                   [-1, 10]             110\n",
      "    BatchNorm1d-7173                   [-1, 10]              20\n",
      "           ReLU-7174                   [-1, 10]               0\n",
      "        Dropout-7175                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7176                   [-1, 10]               0\n",
      "         Linear-7177                   [-1, 10]             110\n",
      "    BatchNorm1d-7178                   [-1, 10]              20\n",
      "           ReLU-7179                   [-1, 10]               0\n",
      "        Dropout-7180                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7181                   [-1, 10]               0\n",
      "         Linear-7182                   [-1, 10]             110\n",
      "        Softmax-7183                   [-1, 10]               0\n",
      "         Linear-7184                   [-1, 10]             110\n",
      "    BatchNorm1d-7185                   [-1, 10]              20\n",
      "           ReLU-7186                   [-1, 10]               0\n",
      "        Dropout-7187                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7188                   [-1, 10]               0\n",
      "         Linear-7189                   [-1, 10]             110\n",
      "    BatchNorm1d-7190                   [-1, 10]              20\n",
      "           ReLU-7191                   [-1, 10]               0\n",
      "        Dropout-7192                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7193                   [-1, 10]               0\n",
      "         Linear-7194                   [-1, 10]             110\n",
      "    BatchNorm1d-7195                   [-1, 10]              20\n",
      "           ReLU-7196                   [-1, 10]               0\n",
      "        Dropout-7197                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7198                   [-1, 10]               0\n",
      "         Linear-7199                   [-1, 10]             110\n",
      "    BatchNorm1d-7200                   [-1, 10]              20\n",
      "           ReLU-7201                   [-1, 10]               0\n",
      "        Dropout-7202                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7203                   [-1, 10]               0\n",
      "         Linear-7204                   [-1, 10]             110\n",
      "    BatchNorm1d-7205                   [-1, 10]              20\n",
      "           ReLU-7206                   [-1, 10]               0\n",
      "        Dropout-7207                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7208                   [-1, 10]               0\n",
      "         Linear-7209                   [-1, 10]             110\n",
      "        Softmax-7210                   [-1, 10]               0\n",
      "         Linear-7211                   [-1, 15]             165\n",
      "        Softmax-7212                   [-1, 15]               0\n",
      "         Linear-7213                   [-1, 10]             110\n",
      "    BatchNorm1d-7214                   [-1, 10]              20\n",
      "           ReLU-7215                   [-1, 10]               0\n",
      "        Dropout-7216                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7217                   [-1, 10]               0\n",
      "         Linear-7218                   [-1, 10]             110\n",
      "    BatchNorm1d-7219                   [-1, 10]              20\n",
      "           ReLU-7220                   [-1, 10]               0\n",
      "        Dropout-7221                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7222                   [-1, 10]               0\n",
      "         Linear-7223                   [-1, 10]             110\n",
      "    BatchNorm1d-7224                   [-1, 10]              20\n",
      "           ReLU-7225                   [-1, 10]               0\n",
      "        Dropout-7226                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7227                   [-1, 10]               0\n",
      "         Linear-7228                   [-1, 10]             110\n",
      "    BatchNorm1d-7229                   [-1, 10]              20\n",
      "           ReLU-7230                   [-1, 10]               0\n",
      "        Dropout-7231                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7232                   [-1, 10]               0\n",
      "         Linear-7233                   [-1, 10]             110\n",
      "    BatchNorm1d-7234                   [-1, 10]              20\n",
      "           ReLU-7235                   [-1, 10]               0\n",
      "        Dropout-7236                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7237                   [-1, 10]               0\n",
      "         Linear-7238                   [-1, 10]             110\n",
      "    BatchNorm1d-7239                   [-1, 10]              20\n",
      "           ReLU-7240                   [-1, 10]               0\n",
      "        Dropout-7241                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7242                   [-1, 10]               0\n",
      "         Linear-7243                   [-1, 10]             110\n",
      "    BatchNorm1d-7244                   [-1, 10]              20\n",
      "           ReLU-7245                   [-1, 10]               0\n",
      "        Dropout-7246                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7247                   [-1, 10]               0\n",
      "         Linear-7248                   [-1, 10]             110\n",
      "    BatchNorm1d-7249                   [-1, 10]              20\n",
      "           ReLU-7250                   [-1, 10]               0\n",
      "        Dropout-7251                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7252                   [-1, 10]               0\n",
      "         Linear-7253                   [-1, 10]             110\n",
      "    BatchNorm1d-7254                   [-1, 10]              20\n",
      "           ReLU-7255                   [-1, 10]               0\n",
      "        Dropout-7256                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7257                   [-1, 10]               0\n",
      "         Linear-7258                   [-1, 10]             110\n",
      "    BatchNorm1d-7259                   [-1, 10]              20\n",
      "           ReLU-7260                   [-1, 10]               0\n",
      "        Dropout-7261                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7262                   [-1, 10]               0\n",
      "         Linear-7263                   [-1, 10]             110\n",
      "        Softmax-7264                   [-1, 10]               0\n",
      "         Linear-7265                   [-1, 10]             110\n",
      "    BatchNorm1d-7266                   [-1, 10]              20\n",
      "           ReLU-7267                   [-1, 10]               0\n",
      "        Dropout-7268                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7269                   [-1, 10]               0\n",
      "         Linear-7270                   [-1, 10]             110\n",
      "    BatchNorm1d-7271                   [-1, 10]              20\n",
      "           ReLU-7272                   [-1, 10]               0\n",
      "        Dropout-7273                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7274                   [-1, 10]               0\n",
      "         Linear-7275                   [-1, 10]             110\n",
      "    BatchNorm1d-7276                   [-1, 10]              20\n",
      "           ReLU-7277                   [-1, 10]               0\n",
      "        Dropout-7278                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7279                   [-1, 10]               0\n",
      "         Linear-7280                   [-1, 10]             110\n",
      "    BatchNorm1d-7281                   [-1, 10]              20\n",
      "           ReLU-7282                   [-1, 10]               0\n",
      "        Dropout-7283                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7284                   [-1, 10]               0\n",
      "         Linear-7285                   [-1, 10]             110\n",
      "    BatchNorm1d-7286                   [-1, 10]              20\n",
      "           ReLU-7287                   [-1, 10]               0\n",
      "        Dropout-7288                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7289                   [-1, 10]               0\n",
      "         Linear-7290                   [-1, 10]             110\n",
      "        Softmax-7291                   [-1, 10]               0\n",
      "         Linear-7292                   [-1, 15]             165\n",
      "        Softmax-7293                   [-1, 15]               0\n",
      "         Linear-7294                   [-1, 10]             110\n",
      "    BatchNorm1d-7295                   [-1, 10]              20\n",
      "           ReLU-7296                   [-1, 10]               0\n",
      "        Dropout-7297                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7298                   [-1, 10]               0\n",
      "         Linear-7299                   [-1, 10]             110\n",
      "    BatchNorm1d-7300                   [-1, 10]              20\n",
      "           ReLU-7301                   [-1, 10]               0\n",
      "        Dropout-7302                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7303                   [-1, 10]               0\n",
      "         Linear-7304                   [-1, 10]             110\n",
      "    BatchNorm1d-7305                   [-1, 10]              20\n",
      "           ReLU-7306                   [-1, 10]               0\n",
      "        Dropout-7307                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7308                   [-1, 10]               0\n",
      "         Linear-7309                   [-1, 10]             110\n",
      "    BatchNorm1d-7310                   [-1, 10]              20\n",
      "           ReLU-7311                   [-1, 10]               0\n",
      "        Dropout-7312                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7313                   [-1, 10]               0\n",
      "         Linear-7314                   [-1, 10]             110\n",
      "    BatchNorm1d-7315                   [-1, 10]              20\n",
      "           ReLU-7316                   [-1, 10]               0\n",
      "        Dropout-7317                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7318                   [-1, 10]               0\n",
      "         Linear-7319                   [-1, 10]             110\n",
      "    BatchNorm1d-7320                   [-1, 10]              20\n",
      "           ReLU-7321                   [-1, 10]               0\n",
      "        Dropout-7322                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7323                   [-1, 10]               0\n",
      "         Linear-7324                   [-1, 10]             110\n",
      "    BatchNorm1d-7325                   [-1, 10]              20\n",
      "           ReLU-7326                   [-1, 10]               0\n",
      "        Dropout-7327                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7328                   [-1, 10]               0\n",
      "         Linear-7329                   [-1, 10]             110\n",
      "    BatchNorm1d-7330                   [-1, 10]              20\n",
      "           ReLU-7331                   [-1, 10]               0\n",
      "        Dropout-7332                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7333                   [-1, 10]               0\n",
      "         Linear-7334                   [-1, 10]             110\n",
      "    BatchNorm1d-7335                   [-1, 10]              20\n",
      "           ReLU-7336                   [-1, 10]               0\n",
      "        Dropout-7337                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7338                   [-1, 10]               0\n",
      "         Linear-7339                   [-1, 10]             110\n",
      "    BatchNorm1d-7340                   [-1, 10]              20\n",
      "           ReLU-7341                   [-1, 10]               0\n",
      "        Dropout-7342                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7343                   [-1, 10]               0\n",
      "         Linear-7344                   [-1, 10]             110\n",
      "        Softmax-7345                   [-1, 10]               0\n",
      "         Linear-7346                   [-1, 10]             110\n",
      "    BatchNorm1d-7347                   [-1, 10]              20\n",
      "           ReLU-7348                   [-1, 10]               0\n",
      "        Dropout-7349                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7350                   [-1, 10]               0\n",
      "         Linear-7351                   [-1, 10]             110\n",
      "    BatchNorm1d-7352                   [-1, 10]              20\n",
      "           ReLU-7353                   [-1, 10]               0\n",
      "        Dropout-7354                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7355                   [-1, 10]               0\n",
      "         Linear-7356                   [-1, 10]             110\n",
      "    BatchNorm1d-7357                   [-1, 10]              20\n",
      "           ReLU-7358                   [-1, 10]               0\n",
      "        Dropout-7359                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7360                   [-1, 10]               0\n",
      "         Linear-7361                   [-1, 10]             110\n",
      "    BatchNorm1d-7362                   [-1, 10]              20\n",
      "           ReLU-7363                   [-1, 10]               0\n",
      "        Dropout-7364                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7365                   [-1, 10]               0\n",
      "         Linear-7366                   [-1, 10]             110\n",
      "    BatchNorm1d-7367                   [-1, 10]              20\n",
      "           ReLU-7368                   [-1, 10]               0\n",
      "        Dropout-7369                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7370                   [-1, 10]               0\n",
      "         Linear-7371                   [-1, 10]             110\n",
      "        Softmax-7372                   [-1, 10]               0\n",
      "         Linear-7373                   [-1, 15]             165\n",
      "        Softmax-7374                   [-1, 15]               0\n",
      "         Linear-7375                   [-1, 10]             110\n",
      "    BatchNorm1d-7376                   [-1, 10]              20\n",
      "           ReLU-7377                   [-1, 10]               0\n",
      "        Dropout-7378                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7379                   [-1, 10]               0\n",
      "         Linear-7380                   [-1, 10]             110\n",
      "    BatchNorm1d-7381                   [-1, 10]              20\n",
      "           ReLU-7382                   [-1, 10]               0\n",
      "        Dropout-7383                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7384                   [-1, 10]               0\n",
      "         Linear-7385                   [-1, 10]             110\n",
      "    BatchNorm1d-7386                   [-1, 10]              20\n",
      "           ReLU-7387                   [-1, 10]               0\n",
      "        Dropout-7388                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7389                   [-1, 10]               0\n",
      "         Linear-7390                   [-1, 10]             110\n",
      "    BatchNorm1d-7391                   [-1, 10]              20\n",
      "           ReLU-7392                   [-1, 10]               0\n",
      "        Dropout-7393                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7394                   [-1, 10]               0\n",
      "         Linear-7395                   [-1, 10]             110\n",
      "    BatchNorm1d-7396                   [-1, 10]              20\n",
      "           ReLU-7397                   [-1, 10]               0\n",
      "        Dropout-7398                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7399                   [-1, 10]               0\n",
      "         Linear-7400                   [-1, 10]             110\n",
      "    BatchNorm1d-7401                   [-1, 10]              20\n",
      "           ReLU-7402                   [-1, 10]               0\n",
      "        Dropout-7403                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7404                   [-1, 10]               0\n",
      "         Linear-7405                   [-1, 10]             110\n",
      "    BatchNorm1d-7406                   [-1, 10]              20\n",
      "           ReLU-7407                   [-1, 10]               0\n",
      "        Dropout-7408                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7409                   [-1, 10]               0\n",
      "         Linear-7410                   [-1, 10]             110\n",
      "    BatchNorm1d-7411                   [-1, 10]              20\n",
      "           ReLU-7412                   [-1, 10]               0\n",
      "        Dropout-7413                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7414                   [-1, 10]               0\n",
      "         Linear-7415                   [-1, 10]             110\n",
      "    BatchNorm1d-7416                   [-1, 10]              20\n",
      "           ReLU-7417                   [-1, 10]               0\n",
      "        Dropout-7418                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7419                   [-1, 10]               0\n",
      "         Linear-7420                   [-1, 10]             110\n",
      "    BatchNorm1d-7421                   [-1, 10]              20\n",
      "           ReLU-7422                   [-1, 10]               0\n",
      "        Dropout-7423                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7424                   [-1, 10]               0\n",
      "         Linear-7425                   [-1, 10]             110\n",
      "        Softmax-7426                   [-1, 10]               0\n",
      "         Linear-7427                   [-1, 10]             110\n",
      "    BatchNorm1d-7428                   [-1, 10]              20\n",
      "           ReLU-7429                   [-1, 10]               0\n",
      "        Dropout-7430                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7431                   [-1, 10]               0\n",
      "         Linear-7432                   [-1, 10]             110\n",
      "    BatchNorm1d-7433                   [-1, 10]              20\n",
      "           ReLU-7434                   [-1, 10]               0\n",
      "        Dropout-7435                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7436                   [-1, 10]               0\n",
      "         Linear-7437                   [-1, 10]             110\n",
      "    BatchNorm1d-7438                   [-1, 10]              20\n",
      "           ReLU-7439                   [-1, 10]               0\n",
      "        Dropout-7440                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7441                   [-1, 10]               0\n",
      "         Linear-7442                   [-1, 10]             110\n",
      "    BatchNorm1d-7443                   [-1, 10]              20\n",
      "           ReLU-7444                   [-1, 10]               0\n",
      "        Dropout-7445                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7446                   [-1, 10]               0\n",
      "         Linear-7447                   [-1, 10]             110\n",
      "    BatchNorm1d-7448                   [-1, 10]              20\n",
      "           ReLU-7449                   [-1, 10]               0\n",
      "        Dropout-7450                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7451                   [-1, 10]               0\n",
      "         Linear-7452                   [-1, 10]             110\n",
      "        Softmax-7453                   [-1, 10]               0\n",
      "         Linear-7454                   [-1, 15]             165\n",
      "        Softmax-7455                   [-1, 15]               0\n",
      "         Linear-7456                   [-1, 10]             110\n",
      "    BatchNorm1d-7457                   [-1, 10]              20\n",
      "           ReLU-7458                   [-1, 10]               0\n",
      "        Dropout-7459                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7460                   [-1, 10]               0\n",
      "         Linear-7461                   [-1, 10]             110\n",
      "    BatchNorm1d-7462                   [-1, 10]              20\n",
      "           ReLU-7463                   [-1, 10]               0\n",
      "        Dropout-7464                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7465                   [-1, 10]               0\n",
      "         Linear-7466                   [-1, 10]             110\n",
      "    BatchNorm1d-7467                   [-1, 10]              20\n",
      "           ReLU-7468                   [-1, 10]               0\n",
      "        Dropout-7469                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7470                   [-1, 10]               0\n",
      "         Linear-7471                   [-1, 10]             110\n",
      "    BatchNorm1d-7472                   [-1, 10]              20\n",
      "           ReLU-7473                   [-1, 10]               0\n",
      "        Dropout-7474                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7475                   [-1, 10]               0\n",
      "         Linear-7476                   [-1, 10]             110\n",
      "    BatchNorm1d-7477                   [-1, 10]              20\n",
      "           ReLU-7478                   [-1, 10]               0\n",
      "        Dropout-7479                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7480                   [-1, 10]               0\n",
      "         Linear-7481                   [-1, 10]             110\n",
      "    BatchNorm1d-7482                   [-1, 10]              20\n",
      "           ReLU-7483                   [-1, 10]               0\n",
      "        Dropout-7484                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7485                   [-1, 10]               0\n",
      "         Linear-7486                   [-1, 10]             110\n",
      "    BatchNorm1d-7487                   [-1, 10]              20\n",
      "           ReLU-7488                   [-1, 10]               0\n",
      "        Dropout-7489                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7490                   [-1, 10]               0\n",
      "         Linear-7491                   [-1, 10]             110\n",
      "    BatchNorm1d-7492                   [-1, 10]              20\n",
      "           ReLU-7493                   [-1, 10]               0\n",
      "        Dropout-7494                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7495                   [-1, 10]               0\n",
      "         Linear-7496                   [-1, 10]             110\n",
      "    BatchNorm1d-7497                   [-1, 10]              20\n",
      "           ReLU-7498                   [-1, 10]               0\n",
      "        Dropout-7499                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7500                   [-1, 10]               0\n",
      "         Linear-7501                   [-1, 10]             110\n",
      "    BatchNorm1d-7502                   [-1, 10]              20\n",
      "           ReLU-7503                   [-1, 10]               0\n",
      "        Dropout-7504                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7505                   [-1, 10]               0\n",
      "         Linear-7506                   [-1, 10]             110\n",
      "        Softmax-7507                   [-1, 10]               0\n",
      "         Linear-7508                   [-1, 10]             110\n",
      "    BatchNorm1d-7509                   [-1, 10]              20\n",
      "           ReLU-7510                   [-1, 10]               0\n",
      "        Dropout-7511                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7512                   [-1, 10]               0\n",
      "         Linear-7513                   [-1, 10]             110\n",
      "    BatchNorm1d-7514                   [-1, 10]              20\n",
      "           ReLU-7515                   [-1, 10]               0\n",
      "        Dropout-7516                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7517                   [-1, 10]               0\n",
      "         Linear-7518                   [-1, 10]             110\n",
      "    BatchNorm1d-7519                   [-1, 10]              20\n",
      "           ReLU-7520                   [-1, 10]               0\n",
      "        Dropout-7521                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7522                   [-1, 10]               0\n",
      "         Linear-7523                   [-1, 10]             110\n",
      "    BatchNorm1d-7524                   [-1, 10]              20\n",
      "           ReLU-7525                   [-1, 10]               0\n",
      "        Dropout-7526                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7527                   [-1, 10]               0\n",
      "         Linear-7528                   [-1, 10]             110\n",
      "    BatchNorm1d-7529                   [-1, 10]              20\n",
      "           ReLU-7530                   [-1, 10]               0\n",
      "        Dropout-7531                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7532                   [-1, 10]               0\n",
      "         Linear-7533                   [-1, 10]             110\n",
      "        Softmax-7534                   [-1, 10]               0\n",
      "         Linear-7535                   [-1, 15]             165\n",
      "        Softmax-7536                   [-1, 15]               0\n",
      "         Linear-7537                   [-1, 10]             110\n",
      "    BatchNorm1d-7538                   [-1, 10]              20\n",
      "           ReLU-7539                   [-1, 10]               0\n",
      "        Dropout-7540                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7541                   [-1, 10]               0\n",
      "         Linear-7542                   [-1, 10]             110\n",
      "    BatchNorm1d-7543                   [-1, 10]              20\n",
      "           ReLU-7544                   [-1, 10]               0\n",
      "        Dropout-7545                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7546                   [-1, 10]               0\n",
      "         Linear-7547                   [-1, 10]             110\n",
      "    BatchNorm1d-7548                   [-1, 10]              20\n",
      "           ReLU-7549                   [-1, 10]               0\n",
      "        Dropout-7550                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7551                   [-1, 10]               0\n",
      "         Linear-7552                   [-1, 10]             110\n",
      "    BatchNorm1d-7553                   [-1, 10]              20\n",
      "           ReLU-7554                   [-1, 10]               0\n",
      "        Dropout-7555                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7556                   [-1, 10]               0\n",
      "         Linear-7557                   [-1, 10]             110\n",
      "    BatchNorm1d-7558                   [-1, 10]              20\n",
      "           ReLU-7559                   [-1, 10]               0\n",
      "        Dropout-7560                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7561                   [-1, 10]               0\n",
      "         Linear-7562                   [-1, 10]             110\n",
      "    BatchNorm1d-7563                   [-1, 10]              20\n",
      "           ReLU-7564                   [-1, 10]               0\n",
      "        Dropout-7565                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7566                   [-1, 10]               0\n",
      "         Linear-7567                   [-1, 10]             110\n",
      "    BatchNorm1d-7568                   [-1, 10]              20\n",
      "           ReLU-7569                   [-1, 10]               0\n",
      "        Dropout-7570                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7571                   [-1, 10]               0\n",
      "         Linear-7572                   [-1, 10]             110\n",
      "    BatchNorm1d-7573                   [-1, 10]              20\n",
      "           ReLU-7574                   [-1, 10]               0\n",
      "        Dropout-7575                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7576                   [-1, 10]               0\n",
      "         Linear-7577                   [-1, 10]             110\n",
      "    BatchNorm1d-7578                   [-1, 10]              20\n",
      "           ReLU-7579                   [-1, 10]               0\n",
      "        Dropout-7580                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7581                   [-1, 10]               0\n",
      "         Linear-7582                   [-1, 10]             110\n",
      "    BatchNorm1d-7583                   [-1, 10]              20\n",
      "           ReLU-7584                   [-1, 10]               0\n",
      "        Dropout-7585                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7586                   [-1, 10]               0\n",
      "         Linear-7587                   [-1, 10]             110\n",
      "        Softmax-7588                   [-1, 10]               0\n",
      "         Linear-7589                   [-1, 10]             110\n",
      "    BatchNorm1d-7590                   [-1, 10]              20\n",
      "           ReLU-7591                   [-1, 10]               0\n",
      "        Dropout-7592                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7593                   [-1, 10]               0\n",
      "         Linear-7594                   [-1, 10]             110\n",
      "    BatchNorm1d-7595                   [-1, 10]              20\n",
      "           ReLU-7596                   [-1, 10]               0\n",
      "        Dropout-7597                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7598                   [-1, 10]               0\n",
      "         Linear-7599                   [-1, 10]             110\n",
      "    BatchNorm1d-7600                   [-1, 10]              20\n",
      "           ReLU-7601                   [-1, 10]               0\n",
      "        Dropout-7602                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7603                   [-1, 10]               0\n",
      "         Linear-7604                   [-1, 10]             110\n",
      "    BatchNorm1d-7605                   [-1, 10]              20\n",
      "           ReLU-7606                   [-1, 10]               0\n",
      "        Dropout-7607                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7608                   [-1, 10]               0\n",
      "         Linear-7609                   [-1, 10]             110\n",
      "    BatchNorm1d-7610                   [-1, 10]              20\n",
      "           ReLU-7611                   [-1, 10]               0\n",
      "        Dropout-7612                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7613                   [-1, 10]               0\n",
      "         Linear-7614                   [-1, 10]             110\n",
      "        Softmax-7615                   [-1, 10]               0\n",
      "         Linear-7616                   [-1, 15]             165\n",
      "        Softmax-7617                   [-1, 15]               0\n",
      "         Linear-7618                   [-1, 10]             110\n",
      "    BatchNorm1d-7619                   [-1, 10]              20\n",
      "           ReLU-7620                   [-1, 10]               0\n",
      "        Dropout-7621                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7622                   [-1, 10]               0\n",
      "         Linear-7623                   [-1, 10]             110\n",
      "    BatchNorm1d-7624                   [-1, 10]              20\n",
      "           ReLU-7625                   [-1, 10]               0\n",
      "        Dropout-7626                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7627                   [-1, 10]               0\n",
      "         Linear-7628                   [-1, 10]             110\n",
      "    BatchNorm1d-7629                   [-1, 10]              20\n",
      "           ReLU-7630                   [-1, 10]               0\n",
      "        Dropout-7631                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7632                   [-1, 10]               0\n",
      "         Linear-7633                   [-1, 10]             110\n",
      "    BatchNorm1d-7634                   [-1, 10]              20\n",
      "           ReLU-7635                   [-1, 10]               0\n",
      "        Dropout-7636                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7637                   [-1, 10]               0\n",
      "         Linear-7638                   [-1, 10]             110\n",
      "    BatchNorm1d-7639                   [-1, 10]              20\n",
      "           ReLU-7640                   [-1, 10]               0\n",
      "        Dropout-7641                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7642                   [-1, 10]               0\n",
      "         Linear-7643                   [-1, 10]             110\n",
      "    BatchNorm1d-7644                   [-1, 10]              20\n",
      "           ReLU-7645                   [-1, 10]               0\n",
      "        Dropout-7646                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7647                   [-1, 10]               0\n",
      "         Linear-7648                   [-1, 10]             110\n",
      "    BatchNorm1d-7649                   [-1, 10]              20\n",
      "           ReLU-7650                   [-1, 10]               0\n",
      "        Dropout-7651                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7652                   [-1, 10]               0\n",
      "         Linear-7653                   [-1, 10]             110\n",
      "    BatchNorm1d-7654                   [-1, 10]              20\n",
      "           ReLU-7655                   [-1, 10]               0\n",
      "        Dropout-7656                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7657                   [-1, 10]               0\n",
      "         Linear-7658                   [-1, 10]             110\n",
      "    BatchNorm1d-7659                   [-1, 10]              20\n",
      "           ReLU-7660                   [-1, 10]               0\n",
      "        Dropout-7661                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7662                   [-1, 10]               0\n",
      "         Linear-7663                   [-1, 10]             110\n",
      "    BatchNorm1d-7664                   [-1, 10]              20\n",
      "           ReLU-7665                   [-1, 10]               0\n",
      "        Dropout-7666                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7667                   [-1, 10]               0\n",
      "         Linear-7668                   [-1, 10]             110\n",
      "        Softmax-7669                   [-1, 10]               0\n",
      "         Linear-7670                   [-1, 10]             110\n",
      "    BatchNorm1d-7671                   [-1, 10]              20\n",
      "           ReLU-7672                   [-1, 10]               0\n",
      "        Dropout-7673                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7674                   [-1, 10]               0\n",
      "         Linear-7675                   [-1, 10]             110\n",
      "    BatchNorm1d-7676                   [-1, 10]              20\n",
      "           ReLU-7677                   [-1, 10]               0\n",
      "        Dropout-7678                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7679                   [-1, 10]               0\n",
      "         Linear-7680                   [-1, 10]             110\n",
      "    BatchNorm1d-7681                   [-1, 10]              20\n",
      "           ReLU-7682                   [-1, 10]               0\n",
      "        Dropout-7683                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7684                   [-1, 10]               0\n",
      "         Linear-7685                   [-1, 10]             110\n",
      "    BatchNorm1d-7686                   [-1, 10]              20\n",
      "           ReLU-7687                   [-1, 10]               0\n",
      "        Dropout-7688                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7689                   [-1, 10]               0\n",
      "         Linear-7690                   [-1, 10]             110\n",
      "    BatchNorm1d-7691                   [-1, 10]              20\n",
      "           ReLU-7692                   [-1, 10]               0\n",
      "        Dropout-7693                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7694                   [-1, 10]               0\n",
      "         Linear-7695                   [-1, 10]             110\n",
      "        Softmax-7696                   [-1, 10]               0\n",
      "         Linear-7697                   [-1, 15]             165\n",
      "        Softmax-7698                   [-1, 15]               0\n",
      "         Linear-7699                   [-1, 10]             110\n",
      "    BatchNorm1d-7700                   [-1, 10]              20\n",
      "           ReLU-7701                   [-1, 10]               0\n",
      "        Dropout-7702                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7703                   [-1, 10]               0\n",
      "         Linear-7704                   [-1, 10]             110\n",
      "    BatchNorm1d-7705                   [-1, 10]              20\n",
      "           ReLU-7706                   [-1, 10]               0\n",
      "        Dropout-7707                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7708                   [-1, 10]               0\n",
      "         Linear-7709                   [-1, 10]             110\n",
      "    BatchNorm1d-7710                   [-1, 10]              20\n",
      "           ReLU-7711                   [-1, 10]               0\n",
      "        Dropout-7712                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7713                   [-1, 10]               0\n",
      "         Linear-7714                   [-1, 10]             110\n",
      "    BatchNorm1d-7715                   [-1, 10]              20\n",
      "           ReLU-7716                   [-1, 10]               0\n",
      "        Dropout-7717                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7718                   [-1, 10]               0\n",
      "         Linear-7719                   [-1, 10]             110\n",
      "    BatchNorm1d-7720                   [-1, 10]              20\n",
      "           ReLU-7721                   [-1, 10]               0\n",
      "        Dropout-7722                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7723                   [-1, 10]               0\n",
      "         Linear-7724                   [-1, 10]             110\n",
      "    BatchNorm1d-7725                   [-1, 10]              20\n",
      "           ReLU-7726                   [-1, 10]               0\n",
      "        Dropout-7727                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7728                   [-1, 10]               0\n",
      "         Linear-7729                   [-1, 10]             110\n",
      "    BatchNorm1d-7730                   [-1, 10]              20\n",
      "           ReLU-7731                   [-1, 10]               0\n",
      "        Dropout-7732                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7733                   [-1, 10]               0\n",
      "         Linear-7734                   [-1, 10]             110\n",
      "    BatchNorm1d-7735                   [-1, 10]              20\n",
      "           ReLU-7736                   [-1, 10]               0\n",
      "        Dropout-7737                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7738                   [-1, 10]               0\n",
      "         Linear-7739                   [-1, 10]             110\n",
      "    BatchNorm1d-7740                   [-1, 10]              20\n",
      "           ReLU-7741                   [-1, 10]               0\n",
      "        Dropout-7742                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7743                   [-1, 10]               0\n",
      "         Linear-7744                   [-1, 10]             110\n",
      "    BatchNorm1d-7745                   [-1, 10]              20\n",
      "           ReLU-7746                   [-1, 10]               0\n",
      "        Dropout-7747                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7748                   [-1, 10]               0\n",
      "         Linear-7749                   [-1, 10]             110\n",
      "        Softmax-7750                   [-1, 10]               0\n",
      "         Linear-7751                   [-1, 10]             110\n",
      "    BatchNorm1d-7752                   [-1, 10]              20\n",
      "           ReLU-7753                   [-1, 10]               0\n",
      "        Dropout-7754                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7755                   [-1, 10]               0\n",
      "         Linear-7756                   [-1, 10]             110\n",
      "    BatchNorm1d-7757                   [-1, 10]              20\n",
      "           ReLU-7758                   [-1, 10]               0\n",
      "        Dropout-7759                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7760                   [-1, 10]               0\n",
      "         Linear-7761                   [-1, 10]             110\n",
      "    BatchNorm1d-7762                   [-1, 10]              20\n",
      "           ReLU-7763                   [-1, 10]               0\n",
      "        Dropout-7764                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7765                   [-1, 10]               0\n",
      "         Linear-7766                   [-1, 10]             110\n",
      "    BatchNorm1d-7767                   [-1, 10]              20\n",
      "           ReLU-7768                   [-1, 10]               0\n",
      "        Dropout-7769                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7770                   [-1, 10]               0\n",
      "         Linear-7771                   [-1, 10]             110\n",
      "    BatchNorm1d-7772                   [-1, 10]              20\n",
      "           ReLU-7773                   [-1, 10]               0\n",
      "        Dropout-7774                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7775                   [-1, 10]               0\n",
      "         Linear-7776                   [-1, 10]             110\n",
      "        Softmax-7777                   [-1, 10]               0\n",
      "         Linear-7778                   [-1, 15]             165\n",
      "        Softmax-7779                   [-1, 15]               0\n",
      "         Linear-7780                   [-1, 10]             110\n",
      "    BatchNorm1d-7781                   [-1, 10]              20\n",
      "           ReLU-7782                   [-1, 10]               0\n",
      "        Dropout-7783                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7784                   [-1, 10]               0\n",
      "         Linear-7785                   [-1, 10]             110\n",
      "    BatchNorm1d-7786                   [-1, 10]              20\n",
      "           ReLU-7787                   [-1, 10]               0\n",
      "        Dropout-7788                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7789                   [-1, 10]               0\n",
      "         Linear-7790                   [-1, 10]             110\n",
      "    BatchNorm1d-7791                   [-1, 10]              20\n",
      "           ReLU-7792                   [-1, 10]               0\n",
      "        Dropout-7793                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7794                   [-1, 10]               0\n",
      "         Linear-7795                   [-1, 10]             110\n",
      "    BatchNorm1d-7796                   [-1, 10]              20\n",
      "           ReLU-7797                   [-1, 10]               0\n",
      "        Dropout-7798                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7799                   [-1, 10]               0\n",
      "         Linear-7800                   [-1, 10]             110\n",
      "    BatchNorm1d-7801                   [-1, 10]              20\n",
      "           ReLU-7802                   [-1, 10]               0\n",
      "        Dropout-7803                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7804                   [-1, 10]               0\n",
      "         Linear-7805                   [-1, 10]             110\n",
      "    BatchNorm1d-7806                   [-1, 10]              20\n",
      "           ReLU-7807                   [-1, 10]               0\n",
      "        Dropout-7808                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7809                   [-1, 10]               0\n",
      "         Linear-7810                   [-1, 10]             110\n",
      "    BatchNorm1d-7811                   [-1, 10]              20\n",
      "           ReLU-7812                   [-1, 10]               0\n",
      "        Dropout-7813                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7814                   [-1, 10]               0\n",
      "         Linear-7815                   [-1, 10]             110\n",
      "    BatchNorm1d-7816                   [-1, 10]              20\n",
      "           ReLU-7817                   [-1, 10]               0\n",
      "        Dropout-7818                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7819                   [-1, 10]               0\n",
      "         Linear-7820                   [-1, 10]             110\n",
      "    BatchNorm1d-7821                   [-1, 10]              20\n",
      "           ReLU-7822                   [-1, 10]               0\n",
      "        Dropout-7823                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7824                   [-1, 10]               0\n",
      "         Linear-7825                   [-1, 10]             110\n",
      "    BatchNorm1d-7826                   [-1, 10]              20\n",
      "           ReLU-7827                   [-1, 10]               0\n",
      "        Dropout-7828                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7829                   [-1, 10]               0\n",
      "         Linear-7830                   [-1, 10]             110\n",
      "        Softmax-7831                   [-1, 10]               0\n",
      "         Linear-7832                   [-1, 10]             110\n",
      "    BatchNorm1d-7833                   [-1, 10]              20\n",
      "           ReLU-7834                   [-1, 10]               0\n",
      "        Dropout-7835                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7836                   [-1, 10]               0\n",
      "         Linear-7837                   [-1, 10]             110\n",
      "    BatchNorm1d-7838                   [-1, 10]              20\n",
      "           ReLU-7839                   [-1, 10]               0\n",
      "        Dropout-7840                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7841                   [-1, 10]               0\n",
      "         Linear-7842                   [-1, 10]             110\n",
      "    BatchNorm1d-7843                   [-1, 10]              20\n",
      "           ReLU-7844                   [-1, 10]               0\n",
      "        Dropout-7845                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7846                   [-1, 10]               0\n",
      "         Linear-7847                   [-1, 10]             110\n",
      "    BatchNorm1d-7848                   [-1, 10]              20\n",
      "           ReLU-7849                   [-1, 10]               0\n",
      "        Dropout-7850                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7851                   [-1, 10]               0\n",
      "         Linear-7852                   [-1, 10]             110\n",
      "    BatchNorm1d-7853                   [-1, 10]              20\n",
      "           ReLU-7854                   [-1, 10]               0\n",
      "        Dropout-7855                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7856                   [-1, 10]               0\n",
      "         Linear-7857                   [-1, 10]             110\n",
      "        Softmax-7858                   [-1, 10]               0\n",
      "         Linear-7859                   [-1, 15]             165\n",
      "        Softmax-7860                   [-1, 15]               0\n",
      "         Linear-7861                   [-1, 10]             110\n",
      "    BatchNorm1d-7862                   [-1, 10]              20\n",
      "           ReLU-7863                   [-1, 10]               0\n",
      "        Dropout-7864                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7865                   [-1, 10]               0\n",
      "         Linear-7866                   [-1, 10]             110\n",
      "    BatchNorm1d-7867                   [-1, 10]              20\n",
      "           ReLU-7868                   [-1, 10]               0\n",
      "        Dropout-7869                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7870                   [-1, 10]               0\n",
      "         Linear-7871                   [-1, 10]             110\n",
      "    BatchNorm1d-7872                   [-1, 10]              20\n",
      "           ReLU-7873                   [-1, 10]               0\n",
      "        Dropout-7874                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7875                   [-1, 10]               0\n",
      "         Linear-7876                   [-1, 10]             110\n",
      "    BatchNorm1d-7877                   [-1, 10]              20\n",
      "           ReLU-7878                   [-1, 10]               0\n",
      "        Dropout-7879                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7880                   [-1, 10]               0\n",
      "         Linear-7881                   [-1, 10]             110\n",
      "    BatchNorm1d-7882                   [-1, 10]              20\n",
      "           ReLU-7883                   [-1, 10]               0\n",
      "        Dropout-7884                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7885                   [-1, 10]               0\n",
      "         Linear-7886                   [-1, 10]             110\n",
      "    BatchNorm1d-7887                   [-1, 10]              20\n",
      "           ReLU-7888                   [-1, 10]               0\n",
      "        Dropout-7889                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7890                   [-1, 10]               0\n",
      "         Linear-7891                   [-1, 10]             110\n",
      "    BatchNorm1d-7892                   [-1, 10]              20\n",
      "           ReLU-7893                   [-1, 10]               0\n",
      "        Dropout-7894                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7895                   [-1, 10]               0\n",
      "         Linear-7896                   [-1, 10]             110\n",
      "    BatchNorm1d-7897                   [-1, 10]              20\n",
      "           ReLU-7898                   [-1, 10]               0\n",
      "        Dropout-7899                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7900                   [-1, 10]               0\n",
      "         Linear-7901                   [-1, 10]             110\n",
      "    BatchNorm1d-7902                   [-1, 10]              20\n",
      "           ReLU-7903                   [-1, 10]               0\n",
      "        Dropout-7904                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7905                   [-1, 10]               0\n",
      "         Linear-7906                   [-1, 10]             110\n",
      "    BatchNorm1d-7907                   [-1, 10]              20\n",
      "           ReLU-7908                   [-1, 10]               0\n",
      "        Dropout-7909                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7910                   [-1, 10]               0\n",
      "         Linear-7911                   [-1, 10]             110\n",
      "        Softmax-7912                   [-1, 10]               0\n",
      "         Linear-7913                   [-1, 10]             110\n",
      "    BatchNorm1d-7914                   [-1, 10]              20\n",
      "           ReLU-7915                   [-1, 10]               0\n",
      "        Dropout-7916                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7917                   [-1, 10]               0\n",
      "         Linear-7918                   [-1, 10]             110\n",
      "    BatchNorm1d-7919                   [-1, 10]              20\n",
      "           ReLU-7920                   [-1, 10]               0\n",
      "        Dropout-7921                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7922                   [-1, 10]               0\n",
      "         Linear-7923                   [-1, 10]             110\n",
      "    BatchNorm1d-7924                   [-1, 10]              20\n",
      "           ReLU-7925                   [-1, 10]               0\n",
      "        Dropout-7926                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7927                   [-1, 10]               0\n",
      "         Linear-7928                   [-1, 10]             110\n",
      "    BatchNorm1d-7929                   [-1, 10]              20\n",
      "           ReLU-7930                   [-1, 10]               0\n",
      "        Dropout-7931                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7932                   [-1, 10]               0\n",
      "         Linear-7933                   [-1, 10]             110\n",
      "    BatchNorm1d-7934                   [-1, 10]              20\n",
      "           ReLU-7935                   [-1, 10]               0\n",
      "        Dropout-7936                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7937                   [-1, 10]               0\n",
      "         Linear-7938                   [-1, 10]             110\n",
      "        Softmax-7939                   [-1, 10]               0\n",
      "         Linear-7940                   [-1, 15]             165\n",
      "        Softmax-7941                   [-1, 15]               0\n",
      "         Linear-7942                   [-1, 10]             110\n",
      "    BatchNorm1d-7943                   [-1, 10]              20\n",
      "           ReLU-7944                   [-1, 10]               0\n",
      "        Dropout-7945                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7946                   [-1, 10]               0\n",
      "         Linear-7947                   [-1, 10]             110\n",
      "    BatchNorm1d-7948                   [-1, 10]              20\n",
      "           ReLU-7949                   [-1, 10]               0\n",
      "        Dropout-7950                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7951                   [-1, 10]               0\n",
      "         Linear-7952                   [-1, 10]             110\n",
      "    BatchNorm1d-7953                   [-1, 10]              20\n",
      "           ReLU-7954                   [-1, 10]               0\n",
      "        Dropout-7955                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7956                   [-1, 10]               0\n",
      "         Linear-7957                   [-1, 10]             110\n",
      "    BatchNorm1d-7958                   [-1, 10]              20\n",
      "           ReLU-7959                   [-1, 10]               0\n",
      "        Dropout-7960                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7961                   [-1, 10]               0\n",
      "         Linear-7962                   [-1, 10]             110\n",
      "    BatchNorm1d-7963                   [-1, 10]              20\n",
      "           ReLU-7964                   [-1, 10]               0\n",
      "        Dropout-7965                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7966                   [-1, 10]               0\n",
      "         Linear-7967                   [-1, 10]             110\n",
      "    BatchNorm1d-7968                   [-1, 10]              20\n",
      "           ReLU-7969                   [-1, 10]               0\n",
      "        Dropout-7970                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7971                   [-1, 10]               0\n",
      "         Linear-7972                   [-1, 10]             110\n",
      "    BatchNorm1d-7973                   [-1, 10]              20\n",
      "           ReLU-7974                   [-1, 10]               0\n",
      "        Dropout-7975                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7976                   [-1, 10]               0\n",
      "         Linear-7977                   [-1, 10]             110\n",
      "    BatchNorm1d-7978                   [-1, 10]              20\n",
      "           ReLU-7979                   [-1, 10]               0\n",
      "        Dropout-7980                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7981                   [-1, 10]               0\n",
      "         Linear-7982                   [-1, 10]             110\n",
      "    BatchNorm1d-7983                   [-1, 10]              20\n",
      "           ReLU-7984                   [-1, 10]               0\n",
      "        Dropout-7985                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7986                   [-1, 10]               0\n",
      "         Linear-7987                   [-1, 10]             110\n",
      "    BatchNorm1d-7988                   [-1, 10]              20\n",
      "           ReLU-7989                   [-1, 10]               0\n",
      "        Dropout-7990                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7991                   [-1, 10]               0\n",
      "         Linear-7992                   [-1, 10]             110\n",
      "        Softmax-7993                   [-1, 10]               0\n",
      "         Linear-7994                   [-1, 10]             110\n",
      "    BatchNorm1d-7995                   [-1, 10]              20\n",
      "           ReLU-7996                   [-1, 10]               0\n",
      "        Dropout-7997                   [-1, 10]               0\n",
      "MultiLayerPerceptron-7998                   [-1, 10]               0\n",
      "         Linear-7999                   [-1, 10]             110\n",
      "    BatchNorm1d-8000                   [-1, 10]              20\n",
      "           ReLU-8001                   [-1, 10]               0\n",
      "        Dropout-8002                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8003                   [-1, 10]               0\n",
      "         Linear-8004                   [-1, 10]             110\n",
      "    BatchNorm1d-8005                   [-1, 10]              20\n",
      "           ReLU-8006                   [-1, 10]               0\n",
      "        Dropout-8007                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8008                   [-1, 10]               0\n",
      "         Linear-8009                   [-1, 10]             110\n",
      "    BatchNorm1d-8010                   [-1, 10]              20\n",
      "           ReLU-8011                   [-1, 10]               0\n",
      "        Dropout-8012                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8013                   [-1, 10]               0\n",
      "         Linear-8014                   [-1, 10]             110\n",
      "    BatchNorm1d-8015                   [-1, 10]              20\n",
      "           ReLU-8016                   [-1, 10]               0\n",
      "        Dropout-8017                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8018                   [-1, 10]               0\n",
      "         Linear-8019                   [-1, 10]             110\n",
      "        Softmax-8020                   [-1, 10]               0\n",
      "         Linear-8021                   [-1, 15]             165\n",
      "        Softmax-8022                   [-1, 15]               0\n",
      "         Linear-8023                   [-1, 10]             110\n",
      "    BatchNorm1d-8024                   [-1, 10]              20\n",
      "           ReLU-8025                   [-1, 10]               0\n",
      "        Dropout-8026                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8027                   [-1, 10]               0\n",
      "         Linear-8028                   [-1, 10]             110\n",
      "    BatchNorm1d-8029                   [-1, 10]              20\n",
      "           ReLU-8030                   [-1, 10]               0\n",
      "        Dropout-8031                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8032                   [-1, 10]               0\n",
      "         Linear-8033                   [-1, 10]             110\n",
      "    BatchNorm1d-8034                   [-1, 10]              20\n",
      "           ReLU-8035                   [-1, 10]               0\n",
      "        Dropout-8036                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8037                   [-1, 10]               0\n",
      "         Linear-8038                   [-1, 10]             110\n",
      "    BatchNorm1d-8039                   [-1, 10]              20\n",
      "           ReLU-8040                   [-1, 10]               0\n",
      "        Dropout-8041                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8042                   [-1, 10]               0\n",
      "         Linear-8043                   [-1, 10]             110\n",
      "    BatchNorm1d-8044                   [-1, 10]              20\n",
      "           ReLU-8045                   [-1, 10]               0\n",
      "        Dropout-8046                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8047                   [-1, 10]               0\n",
      "         Linear-8048                   [-1, 10]             110\n",
      "    BatchNorm1d-8049                   [-1, 10]              20\n",
      "           ReLU-8050                   [-1, 10]               0\n",
      "        Dropout-8051                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8052                   [-1, 10]               0\n",
      "         Linear-8053                   [-1, 10]             110\n",
      "    BatchNorm1d-8054                   [-1, 10]              20\n",
      "           ReLU-8055                   [-1, 10]               0\n",
      "        Dropout-8056                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8057                   [-1, 10]               0\n",
      "         Linear-8058                   [-1, 10]             110\n",
      "    BatchNorm1d-8059                   [-1, 10]              20\n",
      "           ReLU-8060                   [-1, 10]               0\n",
      "        Dropout-8061                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8062                   [-1, 10]               0\n",
      "         Linear-8063                   [-1, 10]             110\n",
      "    BatchNorm1d-8064                   [-1, 10]              20\n",
      "           ReLU-8065                   [-1, 10]               0\n",
      "        Dropout-8066                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8067                   [-1, 10]               0\n",
      "         Linear-8068                   [-1, 10]             110\n",
      "    BatchNorm1d-8069                   [-1, 10]              20\n",
      "           ReLU-8070                   [-1, 10]               0\n",
      "        Dropout-8071                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8072                   [-1, 10]               0\n",
      "         Linear-8073                   [-1, 10]             110\n",
      "        Softmax-8074                   [-1, 10]               0\n",
      "         Linear-8075                   [-1, 10]             110\n",
      "    BatchNorm1d-8076                   [-1, 10]              20\n",
      "           ReLU-8077                   [-1, 10]               0\n",
      "        Dropout-8078                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8079                   [-1, 10]               0\n",
      "         Linear-8080                   [-1, 10]             110\n",
      "    BatchNorm1d-8081                   [-1, 10]              20\n",
      "           ReLU-8082                   [-1, 10]               0\n",
      "        Dropout-8083                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8084                   [-1, 10]               0\n",
      "         Linear-8085                   [-1, 10]             110\n",
      "    BatchNorm1d-8086                   [-1, 10]              20\n",
      "           ReLU-8087                   [-1, 10]               0\n",
      "        Dropout-8088                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8089                   [-1, 10]               0\n",
      "         Linear-8090                   [-1, 10]             110\n",
      "    BatchNorm1d-8091                   [-1, 10]              20\n",
      "           ReLU-8092                   [-1, 10]               0\n",
      "        Dropout-8093                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8094                   [-1, 10]               0\n",
      "         Linear-8095                   [-1, 10]             110\n",
      "    BatchNorm1d-8096                   [-1, 10]              20\n",
      "           ReLU-8097                   [-1, 10]               0\n",
      "        Dropout-8098                   [-1, 10]               0\n",
      "MultiLayerPerceptron-8099                   [-1, 10]               0\n",
      "         Linear-8100                   [-1, 10]             110\n",
      "        Softmax-8101                   [-1, 10]               0\n",
      "         Linear-8102                    [-1, 2]              22\n",
      "    BatchNorm1d-8103                    [-1, 2]               4\n",
      "           ReLU-8104                    [-1, 2]               0\n",
      "        Dropout-8105                    [-1, 2]               0\n",
      "         Linear-8106                    [-1, 3]               9\n",
      "    BatchNorm1d-8107                    [-1, 3]               6\n",
      "           ReLU-8108                    [-1, 3]               0\n",
      "        Dropout-8109                    [-1, 3]               0\n",
      "         Linear-8110                    [-1, 4]              16\n",
      "    BatchNorm1d-8111                    [-1, 4]               8\n",
      "           ReLU-8112                    [-1, 4]               0\n",
      "        Dropout-8113                    [-1, 4]               0\n",
      "         Linear-8114                    [-1, 1]               5\n",
      "MultiLayerPerceptron-8115                    [-1, 1]               0\n",
      "         Linear-8116                    [-1, 2]              22\n",
      "    BatchNorm1d-8117                    [-1, 2]               4\n",
      "           ReLU-8118                    [-1, 2]               0\n",
      "        Dropout-8119                    [-1, 2]               0\n",
      "         Linear-8120                    [-1, 3]               9\n",
      "    BatchNorm1d-8121                    [-1, 3]               6\n",
      "           ReLU-8122                    [-1, 3]               0\n",
      "        Dropout-8123                    [-1, 3]               0\n",
      "         Linear-8124                    [-1, 4]              16\n",
      "    BatchNorm1d-8125                    [-1, 4]               8\n",
      "           ReLU-8126                    [-1, 4]               0\n",
      "        Dropout-8127                    [-1, 4]               0\n",
      "         Linear-8128                    [-1, 1]               5\n",
      "MultiLayerPerceptron-8129                    [-1, 1]               0\n",
      "       PLEModel-8130               [[-1], [-1]]               0\n",
      "================================================================\n",
      "Total params: 233,913\n",
      "Trainable params: 233,913\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.63\n",
      "Params size (MB): 0.89\n",
      "Estimated Total Size (MB): 1.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# https://blog.csdn.net/qq_33952811/article/details/124276599\n",
    "# 参数量和计算量 = 空间复杂度、时间复杂度 = 显存大小、训练时间\n",
    "\n",
    "# from torchstat import stat\n",
    "from torchsummary import summary\n",
    "from models import MultitaskWrapper\n",
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "m = MultitaskWrapper(ms[4]).to(device)\n",
    "# stat(m, (1, 4, 1))\n",
    "summary(m, (numerical_num, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.5736, 0.4327, 0.5736, 0.4600], device='cuda:0',\n",
       "        grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.4564, 0.4087, 0.4048, 0.3834], device='cuda:0',\n",
       "        grad_fn=<SigmoidBackward0>)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "X = torch.rand((batch_size, numerical_num)).to(device)\n",
    "# 默认分类任务，输出是一个数， 不过这里我们有batch个数\n",
    "m(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "tensorboard = SummaryWriter(project_directory/'tensorboard_log/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 11:30:05.859582: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/yecm/.conda/envs/torch/lib/python3.11/site-packages/torch/jit/_trace.py:1056: TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.\n",
      "  module._c._create_method_from_trace(\n"
     ]
    }
   ],
   "source": [
    "tensorboard.add_graph(m, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Python 3.11+ not yet supported for torch.compile",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mcompile(m)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.11/site-packages/torch/__init__.py:1594\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(model, fullgraph, dynamic, backend, mode, options, disable)\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[39mif\u001b[39;00m backend \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minductor\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1593\u001b[0m     backend \u001b[39m=\u001b[39m _TorchCompileInductorWrapper(mode, options, dynamic)\n\u001b[0;32m-> 1594\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_dynamo\u001b[39m.\u001b[39;49moptimize(backend\u001b[39m=\u001b[39;49mbackend, nopython\u001b[39m=\u001b[39;49mfullgraph, dynamic\u001b[39m=\u001b[39;49mdynamic, disable\u001b[39m=\u001b[39;49mdisable)(model)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:457\u001b[0m, in \u001b[0;36moptimize\u001b[0;34m(backend, nopython, guard_export_fn, guard_fail_fn, disable, dynamic)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    425\u001b[0m     backend\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minductor\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    426\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m     dynamic\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    432\u001b[0m ):\n\u001b[1;32m    433\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m    The main entrypoint of TorchDynamo.  Do graph capture and call\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    backend() to optimize extracted graphs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39m            ...\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m     check_if_dynamo_supported()\n\u001b[1;32m    458\u001b[0m     \u001b[39m# Note: The hooks object could be global instead of passed around, *however* that would make\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[39m# for a confusing API usage and plumbing story wherein we nest multiple .optimize calls.\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39m# There is some prior art around this, w/r/t nesting backend calls are enforced to be the same\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[39m# compiler, however, this feels onerous for callback and hooks, and it feels better to give our users an\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[39m# easier to understand UX at the cost of a little more plumbing on our end.\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     hooks \u001b[39m=\u001b[39m Hooks(guard_export_fn\u001b[39m=\u001b[39mguard_export_fn, guard_fail_fn\u001b[39m=\u001b[39mguard_fail_fn)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:413\u001b[0m, in \u001b[0;36mcheck_if_dynamo_supported\u001b[0;34m()\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWindows not yet supported for torch.compile\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    412\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mversion_info \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m11\u001b[39m):\n\u001b[0;32m--> 413\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPython 3.11+ not yet supported for torch.compile\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Python 3.11+ not yet supported for torch.compile"
     ]
    }
   ],
   "source": [
    "torch.compile(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
